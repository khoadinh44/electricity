{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "running.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV8nVSdymR3j"
      },
      "source": [
        "## Clone github "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cyp_5Fi9lSH4",
        "outputId": "a176997f-f5fe-445e-ed11-4f4610d1dac5"
      },
      "source": [
        "!git clone https://github.com/khoadinh44/electricity.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'electricity'...\n",
            "remote: Enumerating objects: 97, done.\u001b[K\n",
            "remote: Counting objects: 100% (97/97), done.\u001b[K\n",
            "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
            "remote: Total 97 (delta 39), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (97/97), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P2Ti356mZTX"
      },
      "source": [
        "# Go into the main brand"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "didCze6MmXv3",
        "outputId": "5f88ceb1-f0cb-4e29-d665-08a7a423c80f"
      },
      "source": [
        "%cd /content/electricity"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/electricity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oIxjdmpm-UJ"
      },
      "source": [
        "# Install library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqMKJgllm3Fh",
        "outputId": "751b1c22-4852-416e-88d4-8925a8ba05cc"
      },
      "source": [
        "%pip install -qr requirements.txt "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 23.7 MB/s eta 0:00:01\r\u001b[K     |██████                          | 20 kB 24.1 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 30 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 71 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 81 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 92 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 107 kB 5.2 MB/s \n",
            "\u001b[?25h  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKWN0KYLmkpc"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrMUXNvCmjH1",
        "outputId": "9416eb29-e7ad-4a81-bc19-f89a7a0d7454"
      },
      "source": [
        "!python main.py"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tflearn/initializations.py:165: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "2021-10-11 19:11:47.070120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:11:47.079735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:11:47.080629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:11:47.081978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:11:47.082963: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:11:47.083772: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:11:47.687270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:11:47.688272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:11:47.689248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:11:47.690312: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-10-11 19:11:47.690379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15090 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "2021-10-11 19:11:47.690955: I tensorflow/core/common_runtime/direct_session.cc:361] Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "is_training: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.928645: I tensorflow/core/common_runtime/placer.cc:114] is_training: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "is_training/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.928703: I tensorflow/core/common_runtime/placer.cc:114] is_training/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "is_training/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.928721: I tensorflow/core/common_runtime/placer.cc:114] is_training/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.928737: I tensorflow/core/common_runtime/placer.cc:114] Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Assign_1: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.928765: I tensorflow/core/common_runtime/placer.cc:114] Assign_1: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Initializer/truncated_normal/TruncatedNormal: (TruncatedNormal): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.928782: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Initializer/truncated_normal/TruncatedNormal: (TruncatedNormal): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Initializer/truncated_normal/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.928799: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Initializer/truncated_normal/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Initializer/truncated_normal: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.928831: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Initializer/truncated_normal: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.928856: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.928880: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.928907: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/b: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.928940: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/b: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/b/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.928964: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/b/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/b/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.928982: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/b/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929004: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929027: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Initializer/truncated_normal/TruncatedNormal: (TruncatedNormal): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929053: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Initializer/truncated_normal/TruncatedNormal: (TruncatedNormal): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Initializer/truncated_normal/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929074: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Initializer/truncated_normal/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Initializer/truncated_normal: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929094: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Initializer/truncated_normal: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929114: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929133: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929152: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/b: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929176: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/b: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/b/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929197: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/b/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/b/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929217: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/b/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929244: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929268: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Initializer/truncated_normal/TruncatedNormal: (TruncatedNormal): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929293: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Initializer/truncated_normal/TruncatedNormal: (TruncatedNormal): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Initializer/truncated_normal/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929315: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Initializer/truncated_normal/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Initializer/truncated_normal: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929350: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Initializer/truncated_normal: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929385: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929409: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929445: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/b: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929478: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/b: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/b/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929517: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/b/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/b/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929557: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/b/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929587: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929609: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/Softmax: (Softmax): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929625: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/Softmax: (Softmax): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Accuracy/ArgMax: (ArgMax): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929642: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/ArgMax: (ArgMax): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Accuracy/ArgMax_1: (ArgMax): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929659: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/ArgMax_1: (ArgMax): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Accuracy/Equal: (Equal): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929691: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/Equal: (Equal): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Accuracy/Cast: (Cast): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929729: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/Cast: (Cast): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Accuracy/Mean: (Mean): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929812: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/Mean: (Mean): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929851: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/truediv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929876: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/truediv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/clip_by_value/Minimum: (Minimum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929903: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/clip_by_value/Minimum: (Minimum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/clip_by_value: (Maximum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929928: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/clip_by_value: (Maximum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Log: (Log): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929960: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Log: (Log): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.929984: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930023: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Neg: (Neg): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930046: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Neg: (Neg): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Mean: (Mean): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930072: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Mean: (Mean): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Training_step: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930128: I tensorflow/core/common_runtime/placer.cc:114] Training_step: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Training_step/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930167: I tensorflow/core/common_runtime/placer.cc:114] Training_step/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Training_step/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930192: I tensorflow/core/common_runtime/placer.cc:114] Training_step/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Global_Step: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930232: I tensorflow/core/common_runtime/placer.cc:114] Global_Step: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Global_Step/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930259: I tensorflow/core/common_runtime/placer.cc:114] Global_Step/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Global_Step/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930281: I tensorflow/core/common_runtime/placer.cc:114] Global_Step/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Add: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930299: I tensorflow/core/common_runtime/placer.cc:114] Add: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Assign_2: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930340: I tensorflow/core/common_runtime/placer.cc:114] Assign_2: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "val_loss: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930358: I tensorflow/core/common_runtime/placer.cc:114] val_loss: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "val_loss/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930377: I tensorflow/core/common_runtime/placer.cc:114] val_loss/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "val_loss/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930404: I tensorflow/core/common_runtime/placer.cc:114] val_loss/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "val_acc: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930447: I tensorflow/core/common_runtime/placer.cc:114] val_acc: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "val_acc/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930493: I tensorflow/core/common_runtime/placer.cc:114] val_acc/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "val_acc/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930516: I tensorflow/core/common_runtime/placer.cc:114] val_acc/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "assign/val_loss: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930537: I tensorflow/core/common_runtime/placer.cc:114] assign/val_loss: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "assign/val_acc: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930559: I tensorflow/core/common_runtime/placer.cc:114] assign/val_acc: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Accuracy/Mean/moving_avg: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930585: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/Mean/moving_avg: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Accuracy/Mean/moving_avg/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930609: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/Mean/moving_avg/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Accuracy/Mean/moving_avg/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930631: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/Mean/moving_avg/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg/add: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930657: I tensorflow/core/common_runtime/placer.cc:114] moving_avg/add: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg/add_1: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930683: I tensorflow/core/common_runtime/placer.cc:114] moving_avg/add_1: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg/truediv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930708: I tensorflow/core/common_runtime/placer.cc:114] moving_avg/truediv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg/Minimum: (Minimum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930733: I tensorflow/core/common_runtime/placer.cc:114] moving_avg/Minimum: (Minimum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg/AssignMovingAvg/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.930784: I tensorflow/core/common_runtime/placer.cc:114] moving_avg/AssignMovingAvg/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg/AssignMovingAvg/sub_1: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.990243: I tensorflow/core/common_runtime/placer.cc:114] moving_avg/AssignMovingAvg/sub_1: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg/AssignMovingAvg/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.990305: I tensorflow/core/common_runtime/placer.cc:114] moving_avg/AssignMovingAvg/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg/AssignMovingAvg: (AssignSub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.990353: I tensorflow/core/common_runtime/placer.cc:114] moving_avg/AssignMovingAvg: (AssignSub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.990390: I tensorflow/core/common_runtime/placer.cc:114] moving_avg: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/Total_Loss: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.990425: I tensorflow/core/common_runtime/placer.cc:114] Adam/Total_Loss: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Mean/moving_avg: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.990463: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Mean/moving_avg: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Mean/moving_avg/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.990495: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Mean/moving_avg/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Mean/moving_avg/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.990516: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Mean/moving_avg/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg/add: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.990544: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg/add: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg/add_1: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.990565: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg/add_1: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg/truediv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.990593: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg/truediv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg/Minimum: (Minimum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.990618: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg/Minimum: (Minimum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg/AssignMovingAvg/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.990648: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg/AssignMovingAvg/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg/AssignMovingAvg/sub_1: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.990671: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg/AssignMovingAvg/sub_1: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg/AssignMovingAvg/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.990686: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg/AssignMovingAvg/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg/AssignMovingAvg: (AssignSub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.990699: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg/AssignMovingAvg: (AssignSub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.990712: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Loss: (ScalarSummary): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:47.990739: I tensorflow/core/common_runtime/placer.cc:114] Loss: (ScalarSummary): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Adam/Loss/raw: (ScalarSummary): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:47.990771: I tensorflow/core/common_runtime/placer.cc:114] Adam/Loss/raw: (ScalarSummary): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Adam/gradients/grad_ys_0: (Fill): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.990803: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/grad_ys_0: (Fill): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.990836: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.990870: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Tile: (Tile): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.990919: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Tile: (Tile): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Shape_1: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.990958: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Shape_1: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Prod: (Prod): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991004: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Prod: (Prod): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Prod_1: (Prod): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991037: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Prod_1: (Prod): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Maximum: (Maximum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991071: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Maximum: (Maximum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/floordiv: (FloorDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991119: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/floordiv: (FloorDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Cast: (Cast): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991151: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Cast: (Cast): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/truediv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991184: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/truediv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Neg_grad/Neg: (Neg): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991216: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Neg_grad/Neg: (Neg): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991250: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/add: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991283: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/add: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/mod: (FloorMod): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991310: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/mod: (FloorMod): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/range: (Range): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991352: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/range: (Range): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/ones: (Fill): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991382: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/ones: (Fill): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/DynamicStitch: (DynamicStitch): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991410: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/DynamicStitch: (DynamicStitch): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991445: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/BroadcastTo: (BroadcastTo): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991479: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/BroadcastTo: (BroadcastTo): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/mul_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991514: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/mul_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/mul_grad/Shape_1: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991546: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/mul_grad/Shape_1: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/mul_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991579: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/mul_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/mul_grad/Mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991614: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/mul_grad/Mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/mul_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991647: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/mul_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/mul_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991679: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/mul_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/mul_grad/Mul_1: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991713: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/mul_grad/Mul_1: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/mul_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991746: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/mul_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/mul_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991780: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/mul_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Log_grad/Reciprocal: (Reciprocal): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991818: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Log_grad/Reciprocal: (Reciprocal): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Log_grad/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991851: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Log_grad/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991885: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value_grad/zeros_like: (ZerosLike): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991919: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value_grad/zeros_like: (ZerosLike): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value_grad/GreaterEqual: (GreaterEqual): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.991952: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value_grad/GreaterEqual: (GreaterEqual): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992002: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value_grad/SelectV2: (SelectV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992037: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value_grad/SelectV2: (SelectV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992074: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992109: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value_grad/SelectV2_1: (SelectV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992142: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value_grad/SelectV2_1: (SelectV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992175: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992209: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992243: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/zeros_like: (ZerosLike): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992277: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/zeros_like: (ZerosLike): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/LessEqual: (LessEqual): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992311: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/LessEqual: (LessEqual): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992358: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/SelectV2: (SelectV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992393: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/SelectV2: (SelectV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992426: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992461: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/SelectV2_1: (SelectV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992494: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/SelectV2_1: (SelectV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992529: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992562: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/truediv_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992595: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/truediv_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/truediv_grad/Shape_1: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992629: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/truediv_grad/Shape_1: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/truediv_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992662: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/truediv_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/truediv_grad/RealDiv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992696: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/truediv_grad/RealDiv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/truediv_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992729: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/truediv_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/truediv_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992762: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/truediv_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/truediv_grad/Neg: (Neg): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992796: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/truediv_grad/Neg: (Neg): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/truediv_grad/RealDiv_1: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992828: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/truediv_grad/RealDiv_1: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/truediv_grad/RealDiv_2: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992861: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/truediv_grad/RealDiv_2: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/truediv_grad/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992895: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/truediv_grad/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/truediv_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992928: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/truediv_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/truediv_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.992967: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/truediv_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993018: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_grad/BroadcastTo: (BroadcastTo): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993053: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_grad/BroadcastTo: (BroadcastTo): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/AddN: (AddN): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993085: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/AddN: (AddN): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected_2/Softmax_grad/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993119: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected_2/Softmax_grad/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected_2/Softmax_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993167: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected_2/Softmax_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected_2/Softmax_grad/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993200: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected_2/Softmax_grad/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected_2/Softmax_grad/mul_1: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993249: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected_2/Softmax_grad/mul_1: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected_2/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993283: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected_2/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected_2/MatMul_grad/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993315: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected_2/MatMul_grad/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected_2/MatMul_grad/MatMul_1: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993362: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected_2/MatMul_grad/MatMul_1: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected_1/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993385: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected_1/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected_1/MatMul_grad/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993418: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected_1/MatMul_grad/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected_1/MatMul_grad/MatMul_1: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993452: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected_1/MatMul_grad/MatMul_1: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993484: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected/MatMul_grad/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993516: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected/MatMul_grad/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected/MatMul_grad/MatMul_1: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993550: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected/MatMul_grad/MatMul_1: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/global_norm/L2Loss: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993581: I tensorflow/core/common_runtime/placer.cc:114] Adam/global_norm/L2Loss: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/global_norm/L2Loss_1: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993611: I tensorflow/core/common_runtime/placer.cc:114] Adam/global_norm/L2Loss_1: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/global_norm/L2Loss_2: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993641: I tensorflow/core/common_runtime/placer.cc:114] Adam/global_norm/L2Loss_2: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/global_norm/L2Loss_3: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993670: I tensorflow/core/common_runtime/placer.cc:114] Adam/global_norm/L2Loss_3: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/global_norm/L2Loss_4: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993714: I tensorflow/core/common_runtime/placer.cc:114] Adam/global_norm/L2Loss_4: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/global_norm/L2Loss_5: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993744: I tensorflow/core/common_runtime/placer.cc:114] Adam/global_norm/L2Loss_5: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/global_norm/stack: (Pack): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993780: I tensorflow/core/common_runtime/placer.cc:114] Adam/global_norm/stack: (Pack): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/global_norm/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993814: I tensorflow/core/common_runtime/placer.cc:114] Adam/global_norm/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/global_norm/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993847: I tensorflow/core/common_runtime/placer.cc:114] Adam/global_norm/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/global_norm/global_norm: (Sqrt): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993880: I tensorflow/core/common_runtime/placer.cc:114] Adam/global_norm/global_norm: (Sqrt): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/truediv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993913: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/truediv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/truediv_1: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.993971: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/truediv_1: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/Minimum: (Minimum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994029: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/Minimum: (Minimum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994065: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994099: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/add: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994131: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/add: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/mul_1: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994175: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/mul_1: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/Adam/clip_by_global_norm/_0: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994203: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/Adam/clip_by_global_norm/_0: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/mul_2: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994261: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/mul_2: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/Adam/clip_by_global_norm/_1: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994308: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/Adam/clip_by_global_norm/_1: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/mul_3: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994349: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/mul_3: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/Adam/clip_by_global_norm/_2: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994376: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/Adam/clip_by_global_norm/_2: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/mul_4: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994405: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/mul_4: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/Adam/clip_by_global_norm/_3: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994434: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/Adam/clip_by_global_norm/_3: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/mul_5: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994462: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/mul_5: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/Adam/clip_by_global_norm/_4: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994519: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/Adam/clip_by_global_norm/_4: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/mul_6: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994546: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/mul_6: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/Adam/clip_by_global_norm/_5: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994590: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/Adam/clip_by_global_norm/_5: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/beta1_power: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994618: I tensorflow/core/common_runtime/placer.cc:114] Adam/beta1_power: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/beta1_power/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994663: I tensorflow/core/common_runtime/placer.cc:114] Adam/beta1_power/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/beta1_power/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994691: I tensorflow/core/common_runtime/placer.cc:114] Adam/beta1_power/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/beta2_power: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994717: I tensorflow/core/common_runtime/placer.cc:114] Adam/beta2_power: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/beta2_power/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994744: I tensorflow/core/common_runtime/placer.cc:114] Adam/beta2_power/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/beta2_power/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994771: I tensorflow/core/common_runtime/placer.cc:114] Adam/beta2_power/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994812: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994838: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994878: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994917: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994969: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.994998: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/b/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995029: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/b/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/b/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995058: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/b/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/b/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995088: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/b/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/b/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995129: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/b/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/b/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995157: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/b/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/b/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995201: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/b/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995260: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995286: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995312: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995363: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995387: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995415: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995454: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995494: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/b/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995554: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/b/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/b/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995585: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/b/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/b/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995615: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/b/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/b/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995643: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/b/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/b/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995676: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/b/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/b/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995699: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/b/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995724: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995770: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995830: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995873: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995895: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995914: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/b/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995931: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/b/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/b/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995948: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/b/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/b/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995966: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/b/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/b/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.995995: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/b/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/b/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996022: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/b/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/b/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996033: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/b/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/update_FullyConnected/W/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996046: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/update_FullyConnected/W/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/update_FullyConnected/b/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996058: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/update_FullyConnected/b/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/update_FullyConnected_1/W/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996077: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/update_FullyConnected_1/W/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/update_FullyConnected_1/b/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996103: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/update_FullyConnected_1/b/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/update_FullyConnected_2/W/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996141: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/update_FullyConnected_2/W/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/update_FullyConnected_2/b/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996161: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/update_FullyConnected_2/b/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996179: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996197: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/mul_1: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996213: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/mul_1: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/Assign_1: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996225: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/Assign_1: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/update: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996245: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/update: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0: (AssignAdd): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996257: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0: (AssignAdd): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/Merge/MergeSummary: (MergeSummary): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:47.996270: I tensorflow/core/common_runtime/placer.cc:114] Adam/Merge/MergeSummary: (MergeSummary): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Adam/train_op_0: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996284: I tensorflow/core/common_runtime/placer.cc:114] Adam/train_op_0: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/filename: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996297: I tensorflow/core/common_runtime/placer.cc:114] save/filename: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Const: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996348: I tensorflow/core/common_runtime/placer.cc:114] save/Const: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/SaveV2: (SaveV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:47.996374: I tensorflow/core/common_runtime/placer.cc:114] save/SaveV2: (SaveV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996396: I tensorflow/core/common_runtime/placer.cc:114] save/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/RestoreV2: (RestoreV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:47.996419: I tensorflow/core/common_runtime/placer.cc:114] save/RestoreV2: (RestoreV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996436: I tensorflow/core/common_runtime/placer.cc:114] save/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_1: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996454: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_1: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_2: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996475: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_2: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_3: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996501: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_3: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_4: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996524: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_4: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_5: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996545: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_5: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_6: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996564: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_6: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_7: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996589: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_7: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_8: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996603: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_8: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_9: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996617: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_9: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_10: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996638: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_10: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_11: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996657: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_11: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_12: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996676: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_12: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_13: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996698: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_13: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_14: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996736: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_14: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_15: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996772: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_15: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_16: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996797: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_16: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_17: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996821: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_17: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_18: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996847: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_18: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_19: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996870: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_19: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_20: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996902: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_20: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_21: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996934: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_21: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_22: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.996985: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_22: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_23: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997028: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_23: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_24: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997053: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_24: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_25: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997109: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_25: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_26: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997132: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_26: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/restore_all: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997158: I tensorflow/core/common_runtime/placer.cc:114] save/restore_all: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/filename: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997186: I tensorflow/core/common_runtime/placer.cc:114] save_1/filename: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Const: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997228: I tensorflow/core/common_runtime/placer.cc:114] save_1/Const: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/SaveV2: (SaveV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:47.997252: I tensorflow/core/common_runtime/placer.cc:114] save_1/SaveV2: (SaveV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_1/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997277: I tensorflow/core/common_runtime/placer.cc:114] save_1/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/RestoreV2: (RestoreV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:47.997316: I tensorflow/core/common_runtime/placer.cc:114] save_1/RestoreV2: (RestoreV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997349: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_1: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997363: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_1: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_2: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997374: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_2: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_3: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997399: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_3: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_4: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997408: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_4: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_5: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997440: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_5: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_6: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997462: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_6: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_7: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997481: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_7: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_8: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997498: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_8: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_9: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997515: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_9: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_10: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997527: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_10: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_11: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997539: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_11: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_12: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997550: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_12: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_13: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997582: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_13: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_14: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997608: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_14: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_15: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997626: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_15: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_16: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997661: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_16: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_17: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997681: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_17: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_18: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997700: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_18: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_19: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997722: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_19: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_20: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997742: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_20: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_21: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997762: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_21: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_22: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997785: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_22: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_23: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997806: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_23: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_24: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997825: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_24: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_25: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997845: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_25: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_26: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997865: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_26: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/restore_all: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997906: I tensorflow/core/common_runtime/placer.cc:114] save_1/restore_all: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_2/filename: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997931: I tensorflow/core/common_runtime/placer.cc:114] save_2/filename: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_2/Const: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.997956: I tensorflow/core/common_runtime/placer.cc:114] save_2/Const: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_2/SaveV2: (SaveV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:47.997986: I tensorflow/core/common_runtime/placer.cc:114] save_2/SaveV2: (SaveV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_2/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998008: I tensorflow/core/common_runtime/placer.cc:114] save_2/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_2/RestoreV2: (RestoreV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:47.998033: I tensorflow/core/common_runtime/placer.cc:114] save_2/RestoreV2: (RestoreV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_2/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998053: I tensorflow/core/common_runtime/placer.cc:114] save_2/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_2/Assign_1: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998075: I tensorflow/core/common_runtime/placer.cc:114] save_2/Assign_1: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_2/Assign_2: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998093: I tensorflow/core/common_runtime/placer.cc:114] save_2/Assign_2: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_2/Assign_3: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998110: I tensorflow/core/common_runtime/placer.cc:114] save_2/Assign_3: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_2/Assign_4: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998124: I tensorflow/core/common_runtime/placer.cc:114] save_2/Assign_4: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_2/Assign_5: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998141: I tensorflow/core/common_runtime/placer.cc:114] save_2/Assign_5: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_2/restore_all: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998158: I tensorflow/core/common_runtime/placer.cc:114] save_2/restore_all: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "init: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998170: I tensorflow/core/common_runtime/placer.cc:114] init: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "init_1: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998187: I tensorflow/core/common_runtime/placer.cc:114] init_1: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "group_deps: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998200: I tensorflow/core/common_runtime/placer.cc:114] group_deps: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "init_2: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998228: I tensorflow/core/common_runtime/placer.cc:114] init_2: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "is_training/Initializer/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998247: I tensorflow/core/common_runtime/placer.cc:114] is_training/Initializer/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Assign/value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998274: I tensorflow/core/common_runtime/placer.cc:114] Assign/value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Assign_1/value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998299: I tensorflow/core/common_runtime/placer.cc:114] Assign_1/value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "InputData/X: (Placeholder): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998332: I tensorflow/core/common_runtime/placer.cc:114] InputData/X: (Placeholder): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Initializer/truncated_normal/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998356: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Initializer/truncated_normal/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Initializer/truncated_normal/mean: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998376: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Initializer/truncated_normal/mean: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Initializer/truncated_normal/stddev: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998396: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Initializer/truncated_normal/stddev: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/b/Initializer/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998415: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/b/Initializer/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Initializer/truncated_normal/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998735: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Initializer/truncated_normal/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Initializer/truncated_normal/mean: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998773: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Initializer/truncated_normal/mean: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Initializer/truncated_normal/stddev: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998792: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Initializer/truncated_normal/stddev: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/b/Initializer/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998805: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/b/Initializer/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Initializer/truncated_normal/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998832: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Initializer/truncated_normal/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Initializer/truncated_normal/mean: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998844: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Initializer/truncated_normal/mean: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Initializer/truncated_normal/stddev: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998857: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Initializer/truncated_normal/stddev: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/b/Initializer/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998873: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/b/Initializer/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "TargetsData/Y: (Placeholder): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998900: I tensorflow/core/common_runtime/placer.cc:114] TargetsData/Y: (Placeholder): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Accuracy/ArgMax/dimension: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998927: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/ArgMax/dimension: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Accuracy/ArgMax_1/dimension: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.998973: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/ArgMax_1/dimension: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Accuracy/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.999008: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Sum/reduction_indices: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.999052: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Sum/reduction_indices: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Cast/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.999078: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Cast/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Cast_1/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.999101: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Cast_1/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Sum_1/reduction_indices: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:47.999142: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Sum_1/reduction_indices: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.002433: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Training_step/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.002472: I tensorflow/core/common_runtime/placer.cc:114] Training_step/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Global_Step/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.002503: I tensorflow/core/common_runtime/placer.cc:114] Global_Step/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Add/y: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.002530: I tensorflow/core/common_runtime/placer.cc:114] Add/y: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "val_loss/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.002557: I tensorflow/core/common_runtime/placer.cc:114] val_loss/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "val_acc/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.002582: I tensorflow/core/common_runtime/placer.cc:114] val_acc/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "placeholder/val_loss: (Placeholder): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.002606: I tensorflow/core/common_runtime/placer.cc:114] placeholder/val_loss: (Placeholder): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "placeholder/val_acc: (Placeholder): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.002647: I tensorflow/core/common_runtime/placer.cc:114] placeholder/val_acc: (Placeholder): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Accuracy/Mean/moving_avg/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.002669: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/Mean/moving_avg/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg/decay: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.002695: I tensorflow/core/common_runtime/placer.cc:114] moving_avg/decay: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg/add/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.002735: I tensorflow/core/common_runtime/placer.cc:114] moving_avg/add/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg/add_1/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.002764: I tensorflow/core/common_runtime/placer.cc:114] moving_avg/add_1/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg/AssignMovingAvg/sub/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.002789: I tensorflow/core/common_runtime/placer.cc:114] moving_avg/AssignMovingAvg/sub/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Mean/moving_avg/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.002811: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Mean/moving_avg/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg/decay: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.002838: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg/decay: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg/add/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.002866: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg/add/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg/add_1/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.002908: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg/add_1/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg/AssignMovingAvg/sub/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.002932: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg/AssignMovingAvg/sub/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Loss/tags: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.005004: I tensorflow/core/common_runtime/placer.cc:114] Loss/tags: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Adam/Loss/raw/tags: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.005049: I tensorflow/core/common_runtime/placer.cc:114] Adam/Loss/raw/tags: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Adam/gradients/Shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.005091: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/grad_ys_0/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.005109: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/grad_ys_0/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Reshape/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.005140: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Reshape/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Shape_2: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.005166: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Shape_2: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.005189: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Const_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.005221: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Const_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Maximum/y: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.005251: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Maximum/y: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/Size: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.005276: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/Size: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.005297: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/range/start: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.005316: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/range/start: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/range/delta: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.005358: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/range/delta: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/ones/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.005385: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/ones/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.005415: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.008982: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected_2/Softmax_grad/Sum/reduction_indices: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009026: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected_2/Softmax_grad/Sum/reduction_indices: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/global_norm/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009069: I tensorflow/core/common_runtime/placer.cc:114] Adam/global_norm/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/global_norm/Const_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009101: I tensorflow/core/common_runtime/placer.cc:114] Adam/global_norm/Const_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/truediv/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009130: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/truediv/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009156: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/truediv_1/y: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009183: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/truediv_1/y: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/mul/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009201: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/mul/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/beta1_power/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009230: I tensorflow/core/common_runtime/placer.cc:114] Adam/beta1_power/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/beta2_power/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009243: I tensorflow/core/common_runtime/placer.cc:114] Adam/beta2_power/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009256: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009270: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/b/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009297: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/b/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/b/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009351: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/b/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009378: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009392: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009405: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Adam_1/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009427: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Adam_1/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/b/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009448: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/b/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/b/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009475: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/b/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009504: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009534: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/b/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009564: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/b/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/b/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009594: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/b/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/learning_rate: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009634: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/learning_rate: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/beta1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009683: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/beta1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/beta2: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009716: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/beta2: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/epsilon: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009744: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/epsilon: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.009765: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/filename/input: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.009780: I tensorflow/core/common_runtime/placer.cc:114] save/filename/input: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save/SaveV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.009791: I tensorflow/core/common_runtime/placer.cc:114] save/SaveV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save/SaveV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.009812: I tensorflow/core/common_runtime/placer.cc:114] save/SaveV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save/RestoreV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.009842: I tensorflow/core/common_runtime/placer.cc:114] save/RestoreV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save/RestoreV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.009866: I tensorflow/core/common_runtime/placer.cc:114] save/RestoreV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_1/filename/input: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.009889: I tensorflow/core/common_runtime/placer.cc:114] save_1/filename/input: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_1/SaveV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.009921: I tensorflow/core/common_runtime/placer.cc:114] save_1/SaveV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_1/SaveV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.009965: I tensorflow/core/common_runtime/placer.cc:114] save_1/SaveV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_1/RestoreV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.010014: I tensorflow/core/common_runtime/placer.cc:114] save_1/RestoreV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_1/RestoreV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.010050: I tensorflow/core/common_runtime/placer.cc:114] save_1/RestoreV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_2/filename/input: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.010086: I tensorflow/core/common_runtime/placer.cc:114] save_2/filename/input: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_2/SaveV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.010121: I tensorflow/core/common_runtime/placer.cc:114] save_2/SaveV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_2/SaveV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.010156: I tensorflow/core/common_runtime/placer.cc:114] save_2/SaveV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_2/RestoreV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.010185: I tensorflow/core/common_runtime/placer.cc:114] save_2/RestoreV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_2/RestoreV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.010215: I tensorflow/core/common_runtime/placer.cc:114] save_2/RestoreV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.055003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:11:48.055951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:11:48.056932: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:11:48.058156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:11:48.059076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:11:48.059971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15090 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "2021-10-11 19:11:48.060052: I tensorflow/core/common_runtime/direct_session.cc:361] Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "---------------------------------\n",
            "Run id: 28WNY5\n",
            "Log directory: /content/electricity/save/tflearn_logs/\n",
            "---------------------------------\n",
            "Training samples: 2300\n",
            "Validation samples: 0\n",
            "--\n",
            "is_training: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149250: I tensorflow/core/common_runtime/placer.cc:114] is_training: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "is_training/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149295: I tensorflow/core/common_runtime/placer.cc:114] is_training/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "is_training/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149338: I tensorflow/core/common_runtime/placer.cc:114] is_training/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149374: I tensorflow/core/common_runtime/placer.cc:114] Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Assign_1: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149398: I tensorflow/core/common_runtime/placer.cc:114] Assign_1: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Initializer/truncated_normal/TruncatedNormal: (TruncatedNormal): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149416: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Initializer/truncated_normal/TruncatedNormal: (TruncatedNormal): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Initializer/truncated_normal/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149433: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Initializer/truncated_normal/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Initializer/truncated_normal: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149448: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Initializer/truncated_normal: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149462: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149475: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149488: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/b: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149503: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/b: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/b/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149517: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/b/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/b/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149531: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/b/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149547: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149563: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Initializer/truncated_normal/TruncatedNormal: (TruncatedNormal): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149578: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Initializer/truncated_normal/TruncatedNormal: (TruncatedNormal): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Initializer/truncated_normal/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149588: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Initializer/truncated_normal/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Initializer/truncated_normal: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149601: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Initializer/truncated_normal: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149614: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149628: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149641: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/b: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149655: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/b: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/b/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149669: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/b/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/b/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149682: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/b/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149697: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149713: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Initializer/truncated_normal/TruncatedNormal: (TruncatedNormal): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149727: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Initializer/truncated_normal/TruncatedNormal: (TruncatedNormal): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Initializer/truncated_normal/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149742: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Initializer/truncated_normal/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Initializer/truncated_normal: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149756: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Initializer/truncated_normal: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149770: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149787: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149801: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/b: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149815: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/b: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/b/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149829: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/b/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/b/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149858: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/b/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149875: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149899: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/Softmax: (Softmax): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149936: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/Softmax: (Softmax): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Accuracy/ArgMax: (ArgMax): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149955: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/ArgMax: (ArgMax): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Accuracy/ArgMax_1: (ArgMax): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149971: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/ArgMax_1: (ArgMax): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Accuracy/Equal: (Equal): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.149987: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/Equal: (Equal): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Accuracy/Cast: (Cast): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150003: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/Cast: (Cast): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Accuracy/Mean: (Mean): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150019: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/Mean: (Mean): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150035: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/truediv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150051: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/truediv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/clip_by_value/Minimum: (Minimum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150067: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/clip_by_value/Minimum: (Minimum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/clip_by_value: (Maximum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150083: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/clip_by_value: (Maximum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Log: (Log): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150099: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Log: (Log): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150115: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150147: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Neg: (Neg): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150163: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Neg: (Neg): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Mean: (Mean): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150194: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Mean: (Mean): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Training_step: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150209: I tensorflow/core/common_runtime/placer.cc:114] Training_step: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Training_step/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150224: I tensorflow/core/common_runtime/placer.cc:114] Training_step/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Training_step/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150238: I tensorflow/core/common_runtime/placer.cc:114] Training_step/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Global_Step: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150253: I tensorflow/core/common_runtime/placer.cc:114] Global_Step: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Global_Step/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150268: I tensorflow/core/common_runtime/placer.cc:114] Global_Step/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Global_Step/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150282: I tensorflow/core/common_runtime/placer.cc:114] Global_Step/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Add: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150298: I tensorflow/core/common_runtime/placer.cc:114] Add: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Assign_2: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150313: I tensorflow/core/common_runtime/placer.cc:114] Assign_2: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "val_loss: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150364: I tensorflow/core/common_runtime/placer.cc:114] val_loss: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "val_loss/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150405: I tensorflow/core/common_runtime/placer.cc:114] val_loss/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "val_loss/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150420: I tensorflow/core/common_runtime/placer.cc:114] val_loss/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "val_acc: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150436: I tensorflow/core/common_runtime/placer.cc:114] val_acc: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "val_acc/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150452: I tensorflow/core/common_runtime/placer.cc:114] val_acc/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "val_acc/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150480: I tensorflow/core/common_runtime/placer.cc:114] val_acc/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "assign/val_loss: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150495: I tensorflow/core/common_runtime/placer.cc:114] assign/val_loss: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "assign/val_acc: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150525: I tensorflow/core/common_runtime/placer.cc:114] assign/val_acc: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Accuracy/Mean/moving_avg: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150571: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/Mean/moving_avg: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Accuracy/Mean/moving_avg/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150588: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/Mean/moving_avg/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Accuracy/Mean/moving_avg/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150603: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/Mean/moving_avg/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg/add: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150621: I tensorflow/core/common_runtime/placer.cc:114] moving_avg/add: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg/add_1: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150638: I tensorflow/core/common_runtime/placer.cc:114] moving_avg/add_1: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg/truediv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150656: I tensorflow/core/common_runtime/placer.cc:114] moving_avg/truediv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg/Minimum: (Minimum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.150673: I tensorflow/core/common_runtime/placer.cc:114] moving_avg/Minimum: (Minimum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg/AssignMovingAvg/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.212499: I tensorflow/core/common_runtime/placer.cc:114] moving_avg/AssignMovingAvg/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg/AssignMovingAvg/sub_1: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.212577: I tensorflow/core/common_runtime/placer.cc:114] moving_avg/AssignMovingAvg/sub_1: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg/AssignMovingAvg/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.212618: I tensorflow/core/common_runtime/placer.cc:114] moving_avg/AssignMovingAvg/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg/AssignMovingAvg: (AssignSub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.212634: I tensorflow/core/common_runtime/placer.cc:114] moving_avg/AssignMovingAvg: (AssignSub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.212653: I tensorflow/core/common_runtime/placer.cc:114] moving_avg: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/Total_Loss: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.212670: I tensorflow/core/common_runtime/placer.cc:114] Adam/Total_Loss: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Mean/moving_avg: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.212684: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Mean/moving_avg: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Mean/moving_avg/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.212702: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Mean/moving_avg/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Mean/moving_avg/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.212718: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Mean/moving_avg/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg/add: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.212736: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg/add: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg/add_1: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.212756: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg/add_1: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg/truediv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.212776: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg/truediv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg/Minimum: (Minimum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.212797: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg/Minimum: (Minimum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg/AssignMovingAvg/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.212831: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg/AssignMovingAvg/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg/AssignMovingAvg/sub_1: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.212852: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg/AssignMovingAvg/sub_1: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg/AssignMovingAvg/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.212886: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg/AssignMovingAvg/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg/AssignMovingAvg: (AssignSub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.212904: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg/AssignMovingAvg: (AssignSub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.212924: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Loss: (ScalarSummary): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.213533: I tensorflow/core/common_runtime/placer.cc:114] Loss: (ScalarSummary): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Adam/Loss/raw: (ScalarSummary): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.213582: I tensorflow/core/common_runtime/placer.cc:114] Adam/Loss/raw: (ScalarSummary): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Adam/gradients/grad_ys_0: (Fill): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.213649: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/grad_ys_0: (Fill): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.213677: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.213706: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Tile: (Tile): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.213732: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Tile: (Tile): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Shape_1: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.213773: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Shape_1: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Prod: (Prod): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.213800: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Prod: (Prod): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Prod_1: (Prod): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.213825: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Prod_1: (Prod): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Maximum: (Maximum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.213852: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Maximum: (Maximum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/floordiv: (FloorDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.213875: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/floordiv: (FloorDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Cast: (Cast): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.213901: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Cast: (Cast): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/truediv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.213941: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/truediv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Neg_grad/Neg: (Neg): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.213976: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Neg_grad/Neg: (Neg): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214004: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/add: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214030: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/add: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/mod: (FloorMod): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214053: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/mod: (FloorMod): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/range: (Range): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214075: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/range: (Range): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/ones: (Fill): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214097: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/ones: (Fill): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/DynamicStitch: (DynamicStitch): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214119: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/DynamicStitch: (DynamicStitch): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214144: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/BroadcastTo: (BroadcastTo): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214169: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/BroadcastTo: (BroadcastTo): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/mul_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214195: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/mul_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/mul_grad/Shape_1: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214234: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/mul_grad/Shape_1: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/mul_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214261: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/mul_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/mul_grad/Mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214287: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/mul_grad/Mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/mul_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214312: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/mul_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/mul_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214349: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/mul_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/mul_grad/Mul_1: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214367: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/mul_grad/Mul_1: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/mul_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214382: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/mul_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/mul_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214403: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/mul_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Log_grad/Reciprocal: (Reciprocal): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214430: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Log_grad/Reciprocal: (Reciprocal): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Log_grad/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214467: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Log_grad/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214497: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value_grad/zeros_like: (ZerosLike): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214524: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value_grad/zeros_like: (ZerosLike): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value_grad/GreaterEqual: (GreaterEqual): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214550: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value_grad/GreaterEqual: (GreaterEqual): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214581: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value_grad/SelectV2: (SelectV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214623: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value_grad/SelectV2: (SelectV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214661: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214689: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value_grad/SelectV2_1: (SelectV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214715: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value_grad/SelectV2_1: (SelectV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214741: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214767: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214809: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/zeros_like: (ZerosLike): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214850: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/zeros_like: (ZerosLike): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/LessEqual: (LessEqual): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214876: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/LessEqual: (LessEqual): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214902: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/SelectV2: (SelectV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.214959: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/SelectV2: (SelectV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215024: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215053: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/SelectV2_1: (SelectV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215080: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/SelectV2_1: (SelectV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215107: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215134: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/truediv_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215161: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/truediv_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/truediv_grad/Shape_1: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215189: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/truediv_grad/Shape_1: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/truediv_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215216: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/truediv_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/truediv_grad/RealDiv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215243: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/truediv_grad/RealDiv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/truediv_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215270: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/truediv_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/truediv_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215298: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/truediv_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/truediv_grad/Neg: (Neg): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215335: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/truediv_grad/Neg: (Neg): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/truediv_grad/RealDiv_1: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215367: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/truediv_grad/RealDiv_1: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/truediv_grad/RealDiv_2: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215394: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/truediv_grad/RealDiv_2: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/truediv_grad/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215421: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/truediv_grad/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/truediv_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215448: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/truediv_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/truediv_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215492: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/truediv_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215517: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_grad/BroadcastTo: (BroadcastTo): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215556: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_grad/BroadcastTo: (BroadcastTo): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/AddN: (AddN): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215601: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/AddN: (AddN): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected_2/Softmax_grad/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215622: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected_2/Softmax_grad/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected_2/Softmax_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215682: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected_2/Softmax_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected_2/Softmax_grad/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215710: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected_2/Softmax_grad/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected_2/Softmax_grad/mul_1: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215751: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected_2/Softmax_grad/mul_1: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected_2/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215778: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected_2/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected_2/MatMul_grad/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215804: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected_2/MatMul_grad/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected_2/MatMul_grad/MatMul_1: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215867: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected_2/MatMul_grad/MatMul_1: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected_1/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215895: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected_1/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected_1/MatMul_grad/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215922: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected_1/MatMul_grad/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected_1/MatMul_grad/MatMul_1: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215969: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected_1/MatMul_grad/MatMul_1: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.215998: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected/MatMul_grad/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216025: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected/MatMul_grad/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected/MatMul_grad/MatMul_1: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216053: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected/MatMul_grad/MatMul_1: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/global_norm/L2Loss: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216078: I tensorflow/core/common_runtime/placer.cc:114] Adam/global_norm/L2Loss: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/global_norm/L2Loss_1: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216103: I tensorflow/core/common_runtime/placer.cc:114] Adam/global_norm/L2Loss_1: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/global_norm/L2Loss_2: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216123: I tensorflow/core/common_runtime/placer.cc:114] Adam/global_norm/L2Loss_2: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/global_norm/L2Loss_3: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216164: I tensorflow/core/common_runtime/placer.cc:114] Adam/global_norm/L2Loss_3: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/global_norm/L2Loss_4: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216188: I tensorflow/core/common_runtime/placer.cc:114] Adam/global_norm/L2Loss_4: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/global_norm/L2Loss_5: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216212: I tensorflow/core/common_runtime/placer.cc:114] Adam/global_norm/L2Loss_5: (L2Loss): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/global_norm/stack: (Pack): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216238: I tensorflow/core/common_runtime/placer.cc:114] Adam/global_norm/stack: (Pack): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/global_norm/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216264: I tensorflow/core/common_runtime/placer.cc:114] Adam/global_norm/Sum: (Sum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/global_norm/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216289: I tensorflow/core/common_runtime/placer.cc:114] Adam/global_norm/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/global_norm/global_norm: (Sqrt): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216315: I tensorflow/core/common_runtime/placer.cc:114] Adam/global_norm/global_norm: (Sqrt): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/truediv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216368: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/truediv: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/truediv_1: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216396: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/truediv_1: (RealDiv): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/Minimum: (Minimum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216422: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/Minimum: (Minimum): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216451: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216478: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/add: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216505: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/add: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/mul_1: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216528: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/mul_1: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/Adam/clip_by_global_norm/_0: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216550: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/Adam/clip_by_global_norm/_0: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/mul_2: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216573: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/mul_2: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/Adam/clip_by_global_norm/_1: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216596: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/Adam/clip_by_global_norm/_1: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/mul_3: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216618: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/mul_3: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/Adam/clip_by_global_norm/_2: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216640: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/Adam/clip_by_global_norm/_2: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/mul_4: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216663: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/mul_4: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/Adam/clip_by_global_norm/_3: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216686: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/Adam/clip_by_global_norm/_3: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/mul_5: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216707: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/mul_5: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/Adam/clip_by_global_norm/_4: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216731: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/Adam/clip_by_global_norm/_4: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/mul_6: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216754: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/mul_6: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/Adam/clip_by_global_norm/_5: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216777: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/Adam/clip_by_global_norm/_5: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/beta1_power: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216800: I tensorflow/core/common_runtime/placer.cc:114] Adam/beta1_power: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/beta1_power/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216831: I tensorflow/core/common_runtime/placer.cc:114] Adam/beta1_power/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/beta1_power/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216854: I tensorflow/core/common_runtime/placer.cc:114] Adam/beta1_power/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/beta2_power: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216877: I tensorflow/core/common_runtime/placer.cc:114] Adam/beta2_power: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/beta2_power/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216899: I tensorflow/core/common_runtime/placer.cc:114] Adam/beta2_power/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/beta2_power/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216922: I tensorflow/core/common_runtime/placer.cc:114] Adam/beta2_power/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216944: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216972: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.216996: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217019: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217037: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217051: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/b/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217074: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/b/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/b/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217097: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/b/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/b/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217120: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/b/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/b/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217142: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/b/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/b/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217164: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/b/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/b/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217201: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/b/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217224: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Adam/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217246: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217268: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217294: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217316: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Adam_1/Initializer/zeros: (Fill): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217349: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217372: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217394: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/b/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217416: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/b/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/b/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217437: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/b/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/b/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217459: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/b/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/b/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217481: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/b/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/b/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217503: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/b/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/b/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217524: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/b/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217546: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217568: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217589: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217610: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217632: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217653: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/b/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217675: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/b/Adam: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/b/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217696: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/b/Adam/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/b/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217717: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/b/Adam/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/b/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217739: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/b/Adam_1: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/b/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217760: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/b/Adam_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/b/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217782: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/b/Adam_1/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/update_FullyConnected/W/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217804: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/update_FullyConnected/W/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/update_FullyConnected/b/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217826: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/update_FullyConnected/b/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/update_FullyConnected_1/W/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217850: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/update_FullyConnected_1/W/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/update_FullyConnected_1/b/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217872: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/update_FullyConnected_1/b/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/update_FullyConnected_2/W/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217894: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/update_FullyConnected_2/W/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/update_FullyConnected_2/b/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217915: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/update_FullyConnected_2/b/ApplyAdam: (ApplyAdam): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217937: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217959: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/mul_1: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.217986: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/mul_1: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/Assign_1: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218008: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/Assign_1: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/update: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218035: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/update: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0: (AssignAdd): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218058: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0: (AssignAdd): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/Merge/MergeSummary: (MergeSummary): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.218082: I tensorflow/core/common_runtime/placer.cc:114] Adam/Merge/MergeSummary: (MergeSummary): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Adam/train_op_0: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218109: I tensorflow/core/common_runtime/placer.cc:114] Adam/train_op_0: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/filename: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218135: I tensorflow/core/common_runtime/placer.cc:114] save/filename: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Const: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218160: I tensorflow/core/common_runtime/placer.cc:114] save/Const: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/SaveV2: (SaveV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.218185: I tensorflow/core/common_runtime/placer.cc:114] save/SaveV2: (SaveV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218209: I tensorflow/core/common_runtime/placer.cc:114] save/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/RestoreV2: (RestoreV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.218234: I tensorflow/core/common_runtime/placer.cc:114] save/RestoreV2: (RestoreV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218256: I tensorflow/core/common_runtime/placer.cc:114] save/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_1: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218278: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_1: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_2: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218299: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_2: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_3: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218329: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_3: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_4: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218353: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_4: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_5: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218374: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_5: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_6: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218406: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_6: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_7: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218427: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_7: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_8: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218448: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_8: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_9: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218467: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_9: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_10: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218489: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_10: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_11: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218510: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_11: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_12: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218532: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_12: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_13: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218553: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_13: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_14: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218574: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_14: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_15: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218596: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_15: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_16: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218617: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_16: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_17: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218638: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_17: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_18: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218659: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_18: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_19: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218684: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_19: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_20: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218705: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_20: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_21: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218727: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_21: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_22: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218748: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_22: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_23: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218769: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_23: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_24: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218796: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_24: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_25: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218818: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_25: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/Assign_26: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218840: I tensorflow/core/common_runtime/placer.cc:114] save/Assign_26: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/restore_all: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218865: I tensorflow/core/common_runtime/placer.cc:114] save/restore_all: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/filename: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218890: I tensorflow/core/common_runtime/placer.cc:114] save_1/filename: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Const: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218916: I tensorflow/core/common_runtime/placer.cc:114] save_1/Const: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/SaveV2: (SaveV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.218941: I tensorflow/core/common_runtime/placer.cc:114] save_1/SaveV2: (SaveV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_1/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.218968: I tensorflow/core/common_runtime/placer.cc:114] save_1/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/RestoreV2: (RestoreV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.218993: I tensorflow/core/common_runtime/placer.cc:114] save_1/RestoreV2: (RestoreV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219016: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_1: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219037: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_1: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_2: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219058: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_2: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_3: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219080: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_3: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_4: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219102: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_4: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_5: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219123: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_5: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_6: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219145: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_6: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_7: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219166: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_7: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_8: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219187: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_8: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_9: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219209: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_9: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_10: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219231: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_10: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_11: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219268: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_11: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_12: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219289: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_12: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_13: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219311: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_13: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_14: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219346: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_14: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_15: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219368: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_15: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_16: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219390: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_16: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_17: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219414: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_17: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_18: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219435: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_18: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_19: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219461: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_19: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_20: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219484: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_20: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_21: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219505: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_21: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_22: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219526: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_22: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_23: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219547: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_23: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_24: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219568: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_24: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_25: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219588: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_25: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/Assign_26: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219609: I tensorflow/core/common_runtime/placer.cc:114] save_1/Assign_26: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_1/restore_all: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219636: I tensorflow/core/common_runtime/placer.cc:114] save_1/restore_all: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_2/filename: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219661: I tensorflow/core/common_runtime/placer.cc:114] save_2/filename: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_2/Const: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219694: I tensorflow/core/common_runtime/placer.cc:114] save_2/Const: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_2/SaveV2: (SaveV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.219729: I tensorflow/core/common_runtime/placer.cc:114] save_2/SaveV2: (SaveV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_2/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219752: I tensorflow/core/common_runtime/placer.cc:114] save_2/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_2/RestoreV2: (RestoreV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.219775: I tensorflow/core/common_runtime/placer.cc:114] save_2/RestoreV2: (RestoreV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_2/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219797: I tensorflow/core/common_runtime/placer.cc:114] save_2/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_2/Assign_1: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219817: I tensorflow/core/common_runtime/placer.cc:114] save_2/Assign_1: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_2/Assign_2: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219838: I tensorflow/core/common_runtime/placer.cc:114] save_2/Assign_2: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_2/Assign_3: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219858: I tensorflow/core/common_runtime/placer.cc:114] save_2/Assign_3: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_2/Assign_4: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219879: I tensorflow/core/common_runtime/placer.cc:114] save_2/Assign_4: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_2/Assign_5: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219900: I tensorflow/core/common_runtime/placer.cc:114] save_2/Assign_5: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_2/restore_all: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219924: I tensorflow/core/common_runtime/placer.cc:114] save_2/restore_all: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "init: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219949: I tensorflow/core/common_runtime/placer.cc:114] init: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "init_1: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.219978: I tensorflow/core/common_runtime/placer.cc:114] init_1: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "group_deps: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220003: I tensorflow/core/common_runtime/placer.cc:114] group_deps: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "init_2: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220027: I tensorflow/core/common_runtime/placer.cc:114] init_2: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/filename: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220052: I tensorflow/core/common_runtime/placer.cc:114] save_3/filename: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Const: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220076: I tensorflow/core/common_runtime/placer.cc:114] save_3/Const: (PlaceholderWithDefault): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/SaveV2: (SaveV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.220100: I tensorflow/core/common_runtime/placer.cc:114] save_3/SaveV2: (SaveV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_3/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220123: I tensorflow/core/common_runtime/placer.cc:114] save_3/control_dependency: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/RestoreV2: (RestoreV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.220147: I tensorflow/core/common_runtime/placer.cc:114] save_3/RestoreV2: (RestoreV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_3/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220168: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_1: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220189: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_1: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_2: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220210: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_2: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_3: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220231: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_3: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_4: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220252: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_4: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_5: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220272: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_5: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_6: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220293: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_6: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_7: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220314: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_7: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_8: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220345: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_8: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_9: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220367: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_9: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_10: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220389: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_10: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_11: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220410: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_11: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_12: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220448: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_12: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_13: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220467: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_13: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_14: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220490: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_14: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_15: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220527: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_15: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_16: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220549: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_16: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_17: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220572: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_17: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_18: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220594: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_18: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_19: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220630: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_19: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_20: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220652: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_20: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_21: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220688: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_21: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_22: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220726: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_22: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_23: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220749: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_23: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_24: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220769: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_24: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_25: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220800: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_25: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/Assign_26: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220831: I tensorflow/core/common_runtime/placer.cc:114] save_3/Assign_26: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save_3/restore_all: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.220866: I tensorflow/core/common_runtime/placer.cc:114] save_3/restore_all: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Accuracy/__raw_: (ScalarSummary): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.220902: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/__raw_: (ScalarSummary): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Merge/MergeSummary: (MergeSummary): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.220925: I tensorflow/core/common_runtime/placer.cc:114] Merge/MergeSummary: (MergeSummary): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Accuracy: (ScalarSummary): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.220972: I tensorflow/core/common_runtime/placer.cc:114] Accuracy: (ScalarSummary): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Merge_1/MergeSummary: (MergeSummary): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.220995: I tensorflow/core/common_runtime/placer.cc:114] Merge_1/MergeSummary: (MergeSummary): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "is_training/Initializer/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.221017: I tensorflow/core/common_runtime/placer.cc:114] is_training/Initializer/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Assign/value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.221049: I tensorflow/core/common_runtime/placer.cc:114] Assign/value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Assign_1/value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.221072: I tensorflow/core/common_runtime/placer.cc:114] Assign_1/value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "InputData/X: (Placeholder): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.221095: I tensorflow/core/common_runtime/placer.cc:114] InputData/X: (Placeholder): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Initializer/truncated_normal/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.221114: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Initializer/truncated_normal/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Initializer/truncated_normal/mean: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.221134: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Initializer/truncated_normal/mean: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Initializer/truncated_normal/stddev: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.221152: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Initializer/truncated_normal/stddev: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/b/Initializer/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.221169: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/b/Initializer/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Initializer/truncated_normal/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.221184: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Initializer/truncated_normal/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Initializer/truncated_normal/mean: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.221197: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Initializer/truncated_normal/mean: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Initializer/truncated_normal/stddev: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.221210: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Initializer/truncated_normal/stddev: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/b/Initializer/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.221222: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/b/Initializer/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Initializer/truncated_normal/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.221242: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Initializer/truncated_normal/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Initializer/truncated_normal/mean: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.221254: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Initializer/truncated_normal/mean: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Initializer/truncated_normal/stddev: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.221277: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Initializer/truncated_normal/stddev: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/b/Initializer/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.221289: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/b/Initializer/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "TargetsData/Y: (Placeholder): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.221306: I tensorflow/core/common_runtime/placer.cc:114] TargetsData/Y: (Placeholder): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Accuracy/ArgMax/dimension: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.221340: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/ArgMax/dimension: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Accuracy/ArgMax_1/dimension: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.228971: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/ArgMax_1/dimension: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Accuracy/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229027: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Sum/reduction_indices: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229058: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Sum/reduction_indices: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Cast/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229085: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Cast/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Cast_1/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229116: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Cast_1/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Sum_1/reduction_indices: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229150: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Sum_1/reduction_indices: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229185: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Training_step/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229222: I tensorflow/core/common_runtime/placer.cc:114] Training_step/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Global_Step/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229264: I tensorflow/core/common_runtime/placer.cc:114] Global_Step/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Add/y: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229299: I tensorflow/core/common_runtime/placer.cc:114] Add/y: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "val_loss/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229354: I tensorflow/core/common_runtime/placer.cc:114] val_loss/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "val_acc/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229391: I tensorflow/core/common_runtime/placer.cc:114] val_acc/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "placeholder/val_loss: (Placeholder): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229427: I tensorflow/core/common_runtime/placer.cc:114] placeholder/val_loss: (Placeholder): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "placeholder/val_acc: (Placeholder): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229458: I tensorflow/core/common_runtime/placer.cc:114] placeholder/val_acc: (Placeholder): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Accuracy/Mean/moving_avg/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229515: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/Mean/moving_avg/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg/decay: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229549: I tensorflow/core/common_runtime/placer.cc:114] moving_avg/decay: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg/add/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229574: I tensorflow/core/common_runtime/placer.cc:114] moving_avg/add/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg/add_1/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229608: I tensorflow/core/common_runtime/placer.cc:114] moving_avg/add_1/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "moving_avg/AssignMovingAvg/sub/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229644: I tensorflow/core/common_runtime/placer.cc:114] moving_avg/AssignMovingAvg/sub/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Crossentropy/Mean/moving_avg/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229673: I tensorflow/core/common_runtime/placer.cc:114] Crossentropy/Mean/moving_avg/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg/decay: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229708: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg/decay: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg/add/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229739: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg/add/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg/add_1/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229764: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg/add_1/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/moving_avg/AssignMovingAvg/sub/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229792: I tensorflow/core/common_runtime/placer.cc:114] Adam/moving_avg/AssignMovingAvg/sub/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Loss/tags: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.229817: I tensorflow/core/common_runtime/placer.cc:114] Loss/tags: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Adam/Loss/raw/tags: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.229843: I tensorflow/core/common_runtime/placer.cc:114] Adam/Loss/raw/tags: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Adam/gradients/Shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229875: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/grad_ys_0/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229905: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/grad_ys_0/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Reshape/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229950: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Reshape/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Shape_2: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.229984: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Shape_2: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.230019: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Const_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.230054: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Const_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Mean_grad/Maximum/y: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.230089: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Mean_grad/Maximum/y: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/Size: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.230120: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/Size: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.230145: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/range/start: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.230164: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/range/start: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/range/delta: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.230180: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/range/delta: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/Sum_1_grad/ones/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.230228: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/Sum_1_grad/ones/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.230252: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.230292: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/Crossentropy/clip_by_value/Minimum_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/gradients/FullyConnected_2/Softmax_grad/Sum/reduction_indices: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.230362: I tensorflow/core/common_runtime/placer.cc:114] Adam/gradients/FullyConnected_2/Softmax_grad/Sum/reduction_indices: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/global_norm/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.230401: I tensorflow/core/common_runtime/placer.cc:114] Adam/global_norm/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/global_norm/Const_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.230439: I tensorflow/core/common_runtime/placer.cc:114] Adam/global_norm/Const_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/truediv/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.230486: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/truediv/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.230551: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/truediv_1/y: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.230584: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/truediv_1/y: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/clip_by_global_norm/mul/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.230612: I tensorflow/core/common_runtime/placer.cc:114] Adam/clip_by_global_norm/mul/x: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/beta1_power/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.230636: I tensorflow/core/common_runtime/placer.cc:114] Adam/beta1_power/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/beta2_power/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.230661: I tensorflow/core/common_runtime/placer.cc:114] Adam/beta2_power/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.230686: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/W/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.230705: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/W/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/b/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.231457: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/b/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected/b/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.231507: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected/b/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.231560: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Adam/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.231592: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Adam/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.231624: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Adam_1/Initializer/zeros/shape_as_tensor: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/W/Adam_1/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.231652: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/W/Adam_1/Initializer/zeros/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/b/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.231681: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/b/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_1/b/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.231708: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_1/b/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.231738: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/W/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.231770: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/W/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/b/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.231799: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/b/Adam/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "FullyConnected_2/b/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.231828: I tensorflow/core/common_runtime/placer.cc:114] FullyConnected_2/b/Adam_1/Initializer/zeros: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/learning_rate: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.231880: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/learning_rate: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/beta1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.231920: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/beta1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/beta2: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.231957: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/beta2: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/epsilon: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.231988: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/epsilon: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Adam/apply_grad_op_0/value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "2021-10-11 19:11:48.232011: I tensorflow/core/common_runtime/placer.cc:114] Adam/apply_grad_op_0/value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n",
            "save/filename/input: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.232038: I tensorflow/core/common_runtime/placer.cc:114] save/filename/input: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save/SaveV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.232062: I tensorflow/core/common_runtime/placer.cc:114] save/SaveV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save/SaveV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.232088: I tensorflow/core/common_runtime/placer.cc:114] save/SaveV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save/RestoreV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.232114: I tensorflow/core/common_runtime/placer.cc:114] save/RestoreV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save/RestoreV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.232141: I tensorflow/core/common_runtime/placer.cc:114] save/RestoreV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_1/filename/input: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.232172: I tensorflow/core/common_runtime/placer.cc:114] save_1/filename/input: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_1/SaveV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.232205: I tensorflow/core/common_runtime/placer.cc:114] save_1/SaveV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_1/SaveV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.232235: I tensorflow/core/common_runtime/placer.cc:114] save_1/SaveV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_1/RestoreV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.232270: I tensorflow/core/common_runtime/placer.cc:114] save_1/RestoreV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_1/RestoreV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.232305: I tensorflow/core/common_runtime/placer.cc:114] save_1/RestoreV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_2/filename/input: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.232357: I tensorflow/core/common_runtime/placer.cc:114] save_2/filename/input: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_2/SaveV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.232392: I tensorflow/core/common_runtime/placer.cc:114] save_2/SaveV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_2/SaveV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.232427: I tensorflow/core/common_runtime/placer.cc:114] save_2/SaveV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_2/RestoreV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.232469: I tensorflow/core/common_runtime/placer.cc:114] save_2/RestoreV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_2/RestoreV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.232504: I tensorflow/core/common_runtime/placer.cc:114] save_2/RestoreV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_3/filename/input: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.232538: I tensorflow/core/common_runtime/placer.cc:114] save_3/filename/input: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_3/SaveV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.232572: I tensorflow/core/common_runtime/placer.cc:114] save_3/SaveV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_3/SaveV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.232604: I tensorflow/core/common_runtime/placer.cc:114] save_3/SaveV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_3/RestoreV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.232638: I tensorflow/core/common_runtime/placer.cc:114] save_3/RestoreV2/tensor_names: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "save_3/RestoreV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.232673: I tensorflow/core/common_runtime/placer.cc:114] save_3/RestoreV2/shape_and_slices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Accuracy/__raw_/tags: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.232714: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/__raw_/tags: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Accuracy/tags: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "2021-10-11 19:11:48.232754: I tensorflow/core/common_runtime/placer.cc:114] Accuracy/tags: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Training Step: 1  | time: 0.472s\n",
            "| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/2300\n",
            "Training Step: 2  | total loss: \u001b[1m\u001b[32m1.02062\u001b[0m\u001b[0m | time: 0.476s\n",
            "| Adam | epoch: 001 | loss: 1.02062 - acc: 0.9000 -- iter: 0064/2300\n",
            "Training Step: 3  | total loss: \u001b[1m\u001b[32m1.17939\u001b[0m\u001b[0m | time: 0.480s\n",
            "| Adam | epoch: 001 | loss: 1.17939 - acc: 0.9818 -- iter: 0096/2300\n",
            "Training Step: 4  | total loss: \u001b[1m\u001b[32m1.15821\u001b[0m\u001b[0m | time: 0.484s\n",
            "| Adam | epoch: 001 | loss: 1.15821 - acc: 0.9955 -- iter: 0128/2300\n",
            "Training Step: 5  | total loss: \u001b[1m\u001b[32m1.17928\u001b[0m\u001b[0m | time: 0.487s\n",
            "| Adam | epoch: 001 | loss: 1.17928 - acc: 0.9986 -- iter: 0160/2300\n",
            "Training Step: 6  | total loss: \u001b[1m\u001b[32m1.20219\u001b[0m\u001b[0m | time: 0.491s\n",
            "| Adam | epoch: 001 | loss: 1.20219 - acc: 0.9995 -- iter: 0192/2300\n",
            "Training Step: 7  | total loss: \u001b[1m\u001b[32m1.15942\u001b[0m\u001b[0m | time: 0.496s\n",
            "| Adam | epoch: 001 | loss: 1.15942 - acc: 0.9998 -- iter: 0224/2300\n",
            "Training Step: 8  | total loss: \u001b[1m\u001b[32m1.12637\u001b[0m\u001b[0m | time: 0.499s\n",
            "| Adam | epoch: 001 | loss: 1.12637 - acc: 0.9999 -- iter: 0256/2300\n",
            "Training Step: 9  | total loss: \u001b[1m\u001b[32m1.13357\u001b[0m\u001b[0m | time: 0.503s\n",
            "| Adam | epoch: 001 | loss: 1.13357 - acc: 1.0000 -- iter: 0288/2300\n",
            "Training Step: 10  | total loss: \u001b[1m\u001b[32m1.14954\u001b[0m\u001b[0m | time: 0.508s\n",
            "| Adam | epoch: 001 | loss: 1.14954 - acc: 1.0000 -- iter: 0320/2300\n",
            "Training Step: 11  | total loss: \u001b[1m\u001b[32m1.14800\u001b[0m\u001b[0m | time: 0.512s\n",
            "| Adam | epoch: 001 | loss: 1.14800 - acc: 1.0000 -- iter: 0352/2300\n",
            "Training Step: 12  | total loss: \u001b[1m\u001b[32m1.14358\u001b[0m\u001b[0m | time: 0.516s\n",
            "| Adam | epoch: 001 | loss: 1.14358 - acc: 1.0000 -- iter: 0384/2300\n",
            "Training Step: 13  | total loss: \u001b[1m\u001b[32m1.13890\u001b[0m\u001b[0m | time: 0.520s\n",
            "| Adam | epoch: 001 | loss: 1.13890 - acc: 1.0000 -- iter: 0416/2300\n",
            "Training Step: 14  | total loss: \u001b[1m\u001b[32m1.14456\u001b[0m\u001b[0m | time: 0.523s\n",
            "| Adam | epoch: 001 | loss: 1.14456 - acc: 1.0000 -- iter: 0448/2300\n",
            "Training Step: 15  | total loss: \u001b[1m\u001b[32m1.13511\u001b[0m\u001b[0m | time: 0.527s\n",
            "| Adam | epoch: 001 | loss: 1.13511 - acc: 1.0000 -- iter: 0480/2300\n",
            "Training Step: 16  | total loss: \u001b[1m\u001b[32m1.14596\u001b[0m\u001b[0m | time: 0.531s\n",
            "| Adam | epoch: 001 | loss: 1.14596 - acc: 1.0000 -- iter: 0512/2300\n",
            "Training Step: 17  | total loss: \u001b[1m\u001b[32m1.13351\u001b[0m\u001b[0m | time: 0.534s\n",
            "| Adam | epoch: 001 | loss: 1.13351 - acc: 1.0000 -- iter: 0544/2300\n",
            "Training Step: 18  | total loss: \u001b[1m\u001b[32m1.13465\u001b[0m\u001b[0m | time: 0.538s\n",
            "| Adam | epoch: 001 | loss: 1.13465 - acc: 1.0000 -- iter: 0576/2300\n",
            "Training Step: 19  | total loss: \u001b[1m\u001b[32m1.14151\u001b[0m\u001b[0m | time: 0.541s\n",
            "| Adam | epoch: 001 | loss: 1.14151 - acc: 1.0000 -- iter: 0608/2300\n",
            "Training Step: 20  | total loss: \u001b[1m\u001b[32m1.15609\u001b[0m\u001b[0m | time: 0.545s\n",
            "| Adam | epoch: 001 | loss: 1.15609 - acc: 1.0000 -- iter: 0640/2300\n",
            "Training Step: 21  | total loss: \u001b[1m\u001b[32m1.15319\u001b[0m\u001b[0m | time: 0.548s\n",
            "| Adam | epoch: 001 | loss: 1.15319 - acc: 1.0000 -- iter: 0672/2300\n",
            "Training Step: 22  | total loss: \u001b[1m\u001b[32m1.15707\u001b[0m\u001b[0m | time: 0.552s\n",
            "| Adam | epoch: 001 | loss: 1.15707 - acc: 1.0000 -- iter: 0704/2300\n",
            "Training Step: 23  | total loss: \u001b[1m\u001b[32m1.14823\u001b[0m\u001b[0m | time: 0.555s\n",
            "| Adam | epoch: 001 | loss: 1.14823 - acc: 1.0000 -- iter: 0736/2300\n",
            "Training Step: 24  | total loss: \u001b[1m\u001b[32m1.16770\u001b[0m\u001b[0m | time: 0.559s\n",
            "| Adam | epoch: 001 | loss: 1.16770 - acc: 1.0000 -- iter: 0768/2300\n",
            "Training Step: 25  | total loss: \u001b[1m\u001b[32m1.15953\u001b[0m\u001b[0m | time: 0.563s\n",
            "| Adam | epoch: 001 | loss: 1.15953 - acc: 1.0000 -- iter: 0800/2300\n",
            "Training Step: 26  | total loss: \u001b[1m\u001b[32m1.14936\u001b[0m\u001b[0m | time: 0.567s\n",
            "| Adam | epoch: 001 | loss: 1.14936 - acc: 1.0000 -- iter: 0832/2300\n",
            "Training Step: 27  | total loss: \u001b[1m\u001b[32m1.15611\u001b[0m\u001b[0m | time: 0.571s\n",
            "| Adam | epoch: 001 | loss: 1.15611 - acc: 1.0000 -- iter: 0864/2300\n",
            "Training Step: 28  | total loss: \u001b[1m\u001b[32m1.14566\u001b[0m\u001b[0m | time: 0.574s\n",
            "| Adam | epoch: 001 | loss: 1.14566 - acc: 1.0000 -- iter: 0896/2300\n",
            "Training Step: 29  | total loss: \u001b[1m\u001b[32m1.14555\u001b[0m\u001b[0m | time: 0.578s\n",
            "| Adam | epoch: 001 | loss: 1.14555 - acc: 1.0000 -- iter: 0928/2300\n",
            "Training Step: 30  | total loss: \u001b[1m\u001b[32m1.15287\u001b[0m\u001b[0m | time: 0.581s\n",
            "| Adam | epoch: 001 | loss: 1.15287 - acc: 1.0000 -- iter: 0960/2300\n",
            "Training Step: 31  | total loss: \u001b[1m\u001b[32m1.16274\u001b[0m\u001b[0m | time: 0.585s\n",
            "| Adam | epoch: 001 | loss: 1.16274 - acc: 1.0000 -- iter: 0992/2300\n",
            "Training Step: 32  | total loss: \u001b[1m\u001b[32m1.17231\u001b[0m\u001b[0m | time: 0.588s\n",
            "| Adam | epoch: 001 | loss: 1.17231 - acc: 1.0000 -- iter: 1024/2300\n",
            "Training Step: 33  | total loss: \u001b[1m\u001b[32m1.16890\u001b[0m\u001b[0m | time: 0.592s\n",
            "| Adam | epoch: 001 | loss: 1.16890 - acc: 1.0000 -- iter: 1056/2300\n",
            "Training Step: 34  | total loss: \u001b[1m\u001b[32m1.16701\u001b[0m\u001b[0m | time: 0.596s\n",
            "| Adam | epoch: 001 | loss: 1.16701 - acc: 1.0000 -- iter: 1088/2300\n",
            "Training Step: 35  | total loss: \u001b[1m\u001b[32m1.16238\u001b[0m\u001b[0m | time: 0.599s\n",
            "| Adam | epoch: 001 | loss: 1.16238 - acc: 1.0000 -- iter: 1120/2300\n",
            "Training Step: 36  | total loss: \u001b[1m\u001b[32m1.17011\u001b[0m\u001b[0m | time: 0.603s\n",
            "| Adam | epoch: 001 | loss: 1.17011 - acc: 1.0000 -- iter: 1152/2300\n",
            "Training Step: 37  | total loss: \u001b[1m\u001b[32m1.16231\u001b[0m\u001b[0m | time: 0.606s\n",
            "| Adam | epoch: 001 | loss: 1.16231 - acc: 1.0000 -- iter: 1184/2300\n",
            "Training Step: 38  | total loss: \u001b[1m\u001b[32m1.15553\u001b[0m\u001b[0m | time: 0.610s\n",
            "| Adam | epoch: 001 | loss: 1.15553 - acc: 1.0000 -- iter: 1216/2300\n",
            "Training Step: 39  | total loss: \u001b[1m\u001b[32m1.15172\u001b[0m\u001b[0m | time: 0.614s\n",
            "| Adam | epoch: 001 | loss: 1.15172 - acc: 1.0000 -- iter: 1248/2300\n",
            "Training Step: 40  | total loss: \u001b[1m\u001b[32m1.15204\u001b[0m\u001b[0m | time: 0.617s\n",
            "| Adam | epoch: 001 | loss: 1.15204 - acc: 1.0000 -- iter: 1280/2300\n",
            "Training Step: 41  | total loss: \u001b[1m\u001b[32m1.15026\u001b[0m\u001b[0m | time: 0.620s\n",
            "| Adam | epoch: 001 | loss: 1.15026 - acc: 1.0000 -- iter: 1312/2300\n",
            "Training Step: 42  | total loss: \u001b[1m\u001b[32m1.14560\u001b[0m\u001b[0m | time: 0.624s\n",
            "| Adam | epoch: 001 | loss: 1.14560 - acc: 1.0000 -- iter: 1344/2300\n",
            "Training Step: 43  | total loss: \u001b[1m\u001b[32m1.14519\u001b[0m\u001b[0m | time: 0.627s\n",
            "| Adam | epoch: 001 | loss: 1.14519 - acc: 1.0000 -- iter: 1376/2300\n",
            "Training Step: 44  | total loss: \u001b[1m\u001b[32m1.15447\u001b[0m\u001b[0m | time: 0.630s\n",
            "| Adam | epoch: 001 | loss: 1.15447 - acc: 1.0000 -- iter: 1408/2300\n",
            "Training Step: 45  | total loss: \u001b[1m\u001b[32m1.15205\u001b[0m\u001b[0m | time: 0.634s\n",
            "| Adam | epoch: 001 | loss: 1.15205 - acc: 1.0000 -- iter: 1440/2300\n",
            "Training Step: 46  | total loss: \u001b[1m\u001b[32m1.14882\u001b[0m\u001b[0m | time: 0.637s\n",
            "| Adam | epoch: 001 | loss: 1.14882 - acc: 1.0000 -- iter: 1472/2300\n",
            "Training Step: 47  | total loss: \u001b[1m\u001b[32m1.14695\u001b[0m\u001b[0m | time: 0.641s\n",
            "| Adam | epoch: 001 | loss: 1.14695 - acc: 1.0000 -- iter: 1504/2300\n",
            "Training Step: 48  | total loss: \u001b[1m\u001b[32m1.14298\u001b[0m\u001b[0m | time: 0.644s\n",
            "| Adam | epoch: 001 | loss: 1.14298 - acc: 1.0000 -- iter: 1536/2300\n",
            "Training Step: 49  | total loss: \u001b[1m\u001b[32m1.13790\u001b[0m\u001b[0m | time: 0.647s\n",
            "| Adam | epoch: 001 | loss: 1.13790 - acc: 1.0000 -- iter: 1568/2300\n",
            "Training Step: 50  | total loss: \u001b[1m\u001b[32m1.13840\u001b[0m\u001b[0m | time: 0.651s\n",
            "| Adam | epoch: 001 | loss: 1.13840 - acc: 1.0000 -- iter: 1600/2300\n",
            "Training Step: 51  | total loss: \u001b[1m\u001b[32m1.14290\u001b[0m\u001b[0m | time: 0.655s\n",
            "| Adam | epoch: 001 | loss: 1.14290 - acc: 1.0000 -- iter: 1632/2300\n",
            "Training Step: 52  | total loss: \u001b[1m\u001b[32m1.14777\u001b[0m\u001b[0m | time: 0.658s\n",
            "| Adam | epoch: 001 | loss: 1.14777 - acc: 1.0000 -- iter: 1664/2300\n",
            "Training Step: 53  | total loss: \u001b[1m\u001b[32m1.15886\u001b[0m\u001b[0m | time: 0.662s\n",
            "| Adam | epoch: 001 | loss: 1.15886 - acc: 1.0000 -- iter: 1696/2300\n",
            "Training Step: 54  | total loss: \u001b[1m\u001b[32m1.15525\u001b[0m\u001b[0m | time: 0.665s\n",
            "| Adam | epoch: 001 | loss: 1.15525 - acc: 1.0000 -- iter: 1728/2300\n",
            "Training Step: 55  | total loss: \u001b[1m\u001b[32m1.14854\u001b[0m\u001b[0m | time: 0.670s\n",
            "| Adam | epoch: 001 | loss: 1.14854 - acc: 1.0000 -- iter: 1760/2300\n",
            "Training Step: 56  | total loss: \u001b[1m\u001b[32m1.14047\u001b[0m\u001b[0m | time: 0.674s\n",
            "| Adam | epoch: 001 | loss: 1.14047 - acc: 1.0000 -- iter: 1792/2300\n",
            "Training Step: 57  | total loss: \u001b[1m\u001b[32m1.13324\u001b[0m\u001b[0m | time: 0.678s\n",
            "| Adam | epoch: 001 | loss: 1.13324 - acc: 1.0000 -- iter: 1824/2300\n",
            "Training Step: 58  | total loss: \u001b[1m\u001b[32m1.14124\u001b[0m\u001b[0m | time: 0.681s\n",
            "| Adam | epoch: 001 | loss: 1.14124 - acc: 1.0000 -- iter: 1856/2300\n",
            "Training Step: 59  | total loss: \u001b[1m\u001b[32m1.13897\u001b[0m\u001b[0m | time: 0.684s\n",
            "| Adam | epoch: 001 | loss: 1.13897 - acc: 1.0000 -- iter: 1888/2300\n",
            "Training Step: 60  | total loss: \u001b[1m\u001b[32m1.12872\u001b[0m\u001b[0m | time: 0.688s\n",
            "| Adam | epoch: 001 | loss: 1.12872 - acc: 1.0000 -- iter: 1920/2300\n",
            "Training Step: 61  | total loss: \u001b[1m\u001b[32m1.12845\u001b[0m\u001b[0m | time: 0.692s\n",
            "| Adam | epoch: 001 | loss: 1.12845 - acc: 1.0000 -- iter: 1952/2300\n",
            "Training Step: 62  | total loss: \u001b[1m\u001b[32m1.13096\u001b[0m\u001b[0m | time: 0.701s\n",
            "| Adam | epoch: 001 | loss: 1.13096 - acc: 1.0000 -- iter: 1984/2300\n",
            "Training Step: 63  | total loss: \u001b[1m\u001b[32m1.13403\u001b[0m\u001b[0m | time: 0.706s\n",
            "| Adam | epoch: 001 | loss: 1.13403 - acc: 1.0000 -- iter: 2016/2300\n",
            "Training Step: 64  | total loss: \u001b[1m\u001b[32m1.13674\u001b[0m\u001b[0m | time: 0.711s\n",
            "| Adam | epoch: 001 | loss: 1.13674 - acc: 1.0000 -- iter: 2048/2300\n",
            "Training Step: 65  | total loss: \u001b[1m\u001b[32m1.13654\u001b[0m\u001b[0m | time: 0.715s\n",
            "| Adam | epoch: 001 | loss: 1.13654 - acc: 1.0000 -- iter: 2080/2300\n",
            "Training Step: 66  | total loss: \u001b[1m\u001b[32m1.13500\u001b[0m\u001b[0m | time: 0.719s\n",
            "| Adam | epoch: 001 | loss: 1.13500 - acc: 1.0000 -- iter: 2112/2300\n",
            "Training Step: 67  | total loss: \u001b[1m\u001b[32m1.13804\u001b[0m\u001b[0m | time: 0.723s\n",
            "| Adam | epoch: 001 | loss: 1.13804 - acc: 1.0000 -- iter: 2144/2300\n",
            "Training Step: 68  | total loss: \u001b[1m\u001b[32m1.14063\u001b[0m\u001b[0m | time: 0.728s\n",
            "| Adam | epoch: 001 | loss: 1.14063 - acc: 1.0000 -- iter: 2176/2300\n",
            "Training Step: 69  | total loss: \u001b[1m\u001b[32m1.14303\u001b[0m\u001b[0m | time: 0.732s\n",
            "| Adam | epoch: 001 | loss: 1.14303 - acc: 1.0000 -- iter: 2208/2300\n",
            "Training Step: 70  | total loss: \u001b[1m\u001b[32m1.14231\u001b[0m\u001b[0m | time: 0.735s\n",
            "| Adam | epoch: 001 | loss: 1.14231 - acc: 1.0000 -- iter: 2240/2300\n",
            "Training Step: 71  | total loss: \u001b[1m\u001b[32m1.13754\u001b[0m\u001b[0m | time: 0.740s\n",
            "| Adam | epoch: 001 | loss: 1.13754 - acc: 1.0000 -- iter: 2272/2300\n",
            "Training Step: 72  | total loss: \u001b[1m\u001b[32m1.13122\u001b[0m\u001b[0m | time: 0.743s\n",
            "| Adam | epoch: 001 | loss: 1.13122 - acc: 1.0000 -- iter: 2300/2300\n",
            "--\n",
            "Training Step: 73  | total loss: \u001b[1m\u001b[32m1.13438\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 002 | loss: 1.13438 - acc: 1.0000 -- iter: 0032/2300\n",
            "Training Step: 74  | total loss: \u001b[1m\u001b[32m1.13712\u001b[0m\u001b[0m | time: 0.007s\n",
            "| Adam | epoch: 002 | loss: 1.13712 - acc: 1.0000 -- iter: 0064/2300\n",
            "Training Step: 75  | total loss: \u001b[1m\u001b[32m1.13260\u001b[0m\u001b[0m | time: 0.010s\n",
            "| Adam | epoch: 002 | loss: 1.13260 - acc: 1.0000 -- iter: 0096/2300\n",
            "Training Step: 76  | total loss: \u001b[1m\u001b[32m1.13549\u001b[0m\u001b[0m | time: 0.014s\n",
            "| Adam | epoch: 002 | loss: 1.13549 - acc: 1.0000 -- iter: 0128/2300\n",
            "Training Step: 77  | total loss: \u001b[1m\u001b[32m1.14050\u001b[0m\u001b[0m | time: 0.018s\n",
            "| Adam | epoch: 002 | loss: 1.14050 - acc: 1.0000 -- iter: 0160/2300\n",
            "Training Step: 78  | total loss: \u001b[1m\u001b[32m1.14419\u001b[0m\u001b[0m | time: 0.022s\n",
            "| Adam | epoch: 002 | loss: 1.14419 - acc: 1.0000 -- iter: 0192/2300\n",
            "Training Step: 79  | total loss: \u001b[1m\u001b[32m1.14181\u001b[0m\u001b[0m | time: 0.026s\n",
            "| Adam | epoch: 002 | loss: 1.14181 - acc: 1.0000 -- iter: 0224/2300\n",
            "Training Step: 80  | total loss: \u001b[1m\u001b[32m1.14278\u001b[0m\u001b[0m | time: 0.030s\n",
            "| Adam | epoch: 002 | loss: 1.14278 - acc: 1.0000 -- iter: 0256/2300\n",
            "Training Step: 81  | total loss: \u001b[1m\u001b[32m1.13784\u001b[0m\u001b[0m | time: 0.033s\n",
            "| Adam | epoch: 002 | loss: 1.13784 - acc: 1.0000 -- iter: 0288/2300\n",
            "Training Step: 82  | total loss: \u001b[1m\u001b[32m1.13847\u001b[0m\u001b[0m | time: 0.037s\n",
            "| Adam | epoch: 002 | loss: 1.13847 - acc: 1.0000 -- iter: 0320/2300\n",
            "Training Step: 83  | total loss: \u001b[1m\u001b[32m1.13298\u001b[0m\u001b[0m | time: 0.041s\n",
            "| Adam | epoch: 002 | loss: 1.13298 - acc: 1.0000 -- iter: 0352/2300\n",
            "Training Step: 84  | total loss: \u001b[1m\u001b[32m1.14006\u001b[0m\u001b[0m | time: 0.044s\n",
            "| Adam | epoch: 002 | loss: 1.14006 - acc: 1.0000 -- iter: 0384/2300\n",
            "Training Step: 85  | total loss: \u001b[1m\u001b[32m1.13753\u001b[0m\u001b[0m | time: 0.048s\n",
            "| Adam | epoch: 002 | loss: 1.13753 - acc: 1.0000 -- iter: 0416/2300\n",
            "Training Step: 86  | total loss: \u001b[1m\u001b[32m1.13820\u001b[0m\u001b[0m | time: 0.051s\n",
            "| Adam | epoch: 002 | loss: 1.13820 - acc: 1.0000 -- iter: 0448/2300\n",
            "Training Step: 87  | total loss: \u001b[1m\u001b[32m1.13088\u001b[0m\u001b[0m | time: 0.054s\n",
            "| Adam | epoch: 002 | loss: 1.13088 - acc: 1.0000 -- iter: 0480/2300\n",
            "Training Step: 88  | total loss: \u001b[1m\u001b[32m1.13780\u001b[0m\u001b[0m | time: 0.058s\n",
            "| Adam | epoch: 002 | loss: 1.13780 - acc: 1.0000 -- iter: 0512/2300\n",
            "Training Step: 89  | total loss: \u001b[1m\u001b[32m1.13692\u001b[0m\u001b[0m | time: 0.061s\n",
            "| Adam | epoch: 002 | loss: 1.13692 - acc: 1.0000 -- iter: 0544/2300\n",
            "Training Step: 90  | total loss: \u001b[1m\u001b[32m1.13580\u001b[0m\u001b[0m | time: 0.065s\n",
            "| Adam | epoch: 002 | loss: 1.13580 - acc: 1.0000 -- iter: 0576/2300\n",
            "Training Step: 91  | total loss: \u001b[1m\u001b[32m1.12795\u001b[0m\u001b[0m | time: 0.068s\n",
            "| Adam | epoch: 002 | loss: 1.12795 - acc: 1.0000 -- iter: 0608/2300\n",
            "Training Step: 92  | total loss: \u001b[1m\u001b[32m1.13166\u001b[0m\u001b[0m | time: 0.071s\n",
            "| Adam | epoch: 002 | loss: 1.13166 - acc: 1.0000 -- iter: 0640/2300\n",
            "Training Step: 93  | total loss: \u001b[1m\u001b[32m1.12298\u001b[0m\u001b[0m | time: 0.075s\n",
            "| Adam | epoch: 002 | loss: 1.12298 - acc: 1.0000 -- iter: 0672/2300\n",
            "Training Step: 94  | total loss: \u001b[1m\u001b[32m1.12257\u001b[0m\u001b[0m | time: 0.078s\n",
            "| Adam | epoch: 002 | loss: 1.12257 - acc: 1.0000 -- iter: 0704/2300\n",
            "Training Step: 95  | total loss: \u001b[1m\u001b[32m1.12032\u001b[0m\u001b[0m | time: 0.082s\n",
            "| Adam | epoch: 002 | loss: 1.12032 - acc: 1.0000 -- iter: 0736/2300\n",
            "Training Step: 96  | total loss: \u001b[1m\u001b[32m1.11626\u001b[0m\u001b[0m | time: 0.085s\n",
            "| Adam | epoch: 002 | loss: 1.11626 - acc: 1.0000 -- iter: 0768/2300\n",
            "Training Step: 97  | total loss: \u001b[1m\u001b[32m1.11324\u001b[0m\u001b[0m | time: 0.089s\n",
            "| Adam | epoch: 002 | loss: 1.11324 - acc: 1.0000 -- iter: 0800/2300\n",
            "Training Step: 98  | total loss: \u001b[1m\u001b[32m1.11656\u001b[0m\u001b[0m | time: 0.092s\n",
            "| Adam | epoch: 002 | loss: 1.11656 - acc: 1.0000 -- iter: 0832/2300\n",
            "Training Step: 99  | total loss: \u001b[1m\u001b[32m1.11806\u001b[0m\u001b[0m | time: 0.096s\n",
            "| Adam | epoch: 002 | loss: 1.11806 - acc: 0.9969 -- iter: 0864/2300\n",
            "Training Step: 100  | total loss: \u001b[1m\u001b[32m1.11888\u001b[0m\u001b[0m | time: 0.099s\n",
            "| Adam | epoch: 002 | loss: 1.11888 - acc: 0.9784 -- iter: 0896/2300\n",
            "Training Step: 101  | total loss: \u001b[1m\u001b[32m1.12095\u001b[0m\u001b[0m | time: 0.103s\n",
            "| Adam | epoch: 002 | loss: 1.12095 - acc: 0.9743 -- iter: 0928/2300\n",
            "Training Step: 102  | total loss: \u001b[1m\u001b[32m1.12631\u001b[0m\u001b[0m | time: 0.106s\n",
            "| Adam | epoch: 002 | loss: 1.12631 - acc: 0.9675 -- iter: 0960/2300\n",
            "Training Step: 103  | total loss: \u001b[1m\u001b[32m1.12982\u001b[0m\u001b[0m | time: 0.110s\n",
            "| Adam | epoch: 002 | loss: 1.12982 - acc: 0.9677 -- iter: 0992/2300\n",
            "Training Step: 104  | total loss: \u001b[1m\u001b[32m1.13040\u001b[0m\u001b[0m | time: 0.113s\n",
            "| Adam | epoch: 002 | loss: 1.13040 - acc: 0.9678 -- iter: 1024/2300\n",
            "Training Step: 105  | total loss: \u001b[1m\u001b[32m1.12508\u001b[0m\u001b[0m | time: 0.117s\n",
            "| Adam | epoch: 002 | loss: 1.12508 - acc: 0.9647 -- iter: 1056/2300\n",
            "Training Step: 106  | total loss: \u001b[1m\u001b[32m1.11543\u001b[0m\u001b[0m | time: 0.120s\n",
            "| Adam | epoch: 002 | loss: 1.11543 - acc: 0.9651 -- iter: 1088/2300\n",
            "Training Step: 107  | total loss: \u001b[1m\u001b[32m1.10744\u001b[0m\u001b[0m | time: 0.123s\n",
            "| Adam | epoch: 002 | loss: 1.10744 - acc: 0.9655 -- iter: 1120/2300\n",
            "Training Step: 108  | total loss: \u001b[1m\u001b[32m1.11262\u001b[0m\u001b[0m | time: 0.126s\n",
            "| Adam | epoch: 002 | loss: 1.11262 - acc: 0.9533 -- iter: 1152/2300\n",
            "Training Step: 109  | total loss: \u001b[1m\u001b[32m1.11162\u001b[0m\u001b[0m | time: 0.130s\n",
            "| Adam | epoch: 002 | loss: 1.11162 - acc: 0.9517 -- iter: 1184/2300\n",
            "Training Step: 110  | total loss: \u001b[1m\u001b[32m1.11432\u001b[0m\u001b[0m | time: 0.135s\n",
            "| Adam | epoch: 002 | loss: 1.11432 - acc: 0.9503 -- iter: 1216/2300\n",
            "Training Step: 111  | total loss: \u001b[1m\u001b[32m1.10958\u001b[0m\u001b[0m | time: 0.139s\n",
            "| Adam | epoch: 002 | loss: 1.10958 - acc: 0.9522 -- iter: 1248/2300\n",
            "Training Step: 112  | total loss: \u001b[1m\u001b[32m1.10984\u001b[0m\u001b[0m | time: 0.143s\n",
            "| Adam | epoch: 002 | loss: 1.10984 - acc: 0.9413 -- iter: 1280/2300\n",
            "Training Step: 113  | total loss: \u001b[1m\u001b[32m1.10488\u001b[0m\u001b[0m | time: 0.146s\n",
            "| Adam | epoch: 002 | loss: 1.10488 - acc: 0.9316 -- iter: 1312/2300\n",
            "Training Step: 114  | total loss: \u001b[1m\u001b[32m1.11145\u001b[0m\u001b[0m | time: 0.150s\n",
            "| Adam | epoch: 002 | loss: 1.11145 - acc: 0.9228 -- iter: 1344/2300\n",
            "Training Step: 115  | total loss: \u001b[1m\u001b[32m1.11904\u001b[0m\u001b[0m | time: 0.154s\n",
            "| Adam | epoch: 002 | loss: 1.11904 - acc: 0.9211 -- iter: 1376/2300\n",
            "Training Step: 116  | total loss: \u001b[1m\u001b[32m1.11472\u001b[0m\u001b[0m | time: 0.158s\n",
            "| Adam | epoch: 002 | loss: 1.11472 - acc: 0.9228 -- iter: 1408/2300\n",
            "Training Step: 117  | total loss: \u001b[1m\u001b[32m1.10804\u001b[0m\u001b[0m | time: 0.162s\n",
            "| Adam | epoch: 002 | loss: 1.10804 - acc: 0.9242 -- iter: 1440/2300\n",
            "Training Step: 118  | total loss: \u001b[1m\u001b[32m1.11472\u001b[0m\u001b[0m | time: 0.166s\n",
            "| Adam | epoch: 002 | loss: 1.11472 - acc: 0.9099 -- iter: 1472/2300\n",
            "Training Step: 119  | total loss: \u001b[1m\u001b[32m1.12284\u001b[0m\u001b[0m | time: 0.170s\n",
            "| Adam | epoch: 002 | loss: 1.12284 - acc: 0.9033 -- iter: 1504/2300\n",
            "Training Step: 120  | total loss: \u001b[1m\u001b[32m1.11767\u001b[0m\u001b[0m | time: 0.174s\n",
            "| Adam | epoch: 002 | loss: 1.11767 - acc: 0.9036 -- iter: 1536/2300\n",
            "Training Step: 121  | total loss: \u001b[1m\u001b[32m1.11214\u001b[0m\u001b[0m | time: 0.177s\n",
            "| Adam | epoch: 002 | loss: 1.11214 - acc: 0.9101 -- iter: 1568/2300\n",
            "Training Step: 122  | total loss: \u001b[1m\u001b[32m1.11269\u001b[0m\u001b[0m | time: 0.181s\n",
            "| Adam | epoch: 002 | loss: 1.11269 - acc: 0.9191 -- iter: 1600/2300\n",
            "Training Step: 123  | total loss: \u001b[1m\u001b[32m1.11159\u001b[0m\u001b[0m | time: 0.185s\n",
            "| Adam | epoch: 002 | loss: 1.11159 - acc: 0.8960 -- iter: 1632/2300\n",
            "Training Step: 124  | total loss: \u001b[1m\u001b[32m1.12588\u001b[0m\u001b[0m | time: 0.189s\n",
            "| Adam | epoch: 002 | loss: 1.12588 - acc: 0.8845 -- iter: 1664/2300\n",
            "Training Step: 125  | total loss: \u001b[1m\u001b[32m1.12629\u001b[0m\u001b[0m | time: 0.193s\n",
            "| Adam | epoch: 002 | loss: 1.12629 - acc: 0.8867 -- iter: 1696/2300\n",
            "Training Step: 126  | total loss: \u001b[1m\u001b[32m1.11880\u001b[0m\u001b[0m | time: 0.196s\n",
            "| Adam | epoch: 002 | loss: 1.11880 - acc: 0.8886 -- iter: 1728/2300\n",
            "Training Step: 127  | total loss: \u001b[1m\u001b[32m1.12423\u001b[0m\u001b[0m | time: 0.200s\n",
            "| Adam | epoch: 002 | loss: 1.12423 - acc: 0.8873 -- iter: 1760/2300\n",
            "Training Step: 128  | total loss: \u001b[1m\u001b[32m1.11762\u001b[0m\u001b[0m | time: 0.203s\n",
            "| Adam | epoch: 002 | loss: 1.11762 - acc: 0.8954 -- iter: 1792/2300\n",
            "Training Step: 129  | total loss: \u001b[1m\u001b[32m1.10682\u001b[0m\u001b[0m | time: 0.207s\n",
            "| Adam | epoch: 002 | loss: 1.10682 - acc: 0.8965 -- iter: 1824/2300\n",
            "Training Step: 130  | total loss: \u001b[1m\u001b[32m1.11287\u001b[0m\u001b[0m | time: 0.211s\n",
            "| Adam | epoch: 002 | loss: 1.11287 - acc: 0.9037 -- iter: 1856/2300\n",
            "Training Step: 131  | total loss: \u001b[1m\u001b[32m1.12214\u001b[0m\u001b[0m | time: 0.214s\n",
            "| Adam | epoch: 002 | loss: 1.12214 - acc: 0.9008 -- iter: 1888/2300\n",
            "Training Step: 132  | total loss: \u001b[1m\u001b[32m1.11207\u001b[0m\u001b[0m | time: 0.218s\n",
            "| Adam | epoch: 002 | loss: 1.11207 - acc: 0.8951 -- iter: 1920/2300\n",
            "Training Step: 133  | total loss: \u001b[1m\u001b[32m1.10445\u001b[0m\u001b[0m | time: 0.222s\n",
            "| Adam | epoch: 002 | loss: 1.10445 - acc: 0.8994 -- iter: 1952/2300\n",
            "Training Step: 134  | total loss: \u001b[1m\u001b[32m1.10524\u001b[0m\u001b[0m | time: 0.225s\n",
            "| Adam | epoch: 002 | loss: 1.10524 - acc: 0.8969 -- iter: 1984/2300\n",
            "Training Step: 135  | total loss: \u001b[1m\u001b[32m1.10635\u001b[0m\u001b[0m | time: 0.229s\n",
            "| Adam | epoch: 002 | loss: 1.10635 - acc: 0.8979 -- iter: 2016/2300\n",
            "Training Step: 136  | total loss: \u001b[1m\u001b[32m1.10546\u001b[0m\u001b[0m | time: 0.232s\n",
            "| Adam | epoch: 002 | loss: 1.10546 - acc: 0.8925 -- iter: 2048/2300\n",
            "Training Step: 137  | total loss: \u001b[1m\u001b[32m1.10627\u001b[0m\u001b[0m | time: 0.236s\n",
            "| Adam | epoch: 002 | loss: 1.10627 - acc: 0.9001 -- iter: 2080/2300\n",
            "Training Step: 138  | total loss: \u001b[1m\u001b[32m1.10791\u001b[0m\u001b[0m | time: 0.239s\n",
            "| Adam | epoch: 002 | loss: 1.10791 - acc: 0.9007 -- iter: 2112/2300\n",
            "Training Step: 139  | total loss: \u001b[1m\u001b[32m1.10759\u001b[0m\u001b[0m | time: 0.243s\n",
            "| Adam | epoch: 002 | loss: 1.10759 - acc: 0.9044 -- iter: 2144/2300\n",
            "Training Step: 140  | total loss: \u001b[1m\u001b[32m1.11308\u001b[0m\u001b[0m | time: 0.247s\n",
            "| Adam | epoch: 002 | loss: 1.11308 - acc: 0.9077 -- iter: 2176/2300\n",
            "Training Step: 141  | total loss: \u001b[1m\u001b[32m1.11294\u001b[0m\u001b[0m | time: 0.251s\n",
            "| Adam | epoch: 002 | loss: 1.11294 - acc: 0.9107 -- iter: 2208/2300\n",
            "Training Step: 142  | total loss: \u001b[1m\u001b[32m1.11275\u001b[0m\u001b[0m | time: 0.254s\n",
            "| Adam | epoch: 002 | loss: 1.11275 - acc: 0.9134 -- iter: 2240/2300\n",
            "Training Step: 143  | total loss: \u001b[1m\u001b[32m1.11813\u001b[0m\u001b[0m | time: 0.257s\n",
            "| Adam | epoch: 002 | loss: 1.11813 - acc: 0.9095 -- iter: 2272/2300\n",
            "Training Step: 144  | total loss: \u001b[1m\u001b[32m1.12201\u001b[0m\u001b[0m | time: 0.261s\n",
            "| Adam | epoch: 002 | loss: 1.12201 - acc: 0.8967 -- iter: 2300/2300\n",
            "--\n",
            "Training Step: 145  | total loss: \u001b[1m\u001b[32m1.12459\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 003 | loss: 1.12459 - acc: 0.9008 -- iter: 0032/2300\n",
            "Training Step: 146  | total loss: \u001b[1m\u001b[32m1.12436\u001b[0m\u001b[0m | time: 0.007s\n",
            "| Adam | epoch: 003 | loss: 1.12436 - acc: 0.8928 -- iter: 0064/2300\n",
            "Training Step: 147  | total loss: \u001b[1m\u001b[32m1.12402\u001b[0m\u001b[0m | time: 0.010s\n",
            "| Adam | epoch: 003 | loss: 1.12402 - acc: 0.8857 -- iter: 0096/2300\n",
            "Training Step: 148  | total loss: \u001b[1m\u001b[32m1.11852\u001b[0m\u001b[0m | time: 0.014s\n",
            "| Adam | epoch: 003 | loss: 1.11852 - acc: 0.8909 -- iter: 0128/2300\n",
            "Training Step: 149  | total loss: \u001b[1m\u001b[32m1.11804\u001b[0m\u001b[0m | time: 0.018s\n",
            "| Adam | epoch: 003 | loss: 1.11804 - acc: 0.8955 -- iter: 0160/2300\n",
            "Training Step: 150  | total loss: \u001b[1m\u001b[32m1.12663\u001b[0m\u001b[0m | time: 0.022s\n",
            "| Adam | epoch: 003 | loss: 1.12663 - acc: 0.8966 -- iter: 0192/2300\n",
            "Training Step: 151  | total loss: \u001b[1m\u001b[32m1.12811\u001b[0m\u001b[0m | time: 0.025s\n",
            "| Adam | epoch: 003 | loss: 1.12811 - acc: 0.9007 -- iter: 0224/2300\n",
            "Training Step: 152  | total loss: \u001b[1m\u001b[32m1.12533\u001b[0m\u001b[0m | time: 0.029s\n",
            "| Adam | epoch: 003 | loss: 1.12533 - acc: 0.9044 -- iter: 0256/2300\n",
            "Training Step: 153  | total loss: \u001b[1m\u001b[32m1.12736\u001b[0m\u001b[0m | time: 0.032s\n",
            "| Adam | epoch: 003 | loss: 1.12736 - acc: 0.8952 -- iter: 0288/2300\n",
            "Training Step: 154  | total loss: \u001b[1m\u001b[32m1.12689\u001b[0m\u001b[0m | time: 0.036s\n",
            "| Adam | epoch: 003 | loss: 1.12689 - acc: 0.8838 -- iter: 0320/2300\n",
            "Training Step: 155  | total loss: \u001b[1m\u001b[32m1.11336\u001b[0m\u001b[0m | time: 0.040s\n",
            "| Adam | epoch: 003 | loss: 1.11336 - acc: 0.8829 -- iter: 0352/2300\n",
            "Training Step: 156  | total loss: \u001b[1m\u001b[32m1.11457\u001b[0m\u001b[0m | time: 0.043s\n",
            "| Adam | epoch: 003 | loss: 1.11457 - acc: 0.8790 -- iter: 0384/2300\n",
            "Training Step: 157  | total loss: \u001b[1m\u001b[32m1.11031\u001b[0m\u001b[0m | time: 0.047s\n",
            "| Adam | epoch: 003 | loss: 1.11031 - acc: 0.8849 -- iter: 0416/2300\n",
            "Training Step: 158  | total loss: \u001b[1m\u001b[32m1.10044\u001b[0m\u001b[0m | time: 0.050s\n",
            "| Adam | epoch: 003 | loss: 1.10044 - acc: 0.8870 -- iter: 0448/2300\n",
            "Training Step: 159  | total loss: \u001b[1m\u001b[32m1.10885\u001b[0m\u001b[0m | time: 0.054s\n",
            "| Adam | epoch: 003 | loss: 1.10885 - acc: 0.8858 -- iter: 0480/2300\n",
            "Training Step: 160  | total loss: \u001b[1m\u001b[32m1.10897\u001b[0m\u001b[0m | time: 0.058s\n",
            "| Adam | epoch: 003 | loss: 1.10897 - acc: 0.8878 -- iter: 0512/2300\n",
            "Training Step: 161  | total loss: \u001b[1m\u001b[32m1.11661\u001b[0m\u001b[0m | time: 0.062s\n",
            "| Adam | epoch: 003 | loss: 1.11661 - acc: 0.8866 -- iter: 0544/2300\n",
            "Training Step: 162  | total loss: \u001b[1m\u001b[32m1.11255\u001b[0m\u001b[0m | time: 0.066s\n",
            "| Adam | epoch: 003 | loss: 1.11255 - acc: 0.8916 -- iter: 0576/2300\n",
            "Training Step: 163  | total loss: \u001b[1m\u001b[32m1.11501\u001b[0m\u001b[0m | time: 0.070s\n",
            "| Adam | epoch: 003 | loss: 1.11501 - acc: 0.8962 -- iter: 0608/2300\n",
            "Training Step: 164  | total loss: \u001b[1m\u001b[32m1.11379\u001b[0m\u001b[0m | time: 0.074s\n",
            "| Adam | epoch: 003 | loss: 1.11379 - acc: 0.9035 -- iter: 0640/2300\n",
            "Training Step: 165  | total loss: \u001b[1m\u001b[32m1.11153\u001b[0m\u001b[0m | time: 0.078s\n",
            "| Adam | epoch: 003 | loss: 1.11153 - acc: 0.9069 -- iter: 0672/2300\n",
            "Training Step: 166  | total loss: \u001b[1m\u001b[32m1.11189\u001b[0m\u001b[0m | time: 0.081s\n",
            "| Adam | epoch: 003 | loss: 1.11189 - acc: 0.8943 -- iter: 0704/2300\n",
            "Training Step: 167  | total loss: \u001b[1m\u001b[32m1.11270\u001b[0m\u001b[0m | time: 0.085s\n",
            "| Adam | epoch: 003 | loss: 1.11270 - acc: 0.8955 -- iter: 0736/2300\n",
            "Training Step: 168  | total loss: \u001b[1m\u001b[32m1.10187\u001b[0m\u001b[0m | time: 0.088s\n",
            "| Adam | epoch: 003 | loss: 1.10187 - acc: 0.8935 -- iter: 0768/2300\n",
            "Training Step: 169  | total loss: \u001b[1m\u001b[32m1.10086\u001b[0m\u001b[0m | time: 0.092s\n",
            "| Adam | epoch: 003 | loss: 1.10086 - acc: 0.8885 -- iter: 0800/2300\n",
            "Training Step: 170  | total loss: \u001b[1m\u001b[32m1.09392\u001b[0m\u001b[0m | time: 0.096s\n",
            "| Adam | epoch: 003 | loss: 1.09392 - acc: 0.8965 -- iter: 0832/2300\n",
            "Training Step: 171  | total loss: \u001b[1m\u001b[32m1.09739\u001b[0m\u001b[0m | time: 0.100s\n",
            "| Adam | epoch: 003 | loss: 1.09739 - acc: 0.8975 -- iter: 0864/2300\n",
            "Training Step: 172  | total loss: \u001b[1m\u001b[32m1.09960\u001b[0m\u001b[0m | time: 0.103s\n",
            "| Adam | epoch: 003 | loss: 1.09960 - acc: 0.8984 -- iter: 0896/2300\n",
            "Training Step: 173  | total loss: \u001b[1m\u001b[32m1.10243\u001b[0m\u001b[0m | time: 0.106s\n",
            "| Adam | epoch: 003 | loss: 1.10243 - acc: 0.9085 -- iter: 0928/2300\n",
            "Training Step: 174  | total loss: \u001b[1m\u001b[32m1.09364\u001b[0m\u001b[0m | time: 0.110s\n",
            "| Adam | epoch: 003 | loss: 1.09364 - acc: 0.9114 -- iter: 0960/2300\n",
            "Training Step: 175  | total loss: \u001b[1m\u001b[32m1.09893\u001b[0m\u001b[0m | time: 0.113s\n",
            "| Adam | epoch: 003 | loss: 1.09893 - acc: 0.9140 -- iter: 0992/2300\n",
            "Training Step: 176  | total loss: \u001b[1m\u001b[32m1.10605\u001b[0m\u001b[0m | time: 0.117s\n",
            "| Adam | epoch: 003 | loss: 1.10605 - acc: 0.9133 -- iter: 1024/2300\n",
            "Training Step: 177  | total loss: \u001b[1m\u001b[32m1.10192\u001b[0m\u001b[0m | time: 0.121s\n",
            "| Adam | epoch: 003 | loss: 1.10192 - acc: 0.9032 -- iter: 1056/2300\n",
            "Training Step: 178  | total loss: \u001b[1m\u001b[32m1.10577\u001b[0m\u001b[0m | time: 0.124s\n",
            "| Adam | epoch: 003 | loss: 1.10577 - acc: 0.9035 -- iter: 1088/2300\n",
            "Training Step: 179  | total loss: \u001b[1m\u001b[32m1.10922\u001b[0m\u001b[0m | time: 0.128s\n",
            "| Adam | epoch: 003 | loss: 1.10922 - acc: 0.9006 -- iter: 1120/2300\n",
            "Training Step: 180  | total loss: \u001b[1m\u001b[32m1.10127\u001b[0m\u001b[0m | time: 0.132s\n",
            "| Adam | epoch: 003 | loss: 1.10127 - acc: 0.9106 -- iter: 1152/2300\n",
            "Training Step: 181  | total loss: \u001b[1m\u001b[32m1.10604\u001b[0m\u001b[0m | time: 0.135s\n",
            "| Adam | epoch: 003 | loss: 1.10604 - acc: 0.9008 -- iter: 1184/2300\n",
            "Training Step: 182  | total loss: \u001b[1m\u001b[32m1.09394\u001b[0m\u001b[0m | time: 0.139s\n",
            "| Adam | epoch: 003 | loss: 1.09394 - acc: 0.9076 -- iter: 1216/2300\n",
            "Training Step: 183  | total loss: \u001b[1m\u001b[32m1.08985\u001b[0m\u001b[0m | time: 0.142s\n",
            "| Adam | epoch: 003 | loss: 1.08985 - acc: 0.9043 -- iter: 1248/2300\n",
            "Training Step: 184  | total loss: \u001b[1m\u001b[32m1.08814\u001b[0m\u001b[0m | time: 0.146s\n",
            "| Adam | epoch: 003 | loss: 1.08814 - acc: 0.8951 -- iter: 1280/2300\n",
            "Training Step: 185  | total loss: \u001b[1m\u001b[32m1.08959\u001b[0m\u001b[0m | time: 0.149s\n",
            "| Adam | epoch: 003 | loss: 1.08959 - acc: 0.9056 -- iter: 1312/2300\n",
            "Training Step: 186  | total loss: \u001b[1m\u001b[32m1.08344\u001b[0m\u001b[0m | time: 0.153s\n",
            "| Adam | epoch: 003 | loss: 1.08344 - acc: 0.9057 -- iter: 1344/2300\n",
            "Training Step: 187  | total loss: \u001b[1m\u001b[32m1.08206\u001b[0m\u001b[0m | time: 0.156s\n",
            "| Adam | epoch: 003 | loss: 1.08206 - acc: 0.8995 -- iter: 1376/2300\n",
            "Training Step: 188  | total loss: \u001b[1m\u001b[32m1.08278\u001b[0m\u001b[0m | time: 0.160s\n",
            "| Adam | epoch: 003 | loss: 1.08278 - acc: 0.9033 -- iter: 1408/2300\n",
            "Training Step: 189  | total loss: \u001b[1m\u001b[32m1.08266\u001b[0m\u001b[0m | time: 0.163s\n",
            "| Adam | epoch: 003 | loss: 1.08266 - acc: 0.9036 -- iter: 1440/2300\n",
            "Training Step: 190  | total loss: \u001b[1m\u001b[32m1.09133\u001b[0m\u001b[0m | time: 0.167s\n",
            "| Adam | epoch: 003 | loss: 1.09133 - acc: 0.9070 -- iter: 1472/2300\n",
            "Training Step: 191  | total loss: \u001b[1m\u001b[32m1.10548\u001b[0m\u001b[0m | time: 0.171s\n",
            "| Adam | epoch: 003 | loss: 1.10548 - acc: 0.8975 -- iter: 1504/2300\n",
            "Training Step: 192  | total loss: \u001b[1m\u001b[32m1.10344\u001b[0m\u001b[0m | time: 0.174s\n",
            "| Adam | epoch: 003 | loss: 1.10344 - acc: 0.9015 -- iter: 1536/2300\n",
            "Training Step: 193  | total loss: \u001b[1m\u001b[32m1.10360\u001b[0m\u001b[0m | time: 0.178s\n",
            "| Adam | epoch: 003 | loss: 1.10360 - acc: 0.8957 -- iter: 1568/2300\n",
            "Training Step: 194  | total loss: \u001b[1m\u001b[32m1.10102\u001b[0m\u001b[0m | time: 0.182s\n",
            "| Adam | epoch: 003 | loss: 1.10102 - acc: 0.8937 -- iter: 1600/2300\n",
            "Training Step: 195  | total loss: \u001b[1m\u001b[32m1.10726\u001b[0m\u001b[0m | time: 0.187s\n",
            "| Adam | epoch: 003 | loss: 1.10726 - acc: 0.8918 -- iter: 1632/2300\n",
            "Training Step: 196  | total loss: \u001b[1m\u001b[32m1.10970\u001b[0m\u001b[0m | time: 0.198s\n",
            "| Adam | epoch: 003 | loss: 1.10970 - acc: 0.8932 -- iter: 1664/2300\n",
            "Training Step: 197  | total loss: \u001b[1m\u001b[32m1.11489\u001b[0m\u001b[0m | time: 0.202s\n",
            "| Adam | epoch: 003 | loss: 1.11489 - acc: 0.8929 -- iter: 1696/2300\n",
            "Training Step: 198  | total loss: \u001b[1m\u001b[32m1.11489\u001b[0m\u001b[0m | time: 0.205s\n",
            "| Adam | epoch: 003 | loss: 1.11489 - acc: 0.8929 -- iter: 1728/2300\n",
            "Training Step: 199  | total loss: \u001b[1m\u001b[32m1.10749\u001b[0m\u001b[0m | time: 0.209s\n",
            "| Adam | epoch: 003 | loss: 1.10749 - acc: 0.9005 -- iter: 1760/2300\n",
            "Training Step: 200  | total loss: \u001b[1m\u001b[32m1.10528\u001b[0m\u001b[0m | time: 0.213s\n",
            "| Adam | epoch: 003 | loss: 1.10528 - acc: 0.8979 -- iter: 1792/2300\n",
            "Training Step: 201  | total loss: \u001b[1m\u001b[32m1.10350\u001b[0m\u001b[0m | time: 0.218s\n",
            "| Adam | epoch: 003 | loss: 1.10350 - acc: 0.9081 -- iter: 1824/2300\n",
            "Training Step: 202  | total loss: \u001b[1m\u001b[32m1.10197\u001b[0m\u001b[0m | time: 0.222s\n",
            "| Adam | epoch: 003 | loss: 1.10197 - acc: 0.9111 -- iter: 1856/2300\n",
            "Training Step: 203  | total loss: \u001b[1m\u001b[32m1.10655\u001b[0m\u001b[0m | time: 0.225s\n",
            "| Adam | epoch: 003 | loss: 1.10655 - acc: 0.9075 -- iter: 1888/2300\n",
            "Training Step: 204  | total loss: \u001b[1m\u001b[32m1.10262\u001b[0m\u001b[0m | time: 0.229s\n",
            "| Adam | epoch: 003 | loss: 1.10262 - acc: 0.9011 -- iter: 1920/2300\n",
            "Training Step: 205  | total loss: \u001b[1m\u001b[32m1.11272\u001b[0m\u001b[0m | time: 0.232s\n",
            "| Adam | epoch: 003 | loss: 1.11272 - acc: 0.8985 -- iter: 1952/2300\n",
            "Training Step: 206  | total loss: \u001b[1m\u001b[32m1.11347\u001b[0m\u001b[0m | time: 0.236s\n",
            "| Adam | epoch: 003 | loss: 1.11347 - acc: 0.8993 -- iter: 1984/2300\n",
            "Training Step: 207  | total loss: \u001b[1m\u001b[32m1.11309\u001b[0m\u001b[0m | time: 0.239s\n",
            "| Adam | epoch: 003 | loss: 1.11309 - acc: 0.9000 -- iter: 2016/2300\n",
            "Training Step: 208  | total loss: \u001b[1m\u001b[32m1.10155\u001b[0m\u001b[0m | time: 0.243s\n",
            "| Adam | epoch: 003 | loss: 1.10155 - acc: 0.9037 -- iter: 2048/2300\n",
            "Training Step: 209  | total loss: \u001b[1m\u001b[32m1.10011\u001b[0m\u001b[0m | time: 0.246s\n",
            "| Adam | epoch: 003 | loss: 1.10011 - acc: 0.9040 -- iter: 2080/2300\n",
            "Training Step: 210  | total loss: \u001b[1m\u001b[32m1.11258\u001b[0m\u001b[0m | time: 0.250s\n",
            "| Adam | epoch: 003 | loss: 1.11258 - acc: 0.9011 -- iter: 2112/2300\n",
            "Training Step: 211  | total loss: \u001b[1m\u001b[32m1.10919\u001b[0m\u001b[0m | time: 0.254s\n",
            "| Adam | epoch: 003 | loss: 1.10919 - acc: 0.9078 -- iter: 2144/2300\n",
            "Training Step: 212  | total loss: \u001b[1m\u001b[32m1.10992\u001b[0m\u001b[0m | time: 0.257s\n",
            "| Adam | epoch: 003 | loss: 1.10992 - acc: 0.9108 -- iter: 2176/2300\n",
            "Training Step: 213  | total loss: \u001b[1m\u001b[32m1.11123\u001b[0m\u001b[0m | time: 0.261s\n",
            "| Adam | epoch: 003 | loss: 1.11123 - acc: 0.9010 -- iter: 2208/2300\n",
            "Training Step: 214  | total loss: \u001b[1m\u001b[32m1.10684\u001b[0m\u001b[0m | time: 0.264s\n",
            "| Adam | epoch: 003 | loss: 1.10684 - acc: 0.9046 -- iter: 2240/2300\n",
            "Training Step: 215  | total loss: \u001b[1m\u001b[32m1.10279\u001b[0m\u001b[0m | time: 0.268s\n",
            "| Adam | epoch: 003 | loss: 1.10279 - acc: 0.8954 -- iter: 2272/2300\n",
            "Training Step: 216  | total loss: \u001b[1m\u001b[32m1.10243\u001b[0m\u001b[0m | time: 0.272s\n",
            "| Adam | epoch: 003 | loss: 1.10243 - acc: 0.8934 -- iter: 2300/2300\n",
            "--\n",
            "Training Step: 217  | total loss: \u001b[1m\u001b[32m1.10190\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 004 | loss: 1.10190 - acc: 0.8978 -- iter: 0032/2300\n",
            "Training Step: 218  | total loss: \u001b[1m\u001b[32m1.10904\u001b[0m\u001b[0m | time: 0.007s\n",
            "| Adam | epoch: 004 | loss: 1.10904 - acc: 0.8924 -- iter: 0064/2300\n",
            "Training Step: 219  | total loss: \u001b[1m\u001b[32m1.11058\u001b[0m\u001b[0m | time: 0.011s\n",
            "| Adam | epoch: 004 | loss: 1.11058 - acc: 0.8996 -- iter: 0096/2300\n",
            "Training Step: 220  | total loss: \u001b[1m\u001b[32m1.11198\u001b[0m\u001b[0m | time: 0.014s\n",
            "| Adam | epoch: 004 | loss: 1.11198 - acc: 0.9060 -- iter: 0128/2300\n",
            "Training Step: 221  | total loss: \u001b[1m\u001b[32m1.11774\u001b[0m\u001b[0m | time: 0.018s\n",
            "| Adam | epoch: 004 | loss: 1.11774 - acc: 0.9061 -- iter: 0160/2300\n",
            "Training Step: 222  | total loss: \u001b[1m\u001b[32m1.11532\u001b[0m\u001b[0m | time: 0.021s\n",
            "| Adam | epoch: 004 | loss: 1.11532 - acc: 0.9123 -- iter: 0192/2300\n",
            "Training Step: 223  | total loss: \u001b[1m\u001b[32m1.11551\u001b[0m\u001b[0m | time: 0.025s\n",
            "| Adam | epoch: 004 | loss: 1.11551 - acc: 0.9117 -- iter: 0224/2300\n",
            "Training Step: 224  | total loss: \u001b[1m\u001b[32m1.11019\u001b[0m\u001b[0m | time: 0.028s\n",
            "| Adam | epoch: 004 | loss: 1.11019 - acc: 0.9143 -- iter: 0256/2300\n",
            "Training Step: 225  | total loss: \u001b[1m\u001b[32m1.11587\u001b[0m\u001b[0m | time: 0.032s\n",
            "| Adam | epoch: 004 | loss: 1.11587 - acc: 0.9072 -- iter: 0288/2300\n",
            "Training Step: 226  | total loss: \u001b[1m\u001b[32m1.10977\u001b[0m\u001b[0m | time: 0.036s\n",
            "| Adam | epoch: 004 | loss: 1.10977 - acc: 0.9040 -- iter: 0320/2300\n",
            "Training Step: 227  | total loss: \u001b[1m\u001b[32m1.11043\u001b[0m\u001b[0m | time: 0.039s\n",
            "| Adam | epoch: 004 | loss: 1.11043 - acc: 0.8980 -- iter: 0352/2300\n",
            "Training Step: 228  | total loss: \u001b[1m\u001b[32m1.11665\u001b[0m\u001b[0m | time: 0.043s\n",
            "| Adam | epoch: 004 | loss: 1.11665 - acc: 0.8894 -- iter: 0384/2300\n",
            "Training Step: 229  | total loss: \u001b[1m\u001b[32m1.11424\u001b[0m\u001b[0m | time: 0.046s\n",
            "| Adam | epoch: 004 | loss: 1.11424 - acc: 0.8849 -- iter: 0416/2300\n",
            "Training Step: 230  | total loss: \u001b[1m\u001b[32m1.11721\u001b[0m\u001b[0m | time: 0.050s\n",
            "| Adam | epoch: 004 | loss: 1.11721 - acc: 0.8839 -- iter: 0448/2300\n",
            "Training Step: 231  | total loss: \u001b[1m\u001b[32m1.11657\u001b[0m\u001b[0m | time: 0.054s\n",
            "| Adam | epoch: 004 | loss: 1.11657 - acc: 0.8861 -- iter: 0480/2300\n",
            "Training Step: 232  | total loss: \u001b[1m\u001b[32m1.11163\u001b[0m\u001b[0m | time: 0.057s\n",
            "| Adam | epoch: 004 | loss: 1.11163 - acc: 0.8944 -- iter: 0512/2300\n",
            "Training Step: 233  | total loss: \u001b[1m\u001b[32m1.11247\u001b[0m\u001b[0m | time: 0.060s\n",
            "| Adam | epoch: 004 | loss: 1.11247 - acc: 0.8893 -- iter: 0544/2300\n",
            "Training Step: 234  | total loss: \u001b[1m\u001b[32m1.11265\u001b[0m\u001b[0m | time: 0.064s\n",
            "| Adam | epoch: 004 | loss: 1.11265 - acc: 0.8910 -- iter: 0576/2300\n",
            "Training Step: 235  | total loss: \u001b[1m\u001b[32m1.10715\u001b[0m\u001b[0m | time: 0.067s\n",
            "| Adam | epoch: 004 | loss: 1.10715 - acc: 0.8832 -- iter: 0608/2300\n",
            "Training Step: 236  | total loss: \u001b[1m\u001b[32m1.11022\u001b[0m\u001b[0m | time: 0.071s\n",
            "| Adam | epoch: 004 | loss: 1.11022 - acc: 0.8698 -- iter: 0640/2300\n",
            "Training Step: 237  | total loss: \u001b[1m\u001b[32m1.11531\u001b[0m\u001b[0m | time: 0.074s\n",
            "| Adam | epoch: 004 | loss: 1.11531 - acc: 0.8766 -- iter: 0672/2300\n",
            "Training Step: 238  | total loss: \u001b[1m\u001b[32m1.11237\u001b[0m\u001b[0m | time: 0.078s\n",
            "| Adam | epoch: 004 | loss: 1.11237 - acc: 0.8858 -- iter: 0704/2300\n",
            "Training Step: 239  | total loss: \u001b[1m\u001b[32m1.10819\u001b[0m\u001b[0m | time: 0.082s\n",
            "| Adam | epoch: 004 | loss: 1.10819 - acc: 0.8847 -- iter: 0736/2300\n",
            "Training Step: 240  | total loss: \u001b[1m\u001b[32m1.11198\u001b[0m\u001b[0m | time: 0.085s\n",
            "| Adam | epoch: 004 | loss: 1.11198 - acc: 0.8900 -- iter: 0768/2300\n",
            "Training Step: 241  | total loss: \u001b[1m\u001b[32m1.11280\u001b[0m\u001b[0m | time: 0.089s\n",
            "| Adam | epoch: 004 | loss: 1.11280 - acc: 0.8979 -- iter: 0800/2300\n",
            "Training Step: 242  | total loss: \u001b[1m\u001b[32m1.10805\u001b[0m\u001b[0m | time: 0.093s\n",
            "| Adam | epoch: 004 | loss: 1.10805 - acc: 0.8956 -- iter: 0832/2300\n",
            "Training Step: 243  | total loss: \u001b[1m\u001b[32m1.11236\u001b[0m\u001b[0m | time: 0.096s\n",
            "| Adam | epoch: 004 | loss: 1.11236 - acc: 0.8967 -- iter: 0864/2300\n",
            "Training Step: 244  | total loss: \u001b[1m\u001b[32m1.11020\u001b[0m\u001b[0m | time: 0.100s\n",
            "| Adam | epoch: 004 | loss: 1.11020 - acc: 0.9039 -- iter: 0896/2300\n",
            "Training Step: 245  | total loss: \u001b[1m\u001b[32m1.10559\u001b[0m\u001b[0m | time: 0.103s\n",
            "| Adam | epoch: 004 | loss: 1.10559 - acc: 0.9041 -- iter: 0928/2300\n",
            "Training Step: 246  | total loss: \u001b[1m\u001b[32m1.10658\u001b[0m\u001b[0m | time: 0.107s\n",
            "| Adam | epoch: 004 | loss: 1.10658 - acc: 0.9043 -- iter: 0960/2300\n",
            "Training Step: 247  | total loss: \u001b[1m\u001b[32m1.11106\u001b[0m\u001b[0m | time: 0.112s\n",
            "| Adam | epoch: 004 | loss: 1.11106 - acc: 0.9045 -- iter: 0992/2300\n",
            "Training Step: 248  | total loss: \u001b[1m\u001b[32m1.11177\u001b[0m\u001b[0m | time: 0.116s\n",
            "| Adam | epoch: 004 | loss: 1.11177 - acc: 0.9109 -- iter: 1024/2300\n",
            "Training Step: 249  | total loss: \u001b[1m\u001b[32m1.10620\u001b[0m\u001b[0m | time: 0.119s\n",
            "| Adam | epoch: 004 | loss: 1.10620 - acc: 0.9042 -- iter: 1056/2300\n",
            "Training Step: 250  | total loss: \u001b[1m\u001b[32m1.09834\u001b[0m\u001b[0m | time: 0.123s\n",
            "| Adam | epoch: 004 | loss: 1.09834 - acc: 0.9044 -- iter: 1088/2300\n",
            "Training Step: 251  | total loss: \u001b[1m\u001b[32m1.09559\u001b[0m\u001b[0m | time: 0.127s\n",
            "| Adam | epoch: 004 | loss: 1.09559 - acc: 0.9109 -- iter: 1120/2300\n",
            "Training Step: 252  | total loss: \u001b[1m\u001b[32m1.10199\u001b[0m\u001b[0m | time: 0.131s\n",
            "| Adam | epoch: 004 | loss: 1.10199 - acc: 0.9104 -- iter: 1152/2300\n",
            "Training Step: 253  | total loss: \u001b[1m\u001b[32m1.09419\u001b[0m\u001b[0m | time: 0.135s\n",
            "| Adam | epoch: 004 | loss: 1.09419 - acc: 0.9131 -- iter: 1184/2300\n",
            "Training Step: 254  | total loss: \u001b[1m\u001b[32m1.09218\u001b[0m\u001b[0m | time: 0.138s\n",
            "| Adam | epoch: 004 | loss: 1.09218 - acc: 0.9155 -- iter: 1216/2300\n",
            "Training Step: 255  | total loss: \u001b[1m\u001b[32m1.08867\u001b[0m\u001b[0m | time: 0.143s\n",
            "| Adam | epoch: 004 | loss: 1.08867 - acc: 0.9240 -- iter: 1248/2300\n",
            "Training Step: 256  | total loss: \u001b[1m\u001b[32m1.08619\u001b[0m\u001b[0m | time: 0.147s\n",
            "| Adam | epoch: 004 | loss: 1.08619 - acc: 0.9222 -- iter: 1280/2300\n",
            "Training Step: 257  | total loss: \u001b[1m\u001b[32m1.08280\u001b[0m\u001b[0m | time: 0.151s\n",
            "| Adam | epoch: 004 | loss: 1.08280 - acc: 0.9175 -- iter: 1312/2300\n",
            "Training Step: 258  | total loss: \u001b[1m\u001b[32m1.08432\u001b[0m\u001b[0m | time: 0.154s\n",
            "| Adam | epoch: 004 | loss: 1.08432 - acc: 0.9164 -- iter: 1344/2300\n",
            "Training Step: 259  | total loss: \u001b[1m\u001b[32m1.09160\u001b[0m\u001b[0m | time: 0.158s\n",
            "| Adam | epoch: 004 | loss: 1.09160 - acc: 0.9122 -- iter: 1376/2300\n",
            "Training Step: 260  | total loss: \u001b[1m\u001b[32m1.08484\u001b[0m\u001b[0m | time: 0.161s\n",
            "| Adam | epoch: 004 | loss: 1.08484 - acc: 0.9179 -- iter: 1408/2300\n",
            "Training Step: 261  | total loss: \u001b[1m\u001b[32m1.06747\u001b[0m\u001b[0m | time: 0.164s\n",
            "| Adam | epoch: 004 | loss: 1.06747 - acc: 0.9198 -- iter: 1440/2300\n",
            "Training Step: 262  | total loss: \u001b[1m\u001b[32m1.06978\u001b[0m\u001b[0m | time: 0.168s\n",
            "| Adam | epoch: 004 | loss: 1.06978 - acc: 0.9154 -- iter: 1472/2300\n",
            "Training Step: 263  | total loss: \u001b[1m\u001b[32m1.07777\u001b[0m\u001b[0m | time: 0.172s\n",
            "| Adam | epoch: 004 | loss: 1.07777 - acc: 0.9113 -- iter: 1504/2300\n",
            "Training Step: 264  | total loss: \u001b[1m\u001b[32m1.08714\u001b[0m\u001b[0m | time: 0.175s\n",
            "| Adam | epoch: 004 | loss: 1.08714 - acc: 0.9046 -- iter: 1536/2300\n",
            "Training Step: 265  | total loss: \u001b[1m\u001b[32m1.08586\u001b[0m\u001b[0m | time: 0.179s\n",
            "| Adam | epoch: 004 | loss: 1.08586 - acc: 0.9079 -- iter: 1568/2300\n",
            "Training Step: 266  | total loss: \u001b[1m\u001b[32m1.08202\u001b[0m\u001b[0m | time: 0.182s\n",
            "| Adam | epoch: 004 | loss: 1.08202 - acc: 0.9077 -- iter: 1600/2300\n",
            "Training Step: 267  | total loss: \u001b[1m\u001b[32m1.07759\u001b[0m\u001b[0m | time: 0.186s\n",
            "| Adam | epoch: 004 | loss: 1.07759 - acc: 0.9138 -- iter: 1632/2300\n",
            "Training Step: 268  | total loss: \u001b[1m\u001b[32m1.07800\u001b[0m\u001b[0m | time: 0.190s\n",
            "| Adam | epoch: 004 | loss: 1.07800 - acc: 0.9162 -- iter: 1664/2300\n",
            "Training Step: 269  | total loss: \u001b[1m\u001b[32m1.08038\u001b[0m\u001b[0m | time: 0.193s\n",
            "| Adam | epoch: 004 | loss: 1.08038 - acc: 0.9183 -- iter: 1696/2300\n",
            "Training Step: 270  | total loss: \u001b[1m\u001b[32m1.08456\u001b[0m\u001b[0m | time: 0.197s\n",
            "| Adam | epoch: 004 | loss: 1.08456 - acc: 0.9046 -- iter: 1728/2300\n",
            "Training Step: 271  | total loss: \u001b[1m\u001b[32m1.09164\u001b[0m\u001b[0m | time: 0.201s\n",
            "| Adam | epoch: 004 | loss: 1.09164 - acc: 0.8954 -- iter: 1760/2300\n",
            "Training Step: 272  | total loss: \u001b[1m\u001b[32m1.09862\u001b[0m\u001b[0m | time: 0.204s\n",
            "| Adam | epoch: 004 | loss: 1.09862 - acc: 0.8996 -- iter: 1792/2300\n",
            "Training Step: 273  | total loss: \u001b[1m\u001b[32m1.10183\u001b[0m\u001b[0m | time: 0.207s\n",
            "| Adam | epoch: 004 | loss: 1.10183 - acc: 0.9034 -- iter: 1824/2300\n",
            "Training Step: 274  | total loss: \u001b[1m\u001b[32m1.09342\u001b[0m\u001b[0m | time: 0.212s\n",
            "| Adam | epoch: 004 | loss: 1.09342 - acc: 0.9037 -- iter: 1856/2300\n",
            "Training Step: 275  | total loss: \u001b[1m\u001b[32m1.09513\u001b[0m\u001b[0m | time: 0.217s\n",
            "| Adam | epoch: 004 | loss: 1.09513 - acc: 0.9071 -- iter: 1888/2300\n",
            "Training Step: 276  | total loss: \u001b[1m\u001b[32m1.08905\u001b[0m\u001b[0m | time: 0.221s\n",
            "| Adam | epoch: 004 | loss: 1.08905 - acc: 0.9132 -- iter: 1920/2300\n",
            "Training Step: 277  | total loss: \u001b[1m\u001b[32m1.08406\u001b[0m\u001b[0m | time: 0.224s\n",
            "| Adam | epoch: 004 | loss: 1.08406 - acc: 0.9125 -- iter: 1952/2300\n",
            "Training Step: 278  | total loss: \u001b[1m\u001b[32m1.08893\u001b[0m\u001b[0m | time: 0.228s\n",
            "| Adam | epoch: 004 | loss: 1.08893 - acc: 0.9213 -- iter: 1984/2300\n",
            "Training Step: 279  | total loss: \u001b[1m\u001b[32m1.09543\u001b[0m\u001b[0m | time: 0.231s\n",
            "| Adam | epoch: 004 | loss: 1.09543 - acc: 0.9135 -- iter: 2016/2300\n",
            "Training Step: 280  | total loss: \u001b[1m\u001b[32m1.09328\u001b[0m\u001b[0m | time: 0.235s\n",
            "| Adam | epoch: 004 | loss: 1.09328 - acc: 0.9190 -- iter: 2048/2300\n",
            "Training Step: 281  | total loss: \u001b[1m\u001b[32m1.10408\u001b[0m\u001b[0m | time: 0.238s\n",
            "| Adam | epoch: 004 | loss: 1.10408 - acc: 0.9178 -- iter: 2080/2300\n",
            "Training Step: 282  | total loss: \u001b[1m\u001b[32m1.10630\u001b[0m\u001b[0m | time: 0.242s\n",
            "| Adam | epoch: 004 | loss: 1.10630 - acc: 0.9135 -- iter: 2112/2300\n",
            "Training Step: 283  | total loss: \u001b[1m\u001b[32m1.10818\u001b[0m\u001b[0m | time: 0.246s\n",
            "| Adam | epoch: 004 | loss: 1.10818 - acc: 0.9034 -- iter: 2144/2300\n",
            "Training Step: 284  | total loss: \u001b[1m\u001b[32m1.10723\u001b[0m\u001b[0m | time: 0.249s\n",
            "| Adam | epoch: 004 | loss: 1.10723 - acc: 0.9099 -- iter: 2176/2300\n",
            "Training Step: 285  | total loss: \u001b[1m\u001b[32m1.10752\u001b[0m\u001b[0m | time: 0.253s\n",
            "| Adam | epoch: 004 | loss: 1.10752 - acc: 0.9033 -- iter: 2208/2300\n",
            "Training Step: 286  | total loss: \u001b[1m\u001b[32m1.10705\u001b[0m\u001b[0m | time: 0.258s\n",
            "| Adam | epoch: 004 | loss: 1.10705 - acc: 0.9036 -- iter: 2240/2300\n",
            "Training Step: 287  | total loss: \u001b[1m\u001b[32m1.10513\u001b[0m\u001b[0m | time: 0.262s\n",
            "| Adam | epoch: 004 | loss: 1.10513 - acc: 0.9132 -- iter: 2272/2300\n",
            "Training Step: 288  | total loss: \u001b[1m\u001b[32m1.10516\u001b[0m\u001b[0m | time: 0.265s\n",
            "| Adam | epoch: 004 | loss: 1.10516 - acc: 0.8969 -- iter: 2300/2300\n",
            "--\n",
            "Training Step: 289  | total loss: \u001b[1m\u001b[32m1.10035\u001b[0m\u001b[0m | time: 0.003s\n",
            "| Adam | epoch: 005 | loss: 1.10035 - acc: 0.9010 -- iter: 0032/2300\n",
            "Training Step: 290  | total loss: \u001b[1m\u001b[32m1.09935\u001b[0m\u001b[0m | time: 0.007s\n",
            "| Adam | epoch: 005 | loss: 1.09935 - acc: 0.9015 -- iter: 0064/2300\n",
            "Training Step: 291  | total loss: \u001b[1m\u001b[32m1.09431\u001b[0m\u001b[0m | time: 0.010s\n",
            "| Adam | epoch: 005 | loss: 1.09431 - acc: 0.9082 -- iter: 0096/2300\n",
            "Training Step: 292  | total loss: \u001b[1m\u001b[32m1.08994\u001b[0m\u001b[0m | time: 0.014s\n",
            "| Adam | epoch: 005 | loss: 1.08994 - acc: 0.9138 -- iter: 0128/2300\n",
            "Training Step: 293  | total loss: \u001b[1m\u001b[32m1.08593\u001b[0m\u001b[0m | time: 0.018s\n",
            "| Adam | epoch: 005 | loss: 1.08593 - acc: 0.9189 -- iter: 0160/2300\n",
            "Training Step: 294  | total loss: \u001b[1m\u001b[32m1.09332\u001b[0m\u001b[0m | time: 0.021s\n",
            "| Adam | epoch: 005 | loss: 1.09332 - acc: 0.9145 -- iter: 0192/2300\n",
            "Training Step: 295  | total loss: \u001b[1m\u001b[32m1.09738\u001b[0m\u001b[0m | time: 0.025s\n",
            "| Adam | epoch: 005 | loss: 1.09738 - acc: 0.9168 -- iter: 0224/2300\n",
            "Training Step: 296  | total loss: \u001b[1m\u001b[32m1.09146\u001b[0m\u001b[0m | time: 0.028s\n",
            "| Adam | epoch: 005 | loss: 1.09146 - acc: 0.9064 -- iter: 0256/2300\n",
            "Training Step: 297  | total loss: \u001b[1m\u001b[32m1.08422\u001b[0m\u001b[0m | time: 0.032s\n",
            "| Adam | epoch: 005 | loss: 1.08422 - acc: 0.8970 -- iter: 0288/2300\n",
            "Training Step: 298  | total loss: \u001b[1m\u001b[32m1.09001\u001b[0m\u001b[0m | time: 0.035s\n",
            "| Adam | epoch: 005 | loss: 1.09001 - acc: 0.8948 -- iter: 0320/2300\n",
            "Training Step: 299  | total loss: \u001b[1m\u001b[32m1.09587\u001b[0m\u001b[0m | time: 0.039s\n",
            "| Adam | epoch: 005 | loss: 1.09587 - acc: 0.8991 -- iter: 0352/2300\n",
            "Training Step: 300  | total loss: \u001b[1m\u001b[32m1.10198\u001b[0m\u001b[0m | time: 0.046s\n",
            "| Adam | epoch: 005 | loss: 1.10198 - acc: 0.8998 -- iter: 0384/2300\n",
            "Training Step: 301  | total loss: \u001b[1m\u001b[32m1.11436\u001b[0m\u001b[0m | time: 0.050s\n",
            "| Adam | epoch: 005 | loss: 1.11436 - acc: 0.8817 -- iter: 0416/2300\n",
            "Training Step: 302  | total loss: \u001b[1m\u001b[32m1.12088\u001b[0m\u001b[0m | time: 0.054s\n",
            "| Adam | epoch: 005 | loss: 1.12088 - acc: 0.8779 -- iter: 0448/2300\n",
            "Training Step: 303  | total loss: \u001b[1m\u001b[32m1.13049\u001b[0m\u001b[0m | time: 0.059s\n",
            "| Adam | epoch: 005 | loss: 1.13049 - acc: 0.8838 -- iter: 0480/2300\n",
            "Training Step: 304  | total loss: \u001b[1m\u001b[32m1.12683\u001b[0m\u001b[0m | time: 0.064s\n",
            "| Adam | epoch: 005 | loss: 1.12683 - acc: 0.8861 -- iter: 0512/2300\n",
            "Training Step: 305  | total loss: \u001b[1m\u001b[32m1.12982\u001b[0m\u001b[0m | time: 0.067s\n",
            "| Adam | epoch: 005 | loss: 1.12982 - acc: 0.8912 -- iter: 0544/2300\n",
            "Training Step: 306  | total loss: \u001b[1m\u001b[32m1.13528\u001b[0m\u001b[0m | time: 0.071s\n",
            "| Adam | epoch: 005 | loss: 1.13528 - acc: 0.8896 -- iter: 0576/2300\n",
            "Training Step: 307  | total loss: \u001b[1m\u001b[32m1.13276\u001b[0m\u001b[0m | time: 0.075s\n",
            "| Adam | epoch: 005 | loss: 1.13276 - acc: 0.8944 -- iter: 0608/2300\n",
            "Training Step: 308  | total loss: \u001b[1m\u001b[32m1.12886\u001b[0m\u001b[0m | time: 0.079s\n",
            "| Adam | epoch: 005 | loss: 1.12886 - acc: 0.8831 -- iter: 0640/2300\n",
            "Training Step: 309  | total loss: \u001b[1m\u001b[32m1.11572\u001b[0m\u001b[0m | time: 0.082s\n",
            "| Adam | epoch: 005 | loss: 1.11572 - acc: 0.8916 -- iter: 0672/2300\n",
            "Training Step: 310  | total loss: \u001b[1m\u001b[32m1.11571\u001b[0m\u001b[0m | time: 0.086s\n",
            "| Adam | epoch: 005 | loss: 1.11571 - acc: 0.8994 -- iter: 0704/2300\n",
            "Training Step: 311  | total loss: \u001b[1m\u001b[32m1.11145\u001b[0m\u001b[0m | time: 0.089s\n",
            "| Adam | epoch: 005 | loss: 1.11145 - acc: 0.9032 -- iter: 0736/2300\n",
            "Training Step: 312  | total loss: \u001b[1m\u001b[32m1.11535\u001b[0m\u001b[0m | time: 0.093s\n",
            "| Adam | epoch: 005 | loss: 1.11535 - acc: 0.9097 -- iter: 0768/2300\n",
            "Training Step: 313  | total loss: \u001b[1m\u001b[32m1.11974\u001b[0m\u001b[0m | time: 0.096s\n",
            "| Adam | epoch: 005 | loss: 1.11974 - acc: 0.9031 -- iter: 0800/2300\n",
            "Training Step: 314  | total loss: \u001b[1m\u001b[32m1.11668\u001b[0m\u001b[0m | time: 0.099s\n",
            "| Adam | epoch: 005 | loss: 1.11668 - acc: 0.9003 -- iter: 0832/2300\n",
            "Training Step: 315  | total loss: \u001b[1m\u001b[32m1.12115\u001b[0m\u001b[0m | time: 0.103s\n",
            "| Adam | epoch: 005 | loss: 1.12115 - acc: 0.9009 -- iter: 0864/2300\n",
            "Training Step: 316  | total loss: \u001b[1m\u001b[32m1.11728\u001b[0m\u001b[0m | time: 0.107s\n",
            "| Adam | epoch: 005 | loss: 1.11728 - acc: 0.9046 -- iter: 0896/2300\n",
            "Training Step: 317  | total loss: \u001b[1m\u001b[32m1.11930\u001b[0m\u001b[0m | time: 0.110s\n",
            "| Adam | epoch: 005 | loss: 1.11930 - acc: 0.9016 -- iter: 0928/2300\n",
            "Training Step: 318  | total loss: \u001b[1m\u001b[32m1.11681\u001b[0m\u001b[0m | time: 0.114s\n",
            "| Adam | epoch: 005 | loss: 1.11681 - acc: 0.8990 -- iter: 0960/2300\n",
            "Training Step: 319  | total loss: \u001b[1m\u001b[32m1.11422\u001b[0m\u001b[0m | time: 0.117s\n",
            "| Adam | epoch: 005 | loss: 1.11422 - acc: 0.8997 -- iter: 0992/2300\n",
            "Training Step: 320  | total loss: \u001b[1m\u001b[32m1.11967\u001b[0m\u001b[0m | time: 0.121s\n",
            "| Adam | epoch: 005 | loss: 1.11967 - acc: 0.8972 -- iter: 1024/2300\n",
            "Training Step: 321  | total loss: \u001b[1m\u001b[32m1.11760\u001b[0m\u001b[0m | time: 0.124s\n",
            "| Adam | epoch: 005 | loss: 1.11760 - acc: 0.9012 -- iter: 1056/2300\n",
            "Training Step: 322  | total loss: \u001b[1m\u001b[32m1.10989\u001b[0m\u001b[0m | time: 0.128s\n",
            "| Adam | epoch: 005 | loss: 1.10989 - acc: 0.8924 -- iter: 1088/2300\n",
            "Training Step: 323  | total loss: \u001b[1m\u001b[32m1.10486\u001b[0m\u001b[0m | time: 0.131s\n",
            "| Adam | epoch: 005 | loss: 1.10486 - acc: 0.8938 -- iter: 1120/2300\n",
            "Training Step: 324  | total loss: \u001b[1m\u001b[32m1.09773\u001b[0m\u001b[0m | time: 0.135s\n",
            "| Adam | epoch: 005 | loss: 1.09773 - acc: 0.8919 -- iter: 1152/2300\n",
            "Training Step: 325  | total loss: \u001b[1m\u001b[32m1.10724\u001b[0m\u001b[0m | time: 0.138s\n",
            "| Adam | epoch: 005 | loss: 1.10724 - acc: 0.8996 -- iter: 1184/2300\n",
            "Training Step: 326  | total loss: \u001b[1m\u001b[32m1.10598\u001b[0m\u001b[0m | time: 0.142s\n",
            "| Adam | epoch: 005 | loss: 1.10598 - acc: 0.9096 -- iter: 1216/2300\n",
            "Training Step: 327  | total loss: \u001b[1m\u001b[32m1.09143\u001b[0m\u001b[0m | time: 0.146s\n",
            "| Adam | epoch: 005 | loss: 1.09143 - acc: 0.9093 -- iter: 1248/2300\n",
            "Training Step: 328  | total loss: \u001b[1m\u001b[32m1.09233\u001b[0m\u001b[0m | time: 0.149s\n",
            "| Adam | epoch: 005 | loss: 1.09233 - acc: 0.9090 -- iter: 1280/2300\n",
            "Training Step: 329  | total loss: \u001b[1m\u001b[32m1.10481\u001b[0m\u001b[0m | time: 0.153s\n",
            "| Adam | epoch: 005 | loss: 1.10481 - acc: 0.9087 -- iter: 1312/2300\n",
            "Training Step: 330  | total loss: \u001b[1m\u001b[32m1.10195\u001b[0m\u001b[0m | time: 0.157s\n",
            "| Adam | epoch: 005 | loss: 1.10195 - acc: 0.9147 -- iter: 1344/2300\n",
            "Training Step: 331  | total loss: \u001b[1m\u001b[32m1.10026\u001b[0m\u001b[0m | time: 0.161s\n",
            "| Adam | epoch: 005 | loss: 1.10026 - acc: 0.9107 -- iter: 1376/2300\n",
            "Training Step: 332  | total loss: \u001b[1m\u001b[32m1.10951\u001b[0m\u001b[0m | time: 0.165s\n",
            "| Adam | epoch: 005 | loss: 1.10951 - acc: 0.9040 -- iter: 1408/2300\n",
            "Training Step: 333  | total loss: \u001b[1m\u001b[32m1.10610\u001b[0m\u001b[0m | time: 0.169s\n",
            "| Adam | epoch: 005 | loss: 1.10610 - acc: 0.9074 -- iter: 1440/2300\n",
            "Training Step: 334  | total loss: \u001b[1m\u001b[32m1.11525\u001b[0m\u001b[0m | time: 0.172s\n",
            "| Adam | epoch: 005 | loss: 1.11525 - acc: 0.9041 -- iter: 1472/2300\n",
            "Training Step: 335  | total loss: \u001b[1m\u001b[32m1.12269\u001b[0m\u001b[0m | time: 0.176s\n",
            "| Adam | epoch: 005 | loss: 1.12269 - acc: 0.9106 -- iter: 1504/2300\n",
            "Training Step: 336  | total loss: \u001b[1m\u001b[32m1.11341\u001b[0m\u001b[0m | time: 0.179s\n",
            "| Adam | epoch: 005 | loss: 1.11341 - acc: 0.9102 -- iter: 1536/2300\n",
            "Training Step: 337  | total loss: \u001b[1m\u001b[32m1.10794\u001b[0m\u001b[0m | time: 0.183s\n",
            "| Adam | epoch: 005 | loss: 1.10794 - acc: 0.9129 -- iter: 1568/2300\n",
            "Training Step: 338  | total loss: \u001b[1m\u001b[32m1.08157\u001b[0m\u001b[0m | time: 0.187s\n",
            "| Adam | epoch: 005 | loss: 1.08157 - acc: 0.9216 -- iter: 1600/2300\n",
            "Training Step: 339  | total loss: \u001b[1m\u001b[32m1.08948\u001b[0m\u001b[0m | time: 0.190s\n",
            "| Adam | epoch: 005 | loss: 1.08948 - acc: 0.9138 -- iter: 1632/2300\n",
            "Training Step: 340  | total loss: \u001b[1m\u001b[32m1.09131\u001b[0m\u001b[0m | time: 0.194s\n",
            "| Adam | epoch: 005 | loss: 1.09131 - acc: 0.9193 -- iter: 1664/2300\n",
            "Training Step: 341  | total loss: \u001b[1m\u001b[32m1.09028\u001b[0m\u001b[0m | time: 0.198s\n",
            "| Adam | epoch: 005 | loss: 1.09028 - acc: 0.9243 -- iter: 1696/2300\n",
            "Training Step: 342  | total loss: \u001b[1m\u001b[32m1.09103\u001b[0m\u001b[0m | time: 0.202s\n",
            "| Adam | epoch: 005 | loss: 1.09103 - acc: 0.9287 -- iter: 1728/2300\n",
            "Training Step: 343  | total loss: \u001b[1m\u001b[32m1.09345\u001b[0m\u001b[0m | time: 0.206s\n",
            "| Adam | epoch: 005 | loss: 1.09345 - acc: 0.9202 -- iter: 1760/2300\n",
            "Training Step: 344  | total loss: \u001b[1m\u001b[32m1.10292\u001b[0m\u001b[0m | time: 0.209s\n",
            "| Adam | epoch: 005 | loss: 1.10292 - acc: 0.9157 -- iter: 1792/2300\n",
            "Training Step: 345  | total loss: \u001b[1m\u001b[32m1.09586\u001b[0m\u001b[0m | time: 0.212s\n",
            "| Adam | epoch: 005 | loss: 1.09586 - acc: 0.9022 -- iter: 1824/2300\n",
            "Training Step: 346  | total loss: \u001b[1m\u001b[32m1.09468\u001b[0m\u001b[0m | time: 0.216s\n",
            "| Adam | epoch: 005 | loss: 1.09468 - acc: 0.8964 -- iter: 1856/2300\n",
            "Training Step: 347  | total loss: \u001b[1m\u001b[32m1.10274\u001b[0m\u001b[0m | time: 0.219s\n",
            "| Adam | epoch: 005 | loss: 1.10274 - acc: 0.8943 -- iter: 1888/2300\n",
            "Training Step: 348  | total loss: \u001b[1m\u001b[32m1.09886\u001b[0m\u001b[0m | time: 0.223s\n",
            "| Adam | epoch: 005 | loss: 1.09886 - acc: 0.8986 -- iter: 1920/2300\n",
            "Training Step: 349  | total loss: \u001b[1m\u001b[32m1.09566\u001b[0m\u001b[0m | time: 0.227s\n",
            "| Adam | epoch: 005 | loss: 1.09566 - acc: 0.9087 -- iter: 1952/2300\n",
            "Training Step: 350  | total loss: \u001b[1m\u001b[32m1.09139\u001b[0m\u001b[0m | time: 0.230s\n",
            "| Adam | epoch: 005 | loss: 1.09139 - acc: 0.9116 -- iter: 1984/2300\n",
            "Training Step: 351  | total loss: \u001b[1m\u001b[32m1.08981\u001b[0m\u001b[0m | time: 0.235s\n",
            "| Adam | epoch: 005 | loss: 1.08981 - acc: 0.9173 -- iter: 2016/2300\n",
            "Training Step: 352  | total loss: \u001b[1m\u001b[32m1.09637\u001b[0m\u001b[0m | time: 0.238s\n",
            "| Adam | epoch: 005 | loss: 1.09637 - acc: 0.9131 -- iter: 2048/2300\n",
            "Training Step: 353  | total loss: \u001b[1m\u001b[32m1.09719\u001b[0m\u001b[0m | time: 0.244s\n",
            "| Adam | epoch: 005 | loss: 1.09719 - acc: 0.9093 -- iter: 2080/2300\n",
            "Training Step: 354  | total loss: \u001b[1m\u001b[32m1.09851\u001b[0m\u001b[0m | time: 0.255s\n",
            "| Adam | epoch: 005 | loss: 1.09851 - acc: 0.9090 -- iter: 2112/2300\n",
            "Training Step: 355  | total loss: \u001b[1m\u001b[32m1.08472\u001b[0m\u001b[0m | time: 0.259s\n",
            "| Adam | epoch: 005 | loss: 1.08472 - acc: 0.9150 -- iter: 2144/2300\n",
            "Training Step: 356  | total loss: \u001b[1m\u001b[32m1.09627\u001b[0m\u001b[0m | time: 0.264s\n",
            "| Adam | epoch: 005 | loss: 1.09627 - acc: 0.9110 -- iter: 2176/2300\n",
            "Training Step: 357  | total loss: \u001b[1m\u001b[32m1.09646\u001b[0m\u001b[0m | time: 0.268s\n",
            "| Adam | epoch: 005 | loss: 1.09646 - acc: 0.9042 -- iter: 2208/2300\n",
            "Training Step: 358  | total loss: \u001b[1m\u001b[32m1.10210\u001b[0m\u001b[0m | time: 0.273s\n",
            "| Adam | epoch: 005 | loss: 1.10210 - acc: 0.9013 -- iter: 2240/2300\n",
            "Training Step: 359  | total loss: \u001b[1m\u001b[32m1.09579\u001b[0m\u001b[0m | time: 0.278s\n",
            "| Adam | epoch: 005 | loss: 1.09579 - acc: 0.9049 -- iter: 2272/2300\n",
            "Training Step: 360  | total loss: \u001b[1m\u001b[32m1.09230\u001b[0m\u001b[0m | time: 0.283s\n",
            "| Adam | epoch: 005 | loss: 1.09230 - acc: 0.9051 -- iter: 2300/2300\n",
            "--\n",
            "Training Step: 361  | total loss: \u001b[1m\u001b[32m1.10871\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 006 | loss: 1.10871 - acc: 0.9052 -- iter: 0032/2300\n",
            "Training Step: 362  | total loss: \u001b[1m\u001b[32m1.11771\u001b[0m\u001b[0m | time: 0.007s\n",
            "| Adam | epoch: 006 | loss: 1.11771 - acc: 0.9084 -- iter: 0064/2300\n",
            "Training Step: 363  | total loss: \u001b[1m\u001b[32m1.11979\u001b[0m\u001b[0m | time: 0.010s\n",
            "| Adam | epoch: 006 | loss: 1.11979 - acc: 0.9082 -- iter: 0096/2300\n",
            "Training Step: 364  | total loss: \u001b[1m\u001b[32m1.11304\u001b[0m\u001b[0m | time: 0.014s\n",
            "| Adam | epoch: 006 | loss: 1.11304 - acc: 0.9174 -- iter: 0128/2300\n",
            "Training Step: 365  | total loss: \u001b[1m\u001b[32m1.11325\u001b[0m\u001b[0m | time: 0.018s\n",
            "| Adam | epoch: 006 | loss: 1.11325 - acc: 0.9114 -- iter: 0160/2300\n",
            "Training Step: 366  | total loss: \u001b[1m\u001b[32m1.11354\u001b[0m\u001b[0m | time: 0.021s\n",
            "| Adam | epoch: 006 | loss: 1.11354 - acc: 0.9024 -- iter: 0192/2300\n",
            "Training Step: 367  | total loss: \u001b[1m\u001b[32m1.11035\u001b[0m\u001b[0m | time: 0.025s\n",
            "| Adam | epoch: 006 | loss: 1.11035 - acc: 0.8996 -- iter: 0224/2300\n",
            "Training Step: 368  | total loss: \u001b[1m\u001b[32m1.10769\u001b[0m\u001b[0m | time: 0.028s\n",
            "| Adam | epoch: 006 | loss: 1.10769 - acc: 0.8909 -- iter: 0256/2300\n",
            "Training Step: 369  | total loss: \u001b[1m\u001b[32m1.10657\u001b[0m\u001b[0m | time: 0.032s\n",
            "| Adam | epoch: 006 | loss: 1.10657 - acc: 0.8924 -- iter: 0288/2300\n",
            "Training Step: 370  | total loss: \u001b[1m\u001b[32m1.11381\u001b[0m\u001b[0m | time: 0.035s\n",
            "| Adam | epoch: 006 | loss: 1.11381 - acc: 0.8970 -- iter: 0320/2300\n",
            "Training Step: 371  | total loss: \u001b[1m\u001b[32m1.11577\u001b[0m\u001b[0m | time: 0.039s\n",
            "| Adam | epoch: 006 | loss: 1.11577 - acc: 0.9010 -- iter: 0352/2300\n",
            "Training Step: 372  | total loss: \u001b[1m\u001b[32m1.11071\u001b[0m\u001b[0m | time: 0.042s\n",
            "| Adam | epoch: 006 | loss: 1.11071 - acc: 0.9015 -- iter: 0384/2300\n",
            "Training Step: 373  | total loss: \u001b[1m\u001b[32m1.10842\u001b[0m\u001b[0m | time: 0.046s\n",
            "| Adam | epoch: 006 | loss: 1.10842 - acc: 0.8989 -- iter: 0416/2300\n",
            "Training Step: 374  | total loss: \u001b[1m\u001b[32m1.10969\u001b[0m\u001b[0m | time: 0.049s\n",
            "| Adam | epoch: 006 | loss: 1.10969 - acc: 0.8965 -- iter: 0448/2300\n",
            "Training Step: 375  | total loss: \u001b[1m\u001b[32m1.10037\u001b[0m\u001b[0m | time: 0.053s\n",
            "| Adam | epoch: 006 | loss: 1.10037 - acc: 0.9006 -- iter: 0480/2300\n",
            "Training Step: 376  | total loss: \u001b[1m\u001b[32m1.10495\u001b[0m\u001b[0m | time: 0.056s\n",
            "| Adam | epoch: 006 | loss: 1.10495 - acc: 0.9012 -- iter: 0512/2300\n",
            "Training Step: 377  | total loss: \u001b[1m\u001b[32m1.10720\u001b[0m\u001b[0m | time: 0.060s\n",
            "| Adam | epoch: 006 | loss: 1.10720 - acc: 0.9048 -- iter: 0544/2300\n",
            "Training Step: 378  | total loss: \u001b[1m\u001b[32m1.09992\u001b[0m\u001b[0m | time: 0.064s\n",
            "| Adam | epoch: 006 | loss: 1.09992 - acc: 0.9081 -- iter: 0576/2300\n",
            "Training Step: 379  | total loss: \u001b[1m\u001b[32m1.10131\u001b[0m\u001b[0m | time: 0.067s\n",
            "| Adam | epoch: 006 | loss: 1.10131 - acc: 0.9048 -- iter: 0608/2300\n",
            "Training Step: 380  | total loss: \u001b[1m\u001b[32m1.10922\u001b[0m\u001b[0m | time: 0.071s\n",
            "| Adam | epoch: 006 | loss: 1.10922 - acc: 0.8955 -- iter: 0640/2300\n",
            "Training Step: 381  | total loss: \u001b[1m\u001b[32m1.11162\u001b[0m\u001b[0m | time: 0.074s\n",
            "| Adam | epoch: 006 | loss: 1.11162 - acc: 0.8935 -- iter: 0672/2300\n",
            "Training Step: 382  | total loss: \u001b[1m\u001b[32m1.09965\u001b[0m\u001b[0m | time: 0.078s\n",
            "| Adam | epoch: 006 | loss: 1.09965 - acc: 0.9010 -- iter: 0704/2300\n",
            "Training Step: 383  | total loss: \u001b[1m\u001b[32m1.10555\u001b[0m\u001b[0m | time: 0.081s\n",
            "| Adam | epoch: 006 | loss: 1.10555 - acc: 0.8984 -- iter: 0736/2300\n",
            "Training Step: 384  | total loss: \u001b[1m\u001b[32m1.10471\u001b[0m\u001b[0m | time: 0.085s\n",
            "| Adam | epoch: 006 | loss: 1.10471 - acc: 0.9023 -- iter: 0768/2300\n",
            "Training Step: 385  | total loss: \u001b[1m\u001b[32m1.10973\u001b[0m\u001b[0m | time: 0.089s\n",
            "| Adam | epoch: 006 | loss: 1.10973 - acc: 0.8965 -- iter: 0800/2300\n",
            "Training Step: 386  | total loss: \u001b[1m\u001b[32m1.10433\u001b[0m\u001b[0m | time: 0.093s\n",
            "| Adam | epoch: 006 | loss: 1.10433 - acc: 0.9006 -- iter: 0832/2300\n",
            "Training Step: 387  | total loss: \u001b[1m\u001b[32m1.11181\u001b[0m\u001b[0m | time: 0.096s\n",
            "| Adam | epoch: 006 | loss: 1.11181 - acc: 0.9043 -- iter: 0864/2300\n",
            "Training Step: 388  | total loss: \u001b[1m\u001b[32m1.11241\u001b[0m\u001b[0m | time: 0.100s\n",
            "| Adam | epoch: 006 | loss: 1.11241 - acc: 0.9076 -- iter: 0896/2300\n",
            "Training Step: 389  | total loss: \u001b[1m\u001b[32m1.11385\u001b[0m\u001b[0m | time: 0.103s\n",
            "| Adam | epoch: 006 | loss: 1.11385 - acc: 0.9043 -- iter: 0928/2300\n",
            "Training Step: 390  | total loss: \u001b[1m\u001b[32m1.11429\u001b[0m\u001b[0m | time: 0.107s\n",
            "| Adam | epoch: 006 | loss: 1.11429 - acc: 0.9045 -- iter: 0960/2300\n",
            "Training Step: 391  | total loss: \u001b[1m\u001b[32m1.12094\u001b[0m\u001b[0m | time: 0.111s\n",
            "| Adam | epoch: 006 | loss: 1.12094 - acc: 0.9109 -- iter: 0992/2300\n",
            "Training Step: 392  | total loss: \u001b[1m\u001b[32m1.11570\u001b[0m\u001b[0m | time: 0.115s\n",
            "| Adam | epoch: 006 | loss: 1.11570 - acc: 0.9136 -- iter: 1024/2300\n",
            "Training Step: 393  | total loss: \u001b[1m\u001b[32m1.10934\u001b[0m\u001b[0m | time: 0.119s\n",
            "| Adam | epoch: 006 | loss: 1.10934 - acc: 0.9066 -- iter: 1056/2300\n",
            "Training Step: 394  | total loss: \u001b[1m\u001b[32m1.11389\u001b[0m\u001b[0m | time: 0.122s\n",
            "| Adam | epoch: 006 | loss: 1.11389 - acc: 0.9003 -- iter: 1088/2300\n",
            "Training Step: 395  | total loss: \u001b[1m\u001b[32m1.12169\u001b[0m\u001b[0m | time: 0.126s\n",
            "| Adam | epoch: 006 | loss: 1.12169 - acc: 0.8853 -- iter: 1120/2300\n",
            "Training Step: 396  | total loss: \u001b[1m\u001b[32m1.11908\u001b[0m\u001b[0m | time: 0.130s\n",
            "| Adam | epoch: 006 | loss: 1.11908 - acc: 0.8936 -- iter: 1152/2300\n",
            "Training Step: 397  | total loss: \u001b[1m\u001b[32m1.11996\u001b[0m\u001b[0m | time: 0.133s\n",
            "| Adam | epoch: 006 | loss: 1.11996 - acc: 0.8886 -- iter: 1184/2300\n",
            "Training Step: 398  | total loss: \u001b[1m\u001b[32m1.11733\u001b[0m\u001b[0m | time: 0.138s\n",
            "| Adam | epoch: 006 | loss: 1.11733 - acc: 0.8967 -- iter: 1216/2300\n",
            "Training Step: 399  | total loss: \u001b[1m\u001b[32m1.10788\u001b[0m\u001b[0m | time: 0.142s\n",
            "| Adam | epoch: 006 | loss: 1.10788 - acc: 0.9070 -- iter: 1248/2300\n",
            "Training Step: 400  | total loss: \u001b[1m\u001b[32m1.10508\u001b[0m\u001b[0m | time: 0.147s\n",
            "| Adam | epoch: 006 | loss: 1.10508 - acc: 0.9163 -- iter: 1280/2300\n",
            "Training Step: 401  | total loss: \u001b[1m\u001b[32m1.11238\u001b[0m\u001b[0m | time: 0.151s\n",
            "| Adam | epoch: 006 | loss: 1.11238 - acc: 0.9153 -- iter: 1312/2300\n",
            "Training Step: 402  | total loss: \u001b[1m\u001b[32m1.10912\u001b[0m\u001b[0m | time: 0.157s\n",
            "| Adam | epoch: 006 | loss: 1.10912 - acc: 0.9144 -- iter: 1344/2300\n",
            "Training Step: 403  | total loss: \u001b[1m\u001b[32m1.11218\u001b[0m\u001b[0m | time: 0.163s\n",
            "| Adam | epoch: 006 | loss: 1.11218 - acc: 0.9073 -- iter: 1376/2300\n",
            "Training Step: 404  | total loss: \u001b[1m\u001b[32m1.11271\u001b[0m\u001b[0m | time: 0.168s\n",
            "| Adam | epoch: 006 | loss: 1.11271 - acc: 0.9166 -- iter: 1408/2300\n",
            "Training Step: 405  | total loss: \u001b[1m\u001b[32m1.11165\u001b[0m\u001b[0m | time: 0.172s\n",
            "| Adam | epoch: 006 | loss: 1.11165 - acc: 0.9093 -- iter: 1440/2300\n",
            "Training Step: 406  | total loss: \u001b[1m\u001b[32m1.10922\u001b[0m\u001b[0m | time: 0.176s\n",
            "| Adam | epoch: 006 | loss: 1.10922 - acc: 0.8934 -- iter: 1472/2300\n",
            "Training Step: 407  | total loss: \u001b[1m\u001b[32m1.11170\u001b[0m\u001b[0m | time: 0.181s\n",
            "| Adam | epoch: 006 | loss: 1.11170 - acc: 0.8915 -- iter: 1504/2300\n",
            "Training Step: 408  | total loss: \u001b[1m\u001b[32m1.11426\u001b[0m\u001b[0m | time: 0.185s\n",
            "| Adam | epoch: 006 | loss: 1.11426 - acc: 0.8899 -- iter: 1536/2300\n",
            "Training Step: 409  | total loss: \u001b[1m\u001b[32m1.11138\u001b[0m\u001b[0m | time: 0.190s\n",
            "| Adam | epoch: 006 | loss: 1.11138 - acc: 0.8978 -- iter: 1568/2300\n",
            "Training Step: 410  | total loss: \u001b[1m\u001b[32m1.11918\u001b[0m\u001b[0m | time: 0.195s\n",
            "| Adam | epoch: 006 | loss: 1.11918 - acc: 0.8955 -- iter: 1600/2300\n",
            "Training Step: 411  | total loss: \u001b[1m\u001b[32m1.11929\u001b[0m\u001b[0m | time: 0.198s\n",
            "| Adam | epoch: 006 | loss: 1.11929 - acc: 0.8997 -- iter: 1632/2300\n",
            "Training Step: 412  | total loss: \u001b[1m\u001b[32m1.12585\u001b[0m\u001b[0m | time: 0.202s\n",
            "| Adam | epoch: 006 | loss: 1.12585 - acc: 0.9035 -- iter: 1664/2300\n",
            "Training Step: 413  | total loss: \u001b[1m\u001b[32m1.12870\u001b[0m\u001b[0m | time: 0.206s\n",
            "| Adam | epoch: 006 | loss: 1.12870 - acc: 0.9100 -- iter: 1696/2300\n",
            "Training Step: 414  | total loss: \u001b[1m\u001b[32m1.13248\u001b[0m\u001b[0m | time: 0.210s\n",
            "| Adam | epoch: 006 | loss: 1.13248 - acc: 0.9128 -- iter: 1728/2300\n",
            "Training Step: 415  | total loss: \u001b[1m\u001b[32m1.12671\u001b[0m\u001b[0m | time: 0.213s\n",
            "| Adam | epoch: 006 | loss: 1.12671 - acc: 0.9090 -- iter: 1760/2300\n",
            "Training Step: 416  | total loss: \u001b[1m\u001b[32m1.12683\u001b[0m\u001b[0m | time: 0.217s\n",
            "| Adam | epoch: 006 | loss: 1.12683 - acc: 0.9087 -- iter: 1792/2300\n",
            "Training Step: 417  | total loss: \u001b[1m\u001b[32m1.11652\u001b[0m\u001b[0m | time: 0.221s\n",
            "| Adam | epoch: 006 | loss: 1.11652 - acc: 0.9053 -- iter: 1824/2300\n",
            "Training Step: 418  | total loss: \u001b[1m\u001b[32m1.11788\u001b[0m\u001b[0m | time: 0.224s\n",
            "| Adam | epoch: 006 | loss: 1.11788 - acc: 0.9054 -- iter: 1856/2300\n",
            "Training Step: 419  | total loss: \u001b[1m\u001b[32m1.11928\u001b[0m\u001b[0m | time: 0.229s\n",
            "| Adam | epoch: 006 | loss: 1.11928 - acc: 0.9086 -- iter: 1888/2300\n",
            "Training Step: 420  | total loss: \u001b[1m\u001b[32m1.11114\u001b[0m\u001b[0m | time: 0.234s\n",
            "| Adam | epoch: 006 | loss: 1.11114 - acc: 0.9146 -- iter: 1920/2300\n",
            "Training Step: 421  | total loss: \u001b[1m\u001b[32m1.11020\u001b[0m\u001b[0m | time: 0.237s\n",
            "| Adam | epoch: 006 | loss: 1.11020 - acc: 0.9169 -- iter: 1952/2300\n",
            "Training Step: 422  | total loss: \u001b[1m\u001b[32m1.11526\u001b[0m\u001b[0m | time: 0.241s\n",
            "| Adam | epoch: 006 | loss: 1.11526 - acc: 0.9065 -- iter: 1984/2300\n",
            "Training Step: 423  | total loss: \u001b[1m\u001b[32m1.12139\u001b[0m\u001b[0m | time: 0.245s\n",
            "| Adam | epoch: 006 | loss: 1.12139 - acc: 0.9002 -- iter: 2016/2300\n",
            "Training Step: 424  | total loss: \u001b[1m\u001b[32m1.11507\u001b[0m\u001b[0m | time: 0.249s\n",
            "| Adam | epoch: 006 | loss: 1.11507 - acc: 0.9039 -- iter: 2048/2300\n",
            "Training Step: 425  | total loss: \u001b[1m\u001b[32m1.11549\u001b[0m\u001b[0m | time: 0.252s\n",
            "| Adam | epoch: 006 | loss: 1.11549 - acc: 0.9010 -- iter: 2080/2300\n",
            "Training Step: 426  | total loss: \u001b[1m\u001b[32m1.11415\u001b[0m\u001b[0m | time: 0.256s\n",
            "| Adam | epoch: 006 | loss: 1.11415 - acc: 0.8922 -- iter: 2112/2300\n",
            "Training Step: 427  | total loss: \u001b[1m\u001b[32m1.10527\u001b[0m\u001b[0m | time: 0.260s\n",
            "| Adam | epoch: 006 | loss: 1.10527 - acc: 0.8998 -- iter: 2144/2300\n",
            "Training Step: 428  | total loss: \u001b[1m\u001b[32m1.11618\u001b[0m\u001b[0m | time: 0.264s\n",
            "| Adam | epoch: 006 | loss: 1.11618 - acc: 0.9067 -- iter: 2176/2300\n",
            "Training Step: 429  | total loss: \u001b[1m\u001b[32m1.10709\u001b[0m\u001b[0m | time: 0.268s\n",
            "| Adam | epoch: 006 | loss: 1.10709 - acc: 0.9098 -- iter: 2208/2300\n",
            "Training Step: 430  | total loss: \u001b[1m\u001b[32m1.11113\u001b[0m\u001b[0m | time: 0.272s\n",
            "| Adam | epoch: 006 | loss: 1.11113 - acc: 0.9126 -- iter: 2240/2300\n",
            "Training Step: 431  | total loss: \u001b[1m\u001b[32m1.11329\u001b[0m\u001b[0m | time: 0.276s\n",
            "| Adam | epoch: 006 | loss: 1.11329 - acc: 0.9151 -- iter: 2272/2300\n",
            "Training Step: 432  | total loss: \u001b[1m\u001b[32m1.11983\u001b[0m\u001b[0m | time: 0.281s\n",
            "| Adam | epoch: 006 | loss: 1.11983 - acc: 0.9079 -- iter: 2300/2300\n",
            "--\n",
            "Training Step: 433  | total loss: \u001b[1m\u001b[32m1.11629\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 007 | loss: 1.11629 - acc: 0.9140 -- iter: 0032/2300\n",
            "Training Step: 434  | total loss: \u001b[1m\u001b[32m1.11470\u001b[0m\u001b[0m | time: 0.009s\n",
            "| Adam | epoch: 007 | loss: 1.11470 - acc: 0.9132 -- iter: 0064/2300\n",
            "Training Step: 435  | total loss: \u001b[1m\u001b[32m1.10954\u001b[0m\u001b[0m | time: 0.013s\n",
            "| Adam | epoch: 007 | loss: 1.10954 - acc: 0.9157 -- iter: 0096/2300\n",
            "Training Step: 436  | total loss: \u001b[1m\u001b[32m1.11140\u001b[0m\u001b[0m | time: 0.017s\n",
            "| Adam | epoch: 007 | loss: 1.11140 - acc: 0.9022 -- iter: 0128/2300\n",
            "Training Step: 437  | total loss: \u001b[1m\u001b[32m1.11172\u001b[0m\u001b[0m | time: 0.020s\n",
            "| Adam | epoch: 007 | loss: 1.11172 - acc: 0.9026 -- iter: 0160/2300\n",
            "Training Step: 438  | total loss: \u001b[1m\u001b[32m1.11807\u001b[0m\u001b[0m | time: 0.024s\n",
            "| Adam | epoch: 007 | loss: 1.11807 - acc: 0.9088 -- iter: 0192/2300\n",
            "Training Step: 439  | total loss: \u001b[1m\u001b[32m1.12386\u001b[0m\u001b[0m | time: 0.028s\n",
            "| Adam | epoch: 007 | loss: 1.12386 - acc: 0.9143 -- iter: 0224/2300\n",
            "Training Step: 440  | total loss: \u001b[1m\u001b[32m1.12243\u001b[0m\u001b[0m | time: 0.032s\n",
            "| Adam | epoch: 007 | loss: 1.12243 - acc: 0.9198 -- iter: 0256/2300\n",
            "Training Step: 441  | total loss: \u001b[1m\u001b[32m1.12687\u001b[0m\u001b[0m | time: 0.036s\n",
            "| Adam | epoch: 007 | loss: 1.12687 - acc: 0.9153 -- iter: 0288/2300\n",
            "Training Step: 442  | total loss: \u001b[1m\u001b[32m1.11506\u001b[0m\u001b[0m | time: 0.039s\n",
            "| Adam | epoch: 007 | loss: 1.11506 - acc: 0.9144 -- iter: 0320/2300\n",
            "Training Step: 443  | total loss: \u001b[1m\u001b[32m1.10711\u001b[0m\u001b[0m | time: 0.042s\n",
            "| Adam | epoch: 007 | loss: 1.10711 - acc: 0.9198 -- iter: 0352/2300\n",
            "Training Step: 444  | total loss: \u001b[1m\u001b[32m1.10229\u001b[0m\u001b[0m | time: 0.046s\n",
            "| Adam | epoch: 007 | loss: 1.10229 - acc: 0.9185 -- iter: 0384/2300\n",
            "Training Step: 445  | total loss: \u001b[1m\u001b[32m1.11175\u001b[0m\u001b[0m | time: 0.050s\n",
            "| Adam | epoch: 007 | loss: 1.11175 - acc: 0.9079 -- iter: 0416/2300\n",
            "Training Step: 446  | total loss: \u001b[1m\u001b[32m1.10464\u001b[0m\u001b[0m | time: 0.054s\n",
            "| Adam | epoch: 007 | loss: 1.10464 - acc: 0.9140 -- iter: 0448/2300\n",
            "Training Step: 447  | total loss: \u001b[1m\u001b[32m1.10236\u001b[0m\u001b[0m | time: 0.058s\n",
            "| Adam | epoch: 007 | loss: 1.10236 - acc: 0.9194 -- iter: 0480/2300\n",
            "Training Step: 448  | total loss: \u001b[1m\u001b[32m1.10254\u001b[0m\u001b[0m | time: 0.061s\n",
            "| Adam | epoch: 007 | loss: 1.10254 - acc: 0.9119 -- iter: 0512/2300\n",
            "Training Step: 449  | total loss: \u001b[1m\u001b[32m1.09673\u001b[0m\u001b[0m | time: 0.065s\n",
            "| Adam | epoch: 007 | loss: 1.09673 - acc: 0.9113 -- iter: 0544/2300\n",
            "Training Step: 450  | total loss: \u001b[1m\u001b[32m1.10413\u001b[0m\u001b[0m | time: 0.069s\n",
            "| Adam | epoch: 007 | loss: 1.10413 - acc: 0.9139 -- iter: 0576/2300\n",
            "Training Step: 451  | total loss: \u001b[1m\u001b[32m1.10442\u001b[0m\u001b[0m | time: 0.073s\n",
            "| Adam | epoch: 007 | loss: 1.10442 - acc: 0.9132 -- iter: 0608/2300\n",
            "Training Step: 452  | total loss: \u001b[1m\u001b[32m1.10068\u001b[0m\u001b[0m | time: 0.077s\n",
            "| Adam | epoch: 007 | loss: 1.10068 - acc: 0.9062 -- iter: 0640/2300\n",
            "Training Step: 453  | total loss: \u001b[1m\u001b[32m1.10087\u001b[0m\u001b[0m | time: 0.081s\n",
            "| Adam | epoch: 007 | loss: 1.10087 - acc: 0.9031 -- iter: 0672/2300\n",
            "Training Step: 454  | total loss: \u001b[1m\u001b[32m1.09733\u001b[0m\u001b[0m | time: 0.085s\n",
            "| Adam | epoch: 007 | loss: 1.09733 - acc: 0.9034 -- iter: 0704/2300\n",
            "Training Step: 455  | total loss: \u001b[1m\u001b[32m1.09248\u001b[0m\u001b[0m | time: 0.090s\n",
            "| Adam | epoch: 007 | loss: 1.09248 - acc: 0.9099 -- iter: 0736/2300\n",
            "Training Step: 456  | total loss: \u001b[1m\u001b[32m1.08733\u001b[0m\u001b[0m | time: 0.093s\n",
            "| Adam | epoch: 007 | loss: 1.08733 - acc: 0.9158 -- iter: 0768/2300\n",
            "Training Step: 457  | total loss: \u001b[1m\u001b[32m1.08761\u001b[0m\u001b[0m | time: 0.098s\n",
            "| Adam | epoch: 007 | loss: 1.08761 - acc: 0.9117 -- iter: 0800/2300\n",
            "Training Step: 458  | total loss: \u001b[1m\u001b[32m1.08906\u001b[0m\u001b[0m | time: 0.102s\n",
            "| Adam | epoch: 007 | loss: 1.08906 - acc: 0.9112 -- iter: 0832/2300\n",
            "Training Step: 459  | total loss: \u001b[1m\u001b[32m1.09222\u001b[0m\u001b[0m | time: 0.106s\n",
            "| Adam | epoch: 007 | loss: 1.09222 - acc: 0.9107 -- iter: 0864/2300\n",
            "Training Step: 460  | total loss: \u001b[1m\u001b[32m1.09340\u001b[0m\u001b[0m | time: 0.110s\n",
            "| Adam | epoch: 007 | loss: 1.09340 - acc: 0.9165 -- iter: 0896/2300\n",
            "Training Step: 461  | total loss: \u001b[1m\u001b[32m1.09380\u001b[0m\u001b[0m | time: 0.113s\n",
            "| Adam | epoch: 007 | loss: 1.09380 - acc: 0.9155 -- iter: 0928/2300\n",
            "Training Step: 462  | total loss: \u001b[1m\u001b[32m1.09156\u001b[0m\u001b[0m | time: 0.118s\n",
            "| Adam | epoch: 007 | loss: 1.09156 - acc: 0.9114 -- iter: 0960/2300\n",
            "Training Step: 463  | total loss: \u001b[1m\u001b[32m1.10211\u001b[0m\u001b[0m | time: 0.122s\n",
            "| Adam | epoch: 007 | loss: 1.10211 - acc: 0.9109 -- iter: 0992/2300\n",
            "Training Step: 464  | total loss: \u001b[1m\u001b[32m1.09769\u001b[0m\u001b[0m | time: 0.126s\n",
            "| Adam | epoch: 007 | loss: 1.09769 - acc: 0.9011 -- iter: 1024/2300\n",
            "Training Step: 465  | total loss: \u001b[1m\u001b[32m1.09491\u001b[0m\u001b[0m | time: 0.130s\n",
            "| Adam | epoch: 007 | loss: 1.09491 - acc: 0.8985 -- iter: 1056/2300\n",
            "Training Step: 466  | total loss: \u001b[1m\u001b[32m1.09824\u001b[0m\u001b[0m | time: 0.134s\n",
            "| Adam | epoch: 007 | loss: 1.09824 - acc: 0.8899 -- iter: 1088/2300\n",
            "Training Step: 467  | total loss: \u001b[1m\u001b[32m1.09285\u001b[0m\u001b[0m | time: 0.138s\n",
            "| Adam | epoch: 007 | loss: 1.09285 - acc: 0.8884 -- iter: 1120/2300\n",
            "Training Step: 468  | total loss: \u001b[1m\u001b[32m1.09714\u001b[0m\u001b[0m | time: 0.141s\n",
            "| Adam | epoch: 007 | loss: 1.09714 - acc: 0.8870 -- iter: 1152/2300\n",
            "Training Step: 469  | total loss: \u001b[1m\u001b[32m1.09573\u001b[0m\u001b[0m | time: 0.145s\n",
            "| Adam | epoch: 007 | loss: 1.09573 - acc: 0.8921 -- iter: 1184/2300\n",
            "Training Step: 470  | total loss: \u001b[1m\u001b[32m1.10080\u001b[0m\u001b[0m | time: 0.148s\n",
            "| Adam | epoch: 007 | loss: 1.10080 - acc: 0.8873 -- iter: 1216/2300\n",
            "Training Step: 471  | total loss: \u001b[1m\u001b[32m1.09737\u001b[0m\u001b[0m | time: 0.151s\n",
            "| Adam | epoch: 007 | loss: 1.09737 - acc: 0.8923 -- iter: 1248/2300\n",
            "Training Step: 472  | total loss: \u001b[1m\u001b[32m1.10774\u001b[0m\u001b[0m | time: 0.155s\n",
            "| Adam | epoch: 007 | loss: 1.10774 - acc: 0.8906 -- iter: 1280/2300\n",
            "Training Step: 473  | total loss: \u001b[1m\u001b[32m1.10371\u001b[0m\u001b[0m | time: 0.159s\n",
            "| Adam | epoch: 007 | loss: 1.10371 - acc: 0.9015 -- iter: 1312/2300\n",
            "Training Step: 474  | total loss: \u001b[1m\u001b[32m1.10777\u001b[0m\u001b[0m | time: 0.162s\n",
            "| Adam | epoch: 007 | loss: 1.10777 - acc: 0.9020 -- iter: 1344/2300\n",
            "Training Step: 475  | total loss: \u001b[1m\u001b[32m1.10878\u001b[0m\u001b[0m | time: 0.166s\n",
            "| Adam | epoch: 007 | loss: 1.10878 - acc: 0.9024 -- iter: 1376/2300\n",
            "Training Step: 476  | total loss: \u001b[1m\u001b[32m1.10577\u001b[0m\u001b[0m | time: 0.169s\n",
            "| Adam | epoch: 007 | loss: 1.10577 - acc: 0.9090 -- iter: 1408/2300\n",
            "Training Step: 477  | total loss: \u001b[1m\u001b[32m1.09741\u001b[0m\u001b[0m | time: 0.174s\n",
            "| Adam | epoch: 007 | loss: 1.09741 - acc: 0.9056 -- iter: 1440/2300\n",
            "Training Step: 478  | total loss: \u001b[1m\u001b[32m1.09344\u001b[0m\u001b[0m | time: 0.180s\n",
            "| Adam | epoch: 007 | loss: 1.09344 - acc: 0.9088 -- iter: 1472/2300\n",
            "Training Step: 479  | total loss: \u001b[1m\u001b[32m1.10103\u001b[0m\u001b[0m | time: 0.184s\n",
            "| Adam | epoch: 007 | loss: 1.10103 - acc: 0.9054 -- iter: 1504/2300\n",
            "Training Step: 480  | total loss: \u001b[1m\u001b[32m1.10712\u001b[0m\u001b[0m | time: 0.188s\n",
            "| Adam | epoch: 007 | loss: 1.10712 - acc: 0.9086 -- iter: 1536/2300\n",
            "Training Step: 481  | total loss: \u001b[1m\u001b[32m1.10454\u001b[0m\u001b[0m | time: 0.192s\n",
            "| Adam | epoch: 007 | loss: 1.10454 - acc: 0.8990 -- iter: 1568/2300\n",
            "Training Step: 482  | total loss: \u001b[1m\u001b[32m1.11667\u001b[0m\u001b[0m | time: 0.195s\n",
            "| Adam | epoch: 007 | loss: 1.11667 - acc: 0.9029 -- iter: 1600/2300\n",
            "Training Step: 483  | total loss: \u001b[1m\u001b[32m1.11832\u001b[0m\u001b[0m | time: 0.199s\n",
            "| Adam | epoch: 007 | loss: 1.11832 - acc: 0.9063 -- iter: 1632/2300\n",
            "Training Step: 484  | total loss: \u001b[1m\u001b[32m1.11677\u001b[0m\u001b[0m | time: 0.202s\n",
            "| Adam | epoch: 007 | loss: 1.11677 - acc: 0.9032 -- iter: 1664/2300\n",
            "Training Step: 485  | total loss: \u001b[1m\u001b[32m1.12402\u001b[0m\u001b[0m | time: 0.206s\n",
            "| Adam | epoch: 007 | loss: 1.12402 - acc: 0.8941 -- iter: 1696/2300\n",
            "Training Step: 486  | total loss: \u001b[1m\u001b[32m1.11678\u001b[0m\u001b[0m | time: 0.210s\n",
            "| Adam | epoch: 007 | loss: 1.11678 - acc: 0.8985 -- iter: 1728/2300\n",
            "Training Step: 487  | total loss: \u001b[1m\u001b[32m1.11222\u001b[0m\u001b[0m | time: 0.214s\n",
            "| Adam | epoch: 007 | loss: 1.11222 - acc: 0.8930 -- iter: 1760/2300\n",
            "Training Step: 488  | total loss: \u001b[1m\u001b[32m1.10789\u001b[0m\u001b[0m | time: 0.218s\n",
            "| Adam | epoch: 007 | loss: 1.10789 - acc: 0.8974 -- iter: 1792/2300\n",
            "Training Step: 489  | total loss: \u001b[1m\u001b[32m1.10636\u001b[0m\u001b[0m | time: 0.221s\n",
            "| Adam | epoch: 007 | loss: 1.10636 - acc: 0.9015 -- iter: 1824/2300\n",
            "Training Step: 490  | total loss: \u001b[1m\u001b[32m1.11114\u001b[0m\u001b[0m | time: 0.225s\n",
            "| Adam | epoch: 007 | loss: 1.11114 - acc: 0.9019 -- iter: 1856/2300\n",
            "Training Step: 491  | total loss: \u001b[1m\u001b[32m1.10626\u001b[0m\u001b[0m | time: 0.228s\n",
            "| Adam | epoch: 007 | loss: 1.10626 - acc: 0.9055 -- iter: 1888/2300\n",
            "Training Step: 492  | total loss: \u001b[1m\u001b[32m1.10620\u001b[0m\u001b[0m | time: 0.232s\n",
            "| Adam | epoch: 007 | loss: 1.10620 - acc: 0.9118 -- iter: 1920/2300\n",
            "Training Step: 493  | total loss: \u001b[1m\u001b[32m1.10582\u001b[0m\u001b[0m | time: 0.236s\n",
            "| Adam | epoch: 007 | loss: 1.10582 - acc: 0.9019 -- iter: 1952/2300\n",
            "Training Step: 494  | total loss: \u001b[1m\u001b[32m1.10829\u001b[0m\u001b[0m | time: 0.239s\n",
            "| Adam | epoch: 007 | loss: 1.10829 - acc: 0.9117 -- iter: 1984/2300\n",
            "Training Step: 495  | total loss: \u001b[1m\u001b[32m1.10611\u001b[0m\u001b[0m | time: 0.243s\n",
            "| Adam | epoch: 007 | loss: 1.10611 - acc: 0.9080 -- iter: 2016/2300\n",
            "Training Step: 496  | total loss: \u001b[1m\u001b[32m1.10308\u001b[0m\u001b[0m | time: 0.247s\n",
            "| Adam | epoch: 007 | loss: 1.10308 - acc: 0.9078 -- iter: 2048/2300\n",
            "Training Step: 497  | total loss: \u001b[1m\u001b[32m1.09028\u001b[0m\u001b[0m | time: 0.250s\n",
            "| Adam | epoch: 007 | loss: 1.09028 - acc: 0.9171 -- iter: 2080/2300\n",
            "Training Step: 498  | total loss: \u001b[1m\u001b[32m1.09412\u001b[0m\u001b[0m | time: 0.254s\n",
            "| Adam | epoch: 007 | loss: 1.09412 - acc: 0.9035 -- iter: 2112/2300\n",
            "Training Step: 499  | total loss: \u001b[1m\u001b[32m1.10665\u001b[0m\u001b[0m | time: 0.257s\n",
            "| Adam | epoch: 007 | loss: 1.10665 - acc: 0.9006 -- iter: 2144/2300\n",
            "Training Step: 500  | total loss: \u001b[1m\u001b[32m1.11317\u001b[0m\u001b[0m | time: 0.261s\n",
            "| Adam | epoch: 007 | loss: 1.11317 - acc: 0.9043 -- iter: 2176/2300\n",
            "Training Step: 501  | total loss: \u001b[1m\u001b[32m1.11657\u001b[0m\u001b[0m | time: 0.264s\n",
            "| Adam | epoch: 007 | loss: 1.11657 - acc: 0.9045 -- iter: 2208/2300\n",
            "Training Step: 502  | total loss: \u001b[1m\u001b[32m1.12008\u001b[0m\u001b[0m | time: 0.268s\n",
            "| Adam | epoch: 007 | loss: 1.12008 - acc: 0.8953 -- iter: 2240/2300\n",
            "Training Step: 503  | total loss: \u001b[1m\u001b[32m1.12155\u001b[0m\u001b[0m | time: 0.272s\n",
            "| Adam | epoch: 007 | loss: 1.12155 - acc: 0.8964 -- iter: 2272/2300\n",
            "Training Step: 504  | total loss: \u001b[1m\u001b[32m1.12966\u001b[0m\u001b[0m | time: 0.275s\n",
            "| Adam | epoch: 007 | loss: 1.12966 - acc: 0.8943 -- iter: 2300/2300\n",
            "--\n",
            "Training Step: 505  | total loss: \u001b[1m\u001b[32m1.13122\u001b[0m\u001b[0m | time: 0.005s\n",
            "| Adam | epoch: 008 | loss: 1.13122 - acc: 0.8955 -- iter: 0032/2300\n",
            "Training Step: 506  | total loss: \u001b[1m\u001b[32m1.12751\u001b[0m\u001b[0m | time: 0.009s\n",
            "| Adam | epoch: 008 | loss: 1.12751 - acc: 0.8934 -- iter: 0064/2300\n",
            "Training Step: 507  | total loss: \u001b[1m\u001b[32m1.12544\u001b[0m\u001b[0m | time: 0.013s\n",
            "| Adam | epoch: 008 | loss: 1.12544 - acc: 0.9041 -- iter: 0096/2300\n",
            "Training Step: 508  | total loss: \u001b[1m\u001b[32m1.11810\u001b[0m\u001b[0m | time: 0.016s\n",
            "| Adam | epoch: 008 | loss: 1.11810 - acc: 0.8980 -- iter: 0128/2300\n",
            "Training Step: 509  | total loss: \u001b[1m\u001b[32m1.11350\u001b[0m\u001b[0m | time: 0.019s\n",
            "| Adam | epoch: 008 | loss: 1.11350 - acc: 0.9020 -- iter: 0160/2300\n",
            "Training Step: 510  | total loss: \u001b[1m\u001b[32m1.11613\u001b[0m\u001b[0m | time: 0.023s\n",
            "| Adam | epoch: 008 | loss: 1.11613 - acc: 0.9055 -- iter: 0192/2300\n",
            "Training Step: 511  | total loss: \u001b[1m\u001b[32m1.11514\u001b[0m\u001b[0m | time: 0.027s\n",
            "| Adam | epoch: 008 | loss: 1.11514 - acc: 0.9150 -- iter: 0224/2300\n",
            "Training Step: 512  | total loss: \u001b[1m\u001b[32m1.11419\u001b[0m\u001b[0m | time: 0.030s\n",
            "| Adam | epoch: 008 | loss: 1.11419 - acc: 0.9235 -- iter: 0256/2300\n",
            "Training Step: 513  | total loss: \u001b[1m\u001b[32m1.12083\u001b[0m\u001b[0m | time: 0.034s\n",
            "| Adam | epoch: 008 | loss: 1.12083 - acc: 0.9124 -- iter: 0288/2300\n",
            "Training Step: 514  | total loss: \u001b[1m\u001b[32m1.11817\u001b[0m\u001b[0m | time: 0.038s\n",
            "| Adam | epoch: 008 | loss: 1.11817 - acc: 0.9149 -- iter: 0320/2300\n",
            "Training Step: 515  | total loss: \u001b[1m\u001b[32m1.11748\u001b[0m\u001b[0m | time: 0.041s\n",
            "| Adam | epoch: 008 | loss: 1.11748 - acc: 0.9140 -- iter: 0352/2300\n",
            "Training Step: 516  | total loss: \u001b[1m\u001b[32m1.11513\u001b[0m\u001b[0m | time: 0.045s\n",
            "| Adam | epoch: 008 | loss: 1.11513 - acc: 0.9070 -- iter: 0384/2300\n",
            "Training Step: 517  | total loss: \u001b[1m\u001b[32m1.11942\u001b[0m\u001b[0m | time: 0.049s\n",
            "| Adam | epoch: 008 | loss: 1.11942 - acc: 0.9038 -- iter: 0416/2300\n",
            "Training Step: 518  | total loss: \u001b[1m\u001b[32m1.12123\u001b[0m\u001b[0m | time: 0.053s\n",
            "| Adam | epoch: 008 | loss: 1.12123 - acc: 0.9072 -- iter: 0448/2300\n",
            "Training Step: 519  | total loss: \u001b[1m\u001b[32m1.12256\u001b[0m\u001b[0m | time: 0.056s\n",
            "| Adam | epoch: 008 | loss: 1.12256 - acc: 0.9133 -- iter: 0480/2300\n",
            "Training Step: 520  | total loss: \u001b[1m\u001b[32m1.11674\u001b[0m\u001b[0m | time: 0.059s\n",
            "| Adam | epoch: 008 | loss: 1.11674 - acc: 0.9095 -- iter: 0512/2300\n",
            "Training Step: 521  | total loss: \u001b[1m\u001b[32m1.11045\u001b[0m\u001b[0m | time: 0.063s\n",
            "| Adam | epoch: 008 | loss: 1.11045 - acc: 0.9060 -- iter: 0544/2300\n",
            "Training Step: 522  | total loss: \u001b[1m\u001b[32m1.10879\u001b[0m\u001b[0m | time: 0.067s\n",
            "| Adam | epoch: 008 | loss: 1.10879 - acc: 0.9061 -- iter: 0576/2300\n",
            "Training Step: 523  | total loss: \u001b[1m\u001b[32m1.09873\u001b[0m\u001b[0m | time: 0.070s\n",
            "| Adam | epoch: 008 | loss: 1.09873 - acc: 0.9092 -- iter: 0608/2300\n",
            "Training Step: 524  | total loss: \u001b[1m\u001b[32m1.09605\u001b[0m\u001b[0m | time: 0.074s\n",
            "| Adam | epoch: 008 | loss: 1.09605 - acc: 0.9120 -- iter: 0640/2300\n",
            "Training Step: 525  | total loss: \u001b[1m\u001b[32m1.09268\u001b[0m\u001b[0m | time: 0.078s\n",
            "| Adam | epoch: 008 | loss: 1.09268 - acc: 0.9146 -- iter: 0672/2300\n",
            "Training Step: 526  | total loss: \u001b[1m\u001b[32m1.08396\u001b[0m\u001b[0m | time: 0.081s\n",
            "| Adam | epoch: 008 | loss: 1.08396 - acc: 0.9169 -- iter: 0704/2300\n",
            "Training Step: 527  | total loss: \u001b[1m\u001b[32m1.08053\u001b[0m\u001b[0m | time: 0.085s\n",
            "| Adam | epoch: 008 | loss: 1.08053 - acc: 0.9221 -- iter: 0736/2300\n",
            "Training Step: 528  | total loss: \u001b[1m\u001b[32m1.08291\u001b[0m\u001b[0m | time: 0.089s\n",
            "| Adam | epoch: 008 | loss: 1.08291 - acc: 0.9142 -- iter: 0768/2300\n",
            "Training Step: 529  | total loss: \u001b[1m\u001b[32m1.07711\u001b[0m\u001b[0m | time: 0.092s\n",
            "| Adam | epoch: 008 | loss: 1.07711 - acc: 0.9197 -- iter: 0800/2300\n",
            "Training Step: 530  | total loss: \u001b[1m\u001b[32m1.08329\u001b[0m\u001b[0m | time: 0.097s\n",
            "| Adam | epoch: 008 | loss: 1.08329 - acc: 0.9121 -- iter: 0832/2300\n",
            "Training Step: 531  | total loss: \u001b[1m\u001b[32m1.08176\u001b[0m\u001b[0m | time: 0.103s\n",
            "| Adam | epoch: 008 | loss: 1.08176 - acc: 0.9178 -- iter: 0864/2300\n",
            "Training Step: 532  | total loss: \u001b[1m\u001b[32m1.09095\u001b[0m\u001b[0m | time: 0.107s\n",
            "| Adam | epoch: 008 | loss: 1.09095 - acc: 0.9104 -- iter: 0896/2300\n",
            "Training Step: 533  | total loss: \u001b[1m\u001b[32m1.09210\u001b[0m\u001b[0m | time: 0.110s\n",
            "| Adam | epoch: 008 | loss: 1.09210 - acc: 0.9099 -- iter: 0928/2300\n",
            "Training Step: 534  | total loss: \u001b[1m\u001b[32m1.10004\u001b[0m\u001b[0m | time: 0.114s\n",
            "| Adam | epoch: 008 | loss: 1.10004 - acc: 0.9033 -- iter: 0960/2300\n",
            "Training Step: 535  | total loss: \u001b[1m\u001b[32m1.09762\u001b[0m\u001b[0m | time: 0.118s\n",
            "| Adam | epoch: 008 | loss: 1.09762 - acc: 0.8974 -- iter: 0992/2300\n",
            "Training Step: 536  | total loss: \u001b[1m\u001b[32m1.09699\u001b[0m\u001b[0m | time: 0.121s\n",
            "| Adam | epoch: 008 | loss: 1.09699 - acc: 0.9014 -- iter: 1024/2300\n",
            "Training Step: 537  | total loss: \u001b[1m\u001b[32m1.10730\u001b[0m\u001b[0m | time: 0.125s\n",
            "| Adam | epoch: 008 | loss: 1.10730 - acc: 0.9019 -- iter: 1056/2300\n",
            "Training Step: 538  | total loss: \u001b[1m\u001b[32m1.11509\u001b[0m\u001b[0m | time: 0.129s\n",
            "| Adam | epoch: 008 | loss: 1.11509 - acc: 0.8961 -- iter: 1088/2300\n",
            "Training Step: 539  | total loss: \u001b[1m\u001b[32m1.10536\u001b[0m\u001b[0m | time: 0.133s\n",
            "| Adam | epoch: 008 | loss: 1.10536 - acc: 0.8940 -- iter: 1120/2300\n",
            "Training Step: 540  | total loss: \u001b[1m\u001b[32m1.09825\u001b[0m\u001b[0m | time: 0.137s\n",
            "| Adam | epoch: 008 | loss: 1.09825 - acc: 0.9014 -- iter: 1152/2300\n",
            "Training Step: 541  | total loss: \u001b[1m\u001b[32m1.10341\u001b[0m\u001b[0m | time: 0.140s\n",
            "| Adam | epoch: 008 | loss: 1.10341 - acc: 0.9019 -- iter: 1184/2300\n",
            "Training Step: 542  | total loss: \u001b[1m\u001b[32m1.10549\u001b[0m\u001b[0m | time: 0.144s\n",
            "| Adam | epoch: 008 | loss: 1.10549 - acc: 0.9055 -- iter: 1216/2300\n",
            "Training Step: 543  | total loss: \u001b[1m\u001b[32m1.10388\u001b[0m\u001b[0m | time: 0.148s\n",
            "| Adam | epoch: 008 | loss: 1.10388 - acc: 0.8962 -- iter: 1248/2300\n",
            "Training Step: 544  | total loss: \u001b[1m\u001b[32m1.10187\u001b[0m\u001b[0m | time: 0.151s\n",
            "| Adam | epoch: 008 | loss: 1.10187 - acc: 0.9066 -- iter: 1280/2300\n",
            "Training Step: 545  | total loss: \u001b[1m\u001b[32m1.10279\u001b[0m\u001b[0m | time: 0.155s\n",
            "| Adam | epoch: 008 | loss: 1.10279 - acc: 0.9097 -- iter: 1312/2300\n",
            "Training Step: 546  | total loss: \u001b[1m\u001b[32m1.10436\u001b[0m\u001b[0m | time: 0.159s\n",
            "| Adam | epoch: 008 | loss: 1.10436 - acc: 0.9093 -- iter: 1344/2300\n",
            "Training Step: 547  | total loss: \u001b[1m\u001b[32m1.09721\u001b[0m\u001b[0m | time: 0.162s\n",
            "| Adam | epoch: 008 | loss: 1.09721 - acc: 0.8934 -- iter: 1376/2300\n",
            "Training Step: 548  | total loss: \u001b[1m\u001b[32m1.09746\u001b[0m\u001b[0m | time: 0.166s\n",
            "| Adam | epoch: 008 | loss: 1.09746 - acc: 0.9009 -- iter: 1408/2300\n",
            "Training Step: 549  | total loss: \u001b[1m\u001b[32m1.08935\u001b[0m\u001b[0m | time: 0.170s\n",
            "| Adam | epoch: 008 | loss: 1.08935 - acc: 0.9046 -- iter: 1440/2300\n",
            "Training Step: 550  | total loss: \u001b[1m\u001b[32m1.09032\u001b[0m\u001b[0m | time: 0.173s\n",
            "| Adam | epoch: 008 | loss: 1.09032 - acc: 0.9047 -- iter: 1472/2300\n",
            "Training Step: 551  | total loss: \u001b[1m\u001b[32m1.09303\u001b[0m\u001b[0m | time: 0.177s\n",
            "| Adam | epoch: 008 | loss: 1.09303 - acc: 0.8986 -- iter: 1504/2300\n",
            "Training Step: 552  | total loss: \u001b[1m\u001b[32m1.09651\u001b[0m\u001b[0m | time: 0.180s\n",
            "| Adam | epoch: 008 | loss: 1.09651 - acc: 0.9025 -- iter: 1536/2300\n",
            "Training Step: 553  | total loss: \u001b[1m\u001b[32m1.10267\u001b[0m\u001b[0m | time: 0.184s\n",
            "| Adam | epoch: 008 | loss: 1.10267 - acc: 0.8873 -- iter: 1568/2300\n",
            "Training Step: 554  | total loss: \u001b[1m\u001b[32m1.10793\u001b[0m\u001b[0m | time: 0.187s\n",
            "| Adam | epoch: 008 | loss: 1.10793 - acc: 0.8829 -- iter: 1600/2300\n",
            "Training Step: 555  | total loss: \u001b[1m\u001b[32m1.10687\u001b[0m\u001b[0m | time: 0.191s\n",
            "| Adam | epoch: 008 | loss: 1.10687 - acc: 0.8884 -- iter: 1632/2300\n",
            "Training Step: 556  | total loss: \u001b[1m\u001b[32m1.09943\u001b[0m\u001b[0m | time: 0.195s\n",
            "| Adam | epoch: 008 | loss: 1.09943 - acc: 0.8933 -- iter: 1664/2300\n",
            "Training Step: 557  | total loss: \u001b[1m\u001b[32m1.09283\u001b[0m\u001b[0m | time: 0.199s\n",
            "| Adam | epoch: 008 | loss: 1.09283 - acc: 0.9008 -- iter: 1696/2300\n",
            "Training Step: 558  | total loss: \u001b[1m\u001b[32m1.09978\u001b[0m\u001b[0m | time: 0.202s\n",
            "| Adam | epoch: 008 | loss: 1.09978 - acc: 0.9076 -- iter: 1728/2300\n",
            "Training Step: 559  | total loss: \u001b[1m\u001b[32m1.08758\u001b[0m\u001b[0m | time: 0.206s\n",
            "| Adam | epoch: 008 | loss: 1.08758 - acc: 0.9075 -- iter: 1760/2300\n",
            "Training Step: 560  | total loss: \u001b[1m\u001b[32m1.08370\u001b[0m\u001b[0m | time: 0.209s\n",
            "| Adam | epoch: 008 | loss: 1.08370 - acc: 0.9105 -- iter: 1792/2300\n",
            "Training Step: 561  | total loss: \u001b[1m\u001b[32m1.07873\u001b[0m\u001b[0m | time: 0.213s\n",
            "| Adam | epoch: 008 | loss: 1.07873 - acc: 0.9132 -- iter: 1824/2300\n",
            "Training Step: 562  | total loss: \u001b[1m\u001b[32m1.08437\u001b[0m\u001b[0m | time: 0.217s\n",
            "| Adam | epoch: 008 | loss: 1.08437 - acc: 0.9125 -- iter: 1856/2300\n",
            "Training Step: 563  | total loss: \u001b[1m\u001b[32m1.08682\u001b[0m\u001b[0m | time: 0.220s\n",
            "| Adam | epoch: 008 | loss: 1.08682 - acc: 0.9181 -- iter: 1888/2300\n",
            "Training Step: 564  | total loss: \u001b[1m\u001b[32m1.09263\u001b[0m\u001b[0m | time: 0.224s\n",
            "| Adam | epoch: 008 | loss: 1.09263 - acc: 0.9169 -- iter: 1920/2300\n",
            "Training Step: 565  | total loss: \u001b[1m\u001b[32m1.08794\u001b[0m\u001b[0m | time: 0.227s\n",
            "| Adam | epoch: 008 | loss: 1.08794 - acc: 0.9127 -- iter: 1952/2300\n",
            "Training Step: 566  | total loss: \u001b[1m\u001b[32m1.07970\u001b[0m\u001b[0m | time: 0.231s\n",
            "| Adam | epoch: 008 | loss: 1.07970 - acc: 0.9152 -- iter: 1984/2300\n",
            "Training Step: 567  | total loss: \u001b[1m\u001b[32m1.08425\u001b[0m\u001b[0m | time: 0.234s\n",
            "| Adam | epoch: 008 | loss: 1.08425 - acc: 0.9112 -- iter: 2016/2300\n",
            "Training Step: 568  | total loss: \u001b[1m\u001b[32m1.08619\u001b[0m\u001b[0m | time: 0.238s\n",
            "| Adam | epoch: 008 | loss: 1.08619 - acc: 0.9107 -- iter: 2048/2300\n",
            "Training Step: 569  | total loss: \u001b[1m\u001b[32m1.08307\u001b[0m\u001b[0m | time: 0.241s\n",
            "| Adam | epoch: 008 | loss: 1.08307 - acc: 0.9196 -- iter: 2080/2300\n",
            "Training Step: 570  | total loss: \u001b[1m\u001b[32m1.09293\u001b[0m\u001b[0m | time: 0.244s\n",
            "| Adam | epoch: 008 | loss: 1.09293 - acc: 0.9214 -- iter: 2112/2300\n",
            "Training Step: 571  | total loss: \u001b[1m\u001b[32m1.09889\u001b[0m\u001b[0m | time: 0.248s\n",
            "| Adam | epoch: 008 | loss: 1.09889 - acc: 0.9230 -- iter: 2144/2300\n",
            "Training Step: 572  | total loss: \u001b[1m\u001b[32m1.09604\u001b[0m\u001b[0m | time: 0.251s\n",
            "| Adam | epoch: 008 | loss: 1.09604 - acc: 0.9182 -- iter: 2176/2300\n",
            "Training Step: 573  | total loss: \u001b[1m\u001b[32m1.09184\u001b[0m\u001b[0m | time: 0.255s\n",
            "| Adam | epoch: 008 | loss: 1.09184 - acc: 0.9139 -- iter: 2208/2300\n",
            "Training Step: 574  | total loss: \u001b[1m\u001b[32m1.08543\u001b[0m\u001b[0m | time: 0.258s\n",
            "| Adam | epoch: 008 | loss: 1.08543 - acc: 0.9100 -- iter: 2240/2300\n",
            "Training Step: 575  | total loss: \u001b[1m\u001b[32m1.08997\u001b[0m\u001b[0m | time: 0.262s\n",
            "| Adam | epoch: 008 | loss: 1.08997 - acc: 0.9128 -- iter: 2272/2300\n",
            "Training Step: 576  | total loss: \u001b[1m\u001b[32m1.08933\u001b[0m\u001b[0m | time: 0.265s\n",
            "| Adam | epoch: 008 | loss: 1.08933 - acc: 0.9059 -- iter: 2300/2300\n",
            "--\n",
            "Training Step: 577  | total loss: \u001b[1m\u001b[32m1.09900\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 009 | loss: 1.09900 - acc: 0.9028 -- iter: 0032/2300\n",
            "Training Step: 578  | total loss: \u001b[1m\u001b[32m1.09202\u001b[0m\u001b[0m | time: 0.007s\n",
            "| Adam | epoch: 009 | loss: 1.09202 - acc: 0.9062 -- iter: 0064/2300\n",
            "Training Step: 579  | total loss: \u001b[1m\u001b[32m1.09975\u001b[0m\u001b[0m | time: 0.011s\n",
            "| Adam | epoch: 009 | loss: 1.09975 - acc: 0.9094 -- iter: 0096/2300\n",
            "Training Step: 580  | total loss: \u001b[1m\u001b[32m1.10876\u001b[0m\u001b[0m | time: 0.014s\n",
            "| Adam | epoch: 009 | loss: 1.10876 - acc: 0.9122 -- iter: 0128/2300\n",
            "Training Step: 581  | total loss: \u001b[1m\u001b[32m1.10032\u001b[0m\u001b[0m | time: 0.018s\n",
            "| Adam | epoch: 009 | loss: 1.10032 - acc: 0.9147 -- iter: 0160/2300\n",
            "Training Step: 582  | total loss: \u001b[1m\u001b[32m1.10954\u001b[0m\u001b[0m | time: 0.021s\n",
            "| Adam | epoch: 009 | loss: 1.10954 - acc: 0.9139 -- iter: 0192/2300\n",
            "Training Step: 583  | total loss: \u001b[1m\u001b[32m1.10509\u001b[0m\u001b[0m | time: 0.025s\n",
            "| Adam | epoch: 009 | loss: 1.10509 - acc: 0.9162 -- iter: 0224/2300\n",
            "Training Step: 584  | total loss: \u001b[1m\u001b[32m1.09713\u001b[0m\u001b[0m | time: 0.029s\n",
            "| Adam | epoch: 009 | loss: 1.09713 - acc: 0.9068 -- iter: 0256/2300\n",
            "Training Step: 585  | total loss: \u001b[1m\u001b[32m1.08995\u001b[0m\u001b[0m | time: 0.033s\n",
            "| Adam | epoch: 009 | loss: 1.08995 - acc: 0.9018 -- iter: 0288/2300\n",
            "Training Step: 586  | total loss: \u001b[1m\u001b[32m1.09253\u001b[0m\u001b[0m | time: 0.036s\n",
            "| Adam | epoch: 009 | loss: 1.09253 - acc: 0.9054 -- iter: 0320/2300\n",
            "Training Step: 587  | total loss: \u001b[1m\u001b[32m1.09788\u001b[0m\u001b[0m | time: 0.040s\n",
            "| Adam | epoch: 009 | loss: 1.09788 - acc: 0.9055 -- iter: 0352/2300\n",
            "Training Step: 588  | total loss: \u001b[1m\u001b[32m1.10822\u001b[0m\u001b[0m | time: 0.043s\n",
            "| Adam | epoch: 009 | loss: 1.10822 - acc: 0.9024 -- iter: 0384/2300\n",
            "Training Step: 589  | total loss: \u001b[1m\u001b[32m1.10344\u001b[0m\u001b[0m | time: 0.047s\n",
            "| Adam | epoch: 009 | loss: 1.10344 - acc: 0.9028 -- iter: 0416/2300\n",
            "Training Step: 590  | total loss: \u001b[1m\u001b[32m1.09630\u001b[0m\u001b[0m | time: 0.050s\n",
            "| Adam | epoch: 009 | loss: 1.09630 - acc: 0.9031 -- iter: 0448/2300\n",
            "Training Step: 591  | total loss: \u001b[1m\u001b[32m1.10447\u001b[0m\u001b[0m | time: 0.054s\n",
            "| Adam | epoch: 009 | loss: 1.10447 - acc: 0.9034 -- iter: 0480/2300\n",
            "Training Step: 592  | total loss: \u001b[1m\u001b[32m1.10527\u001b[0m\u001b[0m | time: 0.057s\n",
            "| Adam | epoch: 009 | loss: 1.10527 - acc: 0.9037 -- iter: 0512/2300\n",
            "Training Step: 593  | total loss: \u001b[1m\u001b[32m1.11007\u001b[0m\u001b[0m | time: 0.061s\n",
            "| Adam | epoch: 009 | loss: 1.11007 - acc: 0.9102 -- iter: 0544/2300\n",
            "Training Step: 594  | total loss: \u001b[1m\u001b[32m1.11019\u001b[0m\u001b[0m | time: 0.064s\n",
            "| Adam | epoch: 009 | loss: 1.11019 - acc: 0.9192 -- iter: 0576/2300\n",
            "Training Step: 595  | total loss: \u001b[1m\u001b[32m1.11154\u001b[0m\u001b[0m | time: 0.068s\n",
            "| Adam | epoch: 009 | loss: 1.11154 - acc: 0.9179 -- iter: 0608/2300\n",
            "Training Step: 596  | total loss: \u001b[1m\u001b[32m1.10849\u001b[0m\u001b[0m | time: 0.072s\n",
            "| Adam | epoch: 009 | loss: 1.10849 - acc: 0.9199 -- iter: 0640/2300\n",
            "Training Step: 597  | total loss: \u001b[1m\u001b[32m1.10812\u001b[0m\u001b[0m | time: 0.076s\n",
            "| Adam | epoch: 009 | loss: 1.10812 - acc: 0.9091 -- iter: 0672/2300\n",
            "Training Step: 598  | total loss: \u001b[1m\u001b[32m1.10908\u001b[0m\u001b[0m | time: 0.079s\n",
            "| Adam | epoch: 009 | loss: 1.10908 - acc: 0.9026 -- iter: 0704/2300\n",
            "Training Step: 599  | total loss: \u001b[1m\u001b[32m1.11609\u001b[0m\u001b[0m | time: 0.083s\n",
            "| Adam | epoch: 009 | loss: 1.11609 - acc: 0.9030 -- iter: 0736/2300\n",
            "Training Step: 600  | total loss: \u001b[1m\u001b[32m1.11305\u001b[0m\u001b[0m | time: 0.086s\n",
            "| Adam | epoch: 009 | loss: 1.11305 - acc: 0.8908 -- iter: 0768/2300\n",
            "Training Step: 601  | total loss: \u001b[1m\u001b[32m1.10745\u001b[0m\u001b[0m | time: 0.089s\n",
            "| Adam | epoch: 009 | loss: 1.10745 - acc: 0.8830 -- iter: 0800/2300\n",
            "Training Step: 602  | total loss: \u001b[1m\u001b[32m1.10342\u001b[0m\u001b[0m | time: 0.093s\n",
            "| Adam | epoch: 009 | loss: 1.10342 - acc: 0.8915 -- iter: 0832/2300\n",
            "Training Step: 603  | total loss: \u001b[1m\u001b[32m1.10605\u001b[0m\u001b[0m | time: 0.096s\n",
            "| Adam | epoch: 009 | loss: 1.10605 - acc: 0.8930 -- iter: 0864/2300\n",
            "Training Step: 604  | total loss: \u001b[1m\u001b[32m1.09810\u001b[0m\u001b[0m | time: 0.099s\n",
            "| Adam | epoch: 009 | loss: 1.09810 - acc: 0.8975 -- iter: 0896/2300\n",
            "Training Step: 605  | total loss: \u001b[1m\u001b[32m1.09341\u001b[0m\u001b[0m | time: 0.103s\n",
            "| Adam | epoch: 009 | loss: 1.09341 - acc: 0.9077 -- iter: 0928/2300\n",
            "Training Step: 606  | total loss: \u001b[1m\u001b[32m1.08595\u001b[0m\u001b[0m | time: 0.106s\n",
            "| Adam | epoch: 009 | loss: 1.08595 - acc: 0.9138 -- iter: 0960/2300\n",
            "Training Step: 607  | total loss: \u001b[1m\u001b[32m1.09076\u001b[0m\u001b[0m | time: 0.110s\n",
            "| Adam | epoch: 009 | loss: 1.09076 - acc: 0.9224 -- iter: 0992/2300\n",
            "Training Step: 608  | total loss: \u001b[1m\u001b[32m1.09445\u001b[0m\u001b[0m | time: 0.113s\n",
            "| Adam | epoch: 009 | loss: 1.09445 - acc: 0.9177 -- iter: 1024/2300\n",
            "Training Step: 609  | total loss: \u001b[1m\u001b[32m1.09624\u001b[0m\u001b[0m | time: 0.116s\n",
            "| Adam | epoch: 009 | loss: 1.09624 - acc: 0.9165 -- iter: 1056/2300\n",
            "Training Step: 610  | total loss: \u001b[1m\u001b[32m1.10420\u001b[0m\u001b[0m | time: 0.120s\n",
            "| Adam | epoch: 009 | loss: 1.10420 - acc: 0.9093 -- iter: 1088/2300\n",
            "Training Step: 611  | total loss: \u001b[1m\u001b[32m1.10525\u001b[0m\u001b[0m | time: 0.123s\n",
            "| Adam | epoch: 009 | loss: 1.10525 - acc: 0.9090 -- iter: 1120/2300\n",
            "Training Step: 612  | total loss: \u001b[1m\u001b[32m1.11073\u001b[0m\u001b[0m | time: 0.128s\n",
            "| Adam | epoch: 009 | loss: 1.11073 - acc: 0.8993 -- iter: 1152/2300\n",
            "Training Step: 613  | total loss: \u001b[1m\u001b[32m1.10934\u001b[0m\u001b[0m | time: 0.134s\n",
            "| Adam | epoch: 009 | loss: 1.10934 - acc: 0.9000 -- iter: 1184/2300\n",
            "Training Step: 614  | total loss: \u001b[1m\u001b[32m1.11227\u001b[0m\u001b[0m | time: 0.138s\n",
            "| Adam | epoch: 009 | loss: 1.11227 - acc: 0.9006 -- iter: 1216/2300\n",
            "Training Step: 615  | total loss: \u001b[1m\u001b[32m1.10977\u001b[0m\u001b[0m | time: 0.141s\n",
            "| Adam | epoch: 009 | loss: 1.10977 - acc: 0.9074 -- iter: 1248/2300\n",
            "Training Step: 616  | total loss: \u001b[1m\u001b[32m1.11828\u001b[0m\u001b[0m | time: 0.145s\n",
            "| Adam | epoch: 009 | loss: 1.11828 - acc: 0.9073 -- iter: 1280/2300\n",
            "Training Step: 617  | total loss: \u001b[1m\u001b[32m1.11745\u001b[0m\u001b[0m | time: 0.148s\n",
            "| Adam | epoch: 009 | loss: 1.11745 - acc: 0.9166 -- iter: 1312/2300\n",
            "Training Step: 618  | total loss: \u001b[1m\u001b[32m1.11934\u001b[0m\u001b[0m | time: 0.152s\n",
            "| Adam | epoch: 009 | loss: 1.11934 - acc: 0.9062 -- iter: 1344/2300\n",
            "Training Step: 619  | total loss: \u001b[1m\u001b[32m1.12270\u001b[0m\u001b[0m | time: 0.155s\n",
            "| Adam | epoch: 009 | loss: 1.12270 - acc: 0.8999 -- iter: 1376/2300\n",
            "Training Step: 620  | total loss: \u001b[1m\u001b[32m1.12920\u001b[0m\u001b[0m | time: 0.159s\n",
            "| Adam | epoch: 009 | loss: 1.12920 - acc: 0.8943 -- iter: 1408/2300\n",
            "Training Step: 621  | total loss: \u001b[1m\u001b[32m1.11340\u001b[0m\u001b[0m | time: 0.163s\n",
            "| Adam | epoch: 009 | loss: 1.11340 - acc: 0.9018 -- iter: 1440/2300\n",
            "Training Step: 622  | total loss: \u001b[1m\u001b[32m1.11535\u001b[0m\u001b[0m | time: 0.167s\n",
            "| Adam | epoch: 009 | loss: 1.11535 - acc: 0.8991 -- iter: 1472/2300\n",
            "Training Step: 623  | total loss: \u001b[1m\u001b[32m1.12205\u001b[0m\u001b[0m | time: 0.171s\n",
            "| Adam | epoch: 009 | loss: 1.12205 - acc: 0.8967 -- iter: 1504/2300\n",
            "Training Step: 624  | total loss: \u001b[1m\u001b[32m1.11969\u001b[0m\u001b[0m | time: 0.174s\n",
            "| Adam | epoch: 009 | loss: 1.11969 - acc: 0.8914 -- iter: 1536/2300\n",
            "Training Step: 625  | total loss: \u001b[1m\u001b[32m1.12246\u001b[0m\u001b[0m | time: 0.178s\n",
            "| Adam | epoch: 009 | loss: 1.12246 - acc: 0.8929 -- iter: 1568/2300\n",
            "Training Step: 626  | total loss: \u001b[1m\u001b[32m1.12461\u001b[0m\u001b[0m | time: 0.182s\n",
            "| Adam | epoch: 009 | loss: 1.12461 - acc: 0.8942 -- iter: 1600/2300\n",
            "Training Step: 627  | total loss: \u001b[1m\u001b[32m1.12997\u001b[0m\u001b[0m | time: 0.185s\n",
            "| Adam | epoch: 009 | loss: 1.12997 - acc: 0.8985 -- iter: 1632/2300\n",
            "Training Step: 628  | total loss: \u001b[1m\u001b[32m1.12499\u001b[0m\u001b[0m | time: 0.189s\n",
            "| Adam | epoch: 009 | loss: 1.12499 - acc: 0.8931 -- iter: 1664/2300\n",
            "Training Step: 629  | total loss: \u001b[1m\u001b[32m1.12354\u001b[0m\u001b[0m | time: 0.193s\n",
            "| Adam | epoch: 009 | loss: 1.12354 - acc: 0.8881 -- iter: 1696/2300\n",
            "Training Step: 630  | total loss: \u001b[1m\u001b[32m1.12226\u001b[0m\u001b[0m | time: 0.197s\n",
            "| Adam | epoch: 009 | loss: 1.12226 - acc: 0.8899 -- iter: 1728/2300\n",
            "Training Step: 631  | total loss: \u001b[1m\u001b[32m1.12529\u001b[0m\u001b[0m | time: 0.200s\n",
            "| Adam | epoch: 009 | loss: 1.12529 - acc: 0.8822 -- iter: 1760/2300\n",
            "Training Step: 632  | total loss: \u001b[1m\u001b[32m1.12072\u001b[0m\u001b[0m | time: 0.204s\n",
            "| Adam | epoch: 009 | loss: 1.12072 - acc: 0.8940 -- iter: 1792/2300\n",
            "Training Step: 633  | total loss: \u001b[1m\u001b[32m1.11962\u001b[0m\u001b[0m | time: 0.207s\n",
            "| Adam | epoch: 009 | loss: 1.11962 - acc: 0.8890 -- iter: 1824/2300\n",
            "Training Step: 634  | total loss: \u001b[1m\u001b[32m1.12223\u001b[0m\u001b[0m | time: 0.211s\n",
            "| Adam | epoch: 009 | loss: 1.12223 - acc: 0.8876 -- iter: 1856/2300\n",
            "Training Step: 635  | total loss: \u001b[1m\u001b[32m1.11611\u001b[0m\u001b[0m | time: 0.215s\n",
            "| Adam | epoch: 009 | loss: 1.11611 - acc: 0.8894 -- iter: 1888/2300\n",
            "Training Step: 636  | total loss: \u001b[1m\u001b[32m1.11078\u001b[0m\u001b[0m | time: 0.218s\n",
            "| Adam | epoch: 009 | loss: 1.11078 - acc: 0.8880 -- iter: 1920/2300\n",
            "Training Step: 637  | total loss: \u001b[1m\u001b[32m1.11666\u001b[0m\u001b[0m | time: 0.222s\n",
            "| Adam | epoch: 009 | loss: 1.11666 - acc: 0.8961 -- iter: 1952/2300\n",
            "Training Step: 638  | total loss: \u001b[1m\u001b[32m1.10832\u001b[0m\u001b[0m | time: 0.226s\n",
            "| Adam | epoch: 009 | loss: 1.10832 - acc: 0.9002 -- iter: 1984/2300\n",
            "Training Step: 639  | total loss: \u001b[1m\u001b[32m1.11082\u001b[0m\u001b[0m | time: 0.229s\n",
            "| Adam | epoch: 009 | loss: 1.11082 - acc: 0.9039 -- iter: 2016/2300\n",
            "Training Step: 640  | total loss: \u001b[1m\u001b[32m1.11442\u001b[0m\u001b[0m | time: 0.233s\n",
            "| Adam | epoch: 009 | loss: 1.11442 - acc: 0.9073 -- iter: 2048/2300\n",
            "Training Step: 641  | total loss: \u001b[1m\u001b[32m1.11349\u001b[0m\u001b[0m | time: 0.237s\n",
            "| Adam | epoch: 009 | loss: 1.11349 - acc: 0.9134 -- iter: 2080/2300\n",
            "Training Step: 642  | total loss: \u001b[1m\u001b[32m1.11399\u001b[0m\u001b[0m | time: 0.240s\n",
            "| Adam | epoch: 009 | loss: 1.11399 - acc: 0.9065 -- iter: 2112/2300\n",
            "Training Step: 643  | total loss: \u001b[1m\u001b[32m1.10877\u001b[0m\u001b[0m | time: 0.244s\n",
            "| Adam | epoch: 009 | loss: 1.10877 - acc: 0.9064 -- iter: 2144/2300\n",
            "Training Step: 644  | total loss: \u001b[1m\u001b[32m1.09685\u001b[0m\u001b[0m | time: 0.248s\n",
            "| Adam | epoch: 009 | loss: 1.09685 - acc: 0.9096 -- iter: 2176/2300\n",
            "Training Step: 645  | total loss: \u001b[1m\u001b[32m1.09276\u001b[0m\u001b[0m | time: 0.252s\n",
            "| Adam | epoch: 009 | loss: 1.09276 - acc: 0.9186 -- iter: 2208/2300\n",
            "Training Step: 646  | total loss: \u001b[1m\u001b[32m1.10142\u001b[0m\u001b[0m | time: 0.255s\n",
            "| Adam | epoch: 009 | loss: 1.10142 - acc: 0.9174 -- iter: 2240/2300\n",
            "Training Step: 647  | total loss: \u001b[1m\u001b[32m1.10270\u001b[0m\u001b[0m | time: 0.258s\n",
            "| Adam | epoch: 009 | loss: 1.10270 - acc: 0.9131 -- iter: 2272/2300\n",
            "Training Step: 648  | total loss: \u001b[1m\u001b[32m1.10388\u001b[0m\u001b[0m | time: 0.263s\n",
            "| Adam | epoch: 009 | loss: 1.10388 - acc: 0.9093 -- iter: 2300/2300\n",
            "--\n",
            "Training Step: 649  | total loss: \u001b[1m\u001b[32m1.11033\u001b[0m\u001b[0m | time: 0.004s\n",
            "| Adam | epoch: 010 | loss: 1.11033 - acc: 0.9153 -- iter: 0032/2300\n",
            "Training Step: 650  | total loss: \u001b[1m\u001b[32m1.10526\u001b[0m\u001b[0m | time: 0.008s\n",
            "| Adam | epoch: 010 | loss: 1.10526 - acc: 0.9144 -- iter: 0064/2300\n",
            "Training Step: 651  | total loss: \u001b[1m\u001b[32m1.10376\u001b[0m\u001b[0m | time: 0.012s\n",
            "| Adam | epoch: 010 | loss: 1.10376 - acc: 0.9198 -- iter: 0096/2300\n",
            "Training Step: 652  | total loss: \u001b[1m\u001b[32m1.10607\u001b[0m\u001b[0m | time: 0.015s\n",
            "| Adam | epoch: 010 | loss: 1.10607 - acc: 0.9247 -- iter: 0128/2300\n",
            "Training Step: 653  | total loss: \u001b[1m\u001b[32m1.10835\u001b[0m\u001b[0m | time: 0.019s\n",
            "| Adam | epoch: 010 | loss: 1.10835 - acc: 0.9322 -- iter: 0160/2300\n",
            "Training Step: 654  | total loss: \u001b[1m\u001b[32m1.11095\u001b[0m\u001b[0m | time: 0.022s\n",
            "| Adam | epoch: 010 | loss: 1.11095 - acc: 0.9265 -- iter: 0192/2300\n",
            "Training Step: 655  | total loss: \u001b[1m\u001b[32m1.11132\u001b[0m\u001b[0m | time: 0.027s\n",
            "| Adam | epoch: 010 | loss: 1.11132 - acc: 0.9182 -- iter: 0224/2300\n",
            "Training Step: 656  | total loss: \u001b[1m\u001b[32m1.11658\u001b[0m\u001b[0m | time: 0.031s\n",
            "| Adam | epoch: 010 | loss: 1.11658 - acc: 0.9108 -- iter: 0256/2300\n",
            "Training Step: 657  | total loss: \u001b[1m\u001b[32m1.10796\u001b[0m\u001b[0m | time: 0.035s\n",
            "| Adam | epoch: 010 | loss: 1.10796 - acc: 0.9126 -- iter: 0288/2300\n",
            "Training Step: 658  | total loss: \u001b[1m\u001b[32m1.10016\u001b[0m\u001b[0m | time: 0.039s\n",
            "| Adam | epoch: 010 | loss: 1.10016 - acc: 0.9142 -- iter: 0320/2300\n",
            "Training Step: 659  | total loss: \u001b[1m\u001b[32m1.09808\u001b[0m\u001b[0m | time: 0.042s\n",
            "| Adam | epoch: 010 | loss: 1.09808 - acc: 0.9227 -- iter: 0352/2300\n",
            "Training Step: 660  | total loss: \u001b[1m\u001b[32m1.09874\u001b[0m\u001b[0m | time: 0.046s\n",
            "| Adam | epoch: 010 | loss: 1.09874 - acc: 0.9211 -- iter: 0384/2300\n",
            "Training Step: 661  | total loss: \u001b[1m\u001b[32m1.09815\u001b[0m\u001b[0m | time: 0.050s\n",
            "| Adam | epoch: 010 | loss: 1.09815 - acc: 0.9196 -- iter: 0416/2300\n",
            "Training Step: 662  | total loss: \u001b[1m\u001b[32m1.10465\u001b[0m\u001b[0m | time: 0.054s\n",
            "| Adam | epoch: 010 | loss: 1.10465 - acc: 0.9214 -- iter: 0448/2300\n",
            "Training Step: 663  | total loss: \u001b[1m\u001b[32m1.10716\u001b[0m\u001b[0m | time: 0.058s\n",
            "| Adam | epoch: 010 | loss: 1.10716 - acc: 0.9230 -- iter: 0480/2300\n",
            "Training Step: 664  | total loss: \u001b[1m\u001b[32m1.10863\u001b[0m\u001b[0m | time: 0.064s\n",
            "| Adam | epoch: 010 | loss: 1.10863 - acc: 0.9276 -- iter: 0512/2300\n",
            "Training Step: 665  | total loss: \u001b[1m\u001b[32m1.10005\u001b[0m\u001b[0m | time: 0.069s\n",
            "| Adam | epoch: 010 | loss: 1.10005 - acc: 0.9161 -- iter: 0544/2300\n",
            "Training Step: 666  | total loss: \u001b[1m\u001b[32m1.10405\u001b[0m\u001b[0m | time: 0.073s\n",
            "| Adam | epoch: 010 | loss: 1.10405 - acc: 0.9245 -- iter: 0576/2300\n",
            "Training Step: 667  | total loss: \u001b[1m\u001b[32m1.10845\u001b[0m\u001b[0m | time: 0.077s\n",
            "| Adam | epoch: 010 | loss: 1.10845 - acc: 0.9289 -- iter: 0608/2300\n",
            "Training Step: 668  | total loss: \u001b[1m\u001b[32m1.10916\u001b[0m\u001b[0m | time: 0.081s\n",
            "| Adam | epoch: 010 | loss: 1.10916 - acc: 0.9266 -- iter: 0640/2300\n",
            "Training Step: 669  | total loss: \u001b[1m\u001b[32m1.10781\u001b[0m\u001b[0m | time: 0.085s\n",
            "| Adam | epoch: 010 | loss: 1.10781 - acc: 0.9277 -- iter: 0672/2300\n",
            "Training Step: 670  | total loss: \u001b[1m\u001b[32m1.10902\u001b[0m\u001b[0m | time: 0.089s\n",
            "| Adam | epoch: 010 | loss: 1.10902 - acc: 0.9162 -- iter: 0704/2300\n",
            "Training Step: 671  | total loss: \u001b[1m\u001b[32m1.10590\u001b[0m\u001b[0m | time: 0.093s\n",
            "| Adam | epoch: 010 | loss: 1.10590 - acc: 0.9090 -- iter: 0736/2300\n",
            "Training Step: 672  | total loss: \u001b[1m\u001b[32m1.08151\u001b[0m\u001b[0m | time: 0.096s\n",
            "| Adam | epoch: 010 | loss: 1.08151 - acc: 0.9181 -- iter: 0768/2300\n",
            "Training Step: 673  | total loss: \u001b[1m\u001b[32m1.07988\u001b[0m\u001b[0m | time: 0.101s\n",
            "| Adam | epoch: 010 | loss: 1.07988 - acc: 0.9231 -- iter: 0800/2300\n",
            "Training Step: 674  | total loss: \u001b[1m\u001b[32m1.08290\u001b[0m\u001b[0m | time: 0.105s\n",
            "| Adam | epoch: 010 | loss: 1.08290 - acc: 0.9277 -- iter: 0832/2300\n",
            "Training Step: 675  | total loss: \u001b[1m\u001b[32m1.08624\u001b[0m\u001b[0m | time: 0.109s\n",
            "| Adam | epoch: 010 | loss: 1.08624 - acc: 0.9255 -- iter: 0864/2300\n",
            "Training Step: 676  | total loss: \u001b[1m\u001b[32m1.08942\u001b[0m\u001b[0m | time: 0.113s\n",
            "| Adam | epoch: 010 | loss: 1.08942 - acc: 0.9205 -- iter: 0896/2300\n",
            "Training Step: 677  | total loss: \u001b[1m\u001b[32m1.09465\u001b[0m\u001b[0m | time: 0.117s\n",
            "| Adam | epoch: 010 | loss: 1.09465 - acc: 0.9159 -- iter: 0928/2300\n",
            "Training Step: 678  | total loss: \u001b[1m\u001b[32m1.08966\u001b[0m\u001b[0m | time: 0.121s\n",
            "| Adam | epoch: 010 | loss: 1.08966 - acc: 0.9118 -- iter: 0960/2300\n",
            "Training Step: 679  | total loss: \u001b[1m\u001b[32m1.08637\u001b[0m\u001b[0m | time: 0.125s\n",
            "| Adam | epoch: 010 | loss: 1.08637 - acc: 0.9175 -- iter: 0992/2300\n",
            "Training Step: 680  | total loss: \u001b[1m\u001b[32m1.09127\u001b[0m\u001b[0m | time: 0.129s\n",
            "| Adam | epoch: 010 | loss: 1.09127 - acc: 0.9164 -- iter: 1024/2300\n",
            "Training Step: 681  | total loss: \u001b[1m\u001b[32m1.10131\u001b[0m\u001b[0m | time: 0.133s\n",
            "| Adam | epoch: 010 | loss: 1.10131 - acc: 0.9123 -- iter: 1056/2300\n",
            "Training Step: 682  | total loss: \u001b[1m\u001b[32m1.10440\u001b[0m\u001b[0m | time: 0.137s\n",
            "| Adam | epoch: 010 | loss: 1.10440 - acc: 0.9085 -- iter: 1088/2300\n",
            "Training Step: 683  | total loss: \u001b[1m\u001b[32m1.10155\u001b[0m\u001b[0m | time: 0.141s\n",
            "| Adam | epoch: 010 | loss: 1.10155 - acc: 0.9021 -- iter: 1120/2300\n",
            "Training Step: 684  | total loss: \u001b[1m\u001b[32m1.11347\u001b[0m\u001b[0m | time: 0.145s\n",
            "| Adam | epoch: 010 | loss: 1.11347 - acc: 0.8994 -- iter: 1152/2300\n",
            "Training Step: 685  | total loss: \u001b[1m\u001b[32m1.10796\u001b[0m\u001b[0m | time: 0.150s\n",
            "| Adam | epoch: 010 | loss: 1.10796 - acc: 0.9000 -- iter: 1184/2300\n",
            "Training Step: 686  | total loss: \u001b[1m\u001b[32m1.11396\u001b[0m\u001b[0m | time: 0.154s\n",
            "| Adam | epoch: 010 | loss: 1.11396 - acc: 0.8944 -- iter: 1216/2300\n",
            "Training Step: 687  | total loss: \u001b[1m\u001b[32m1.11617\u001b[0m\u001b[0m | time: 0.159s\n",
            "| Adam | epoch: 010 | loss: 1.11617 - acc: 0.8987 -- iter: 1248/2300\n",
            "Training Step: 688  | total loss: \u001b[1m\u001b[32m1.10792\u001b[0m\u001b[0m | time: 0.163s\n",
            "| Adam | epoch: 010 | loss: 1.10792 - acc: 0.9026 -- iter: 1280/2300\n",
            "Training Step: 689  | total loss: \u001b[1m\u001b[32m1.10635\u001b[0m\u001b[0m | time: 0.166s\n",
            "| Adam | epoch: 010 | loss: 1.10635 - acc: 0.9061 -- iter: 1312/2300\n",
            "Training Step: 690  | total loss: \u001b[1m\u001b[32m1.10932\u001b[0m\u001b[0m | time: 0.171s\n",
            "| Adam | epoch: 010 | loss: 1.10932 - acc: 0.9124 -- iter: 1344/2300\n",
            "Training Step: 691  | total loss: \u001b[1m\u001b[32m1.11253\u001b[0m\u001b[0m | time: 0.174s\n",
            "| Adam | epoch: 010 | loss: 1.11253 - acc: 0.9149 -- iter: 1376/2300\n",
            "Training Step: 692  | total loss: \u001b[1m\u001b[32m1.10868\u001b[0m\u001b[0m | time: 0.178s\n",
            "| Adam | epoch: 010 | loss: 1.10868 - acc: 0.9171 -- iter: 1408/2300\n",
            "Training Step: 693  | total loss: \u001b[1m\u001b[32m1.10954\u001b[0m\u001b[0m | time: 0.182s\n",
            "| Adam | epoch: 010 | loss: 1.10954 - acc: 0.9192 -- iter: 1440/2300\n",
            "Training Step: 694  | total loss: \u001b[1m\u001b[32m1.11140\u001b[0m\u001b[0m | time: 0.186s\n",
            "| Adam | epoch: 010 | loss: 1.11140 - acc: 0.9054 -- iter: 1472/2300\n",
            "Training Step: 695  | total loss: \u001b[1m\u001b[32m1.11099\u001b[0m\u001b[0m | time: 0.190s\n",
            "| Adam | epoch: 010 | loss: 1.11099 - acc: 0.9023 -- iter: 1504/2300\n",
            "Training Step: 696  | total loss: \u001b[1m\u001b[32m1.10541\u001b[0m\u001b[0m | time: 0.194s\n",
            "| Adam | epoch: 010 | loss: 1.10541 - acc: 0.8996 -- iter: 1536/2300\n",
            "Training Step: 697  | total loss: \u001b[1m\u001b[32m1.10911\u001b[0m\u001b[0m | time: 0.198s\n",
            "| Adam | epoch: 010 | loss: 1.10911 - acc: 0.9065 -- iter: 1568/2300\n",
            "Training Step: 698  | total loss: \u001b[1m\u001b[32m1.10344\u001b[0m\u001b[0m | time: 0.202s\n",
            "| Adam | epoch: 010 | loss: 1.10344 - acc: 0.9096 -- iter: 1600/2300\n",
            "Training Step: 699  | total loss: \u001b[1m\u001b[32m1.09847\u001b[0m\u001b[0m | time: 0.205s\n",
            "| Adam | epoch: 010 | loss: 1.09847 - acc: 0.9124 -- iter: 1632/2300\n",
            "Training Step: 700  | total loss: \u001b[1m\u001b[32m1.09830\u001b[0m\u001b[0m | time: 0.209s\n",
            "| Adam | epoch: 010 | loss: 1.09830 - acc: 0.9055 -- iter: 1664/2300\n",
            "Training Step: 701  | total loss: \u001b[1m\u001b[32m1.09911\u001b[0m\u001b[0m | time: 0.212s\n",
            "| Adam | epoch: 010 | loss: 1.09911 - acc: 0.8962 -- iter: 1696/2300\n",
            "Training Step: 702  | total loss: \u001b[1m\u001b[32m1.10366\u001b[0m\u001b[0m | time: 0.216s\n",
            "| Adam | epoch: 010 | loss: 1.10366 - acc: 0.9004 -- iter: 1728/2300\n",
            "Training Step: 703  | total loss: \u001b[1m\u001b[32m1.10556\u001b[0m\u001b[0m | time: 0.219s\n",
            "| Adam | epoch: 010 | loss: 1.10556 - acc: 0.8916 -- iter: 1760/2300\n",
            "Training Step: 704  | total loss: \u001b[1m\u001b[32m1.10211\u001b[0m\u001b[0m | time: 0.223s\n",
            "| Adam | epoch: 010 | loss: 1.10211 - acc: 0.8930 -- iter: 1792/2300\n",
            "Training Step: 705  | total loss: \u001b[1m\u001b[32m1.09864\u001b[0m\u001b[0m | time: 0.226s\n",
            "| Adam | epoch: 010 | loss: 1.09864 - acc: 0.8881 -- iter: 1824/2300\n",
            "Training Step: 706  | total loss: \u001b[1m\u001b[32m1.10758\u001b[0m\u001b[0m | time: 0.230s\n",
            "| Adam | epoch: 010 | loss: 1.10758 - acc: 0.8962 -- iter: 1856/2300\n",
            "Training Step: 707  | total loss: \u001b[1m\u001b[32m1.11303\u001b[0m\u001b[0m | time: 0.233s\n",
            "| Adam | epoch: 010 | loss: 1.11303 - acc: 0.9003 -- iter: 1888/2300\n",
            "Training Step: 708  | total loss: \u001b[1m\u001b[32m1.12194\u001b[0m\u001b[0m | time: 0.237s\n",
            "| Adam | epoch: 010 | loss: 1.12194 - acc: 0.9009 -- iter: 1920/2300\n",
            "Training Step: 709  | total loss: \u001b[1m\u001b[32m1.13039\u001b[0m\u001b[0m | time: 0.240s\n",
            "| Adam | epoch: 010 | loss: 1.13039 - acc: 0.8921 -- iter: 1952/2300\n",
            "Training Step: 710  | total loss: \u001b[1m\u001b[32m1.13282\u001b[0m\u001b[0m | time: 0.244s\n",
            "| Adam | epoch: 010 | loss: 1.13282 - acc: 0.8935 -- iter: 1984/2300\n",
            "Training Step: 711  | total loss: \u001b[1m\u001b[32m1.13437\u001b[0m\u001b[0m | time: 0.248s\n",
            "| Adam | epoch: 010 | loss: 1.13437 - acc: 0.9010 -- iter: 2016/2300\n",
            "Training Step: 712  | total loss: \u001b[1m\u001b[32m1.12354\u001b[0m\u001b[0m | time: 0.251s\n",
            "| Adam | epoch: 010 | loss: 1.12354 - acc: 0.9047 -- iter: 2048/2300\n",
            "Training Step: 713  | total loss: \u001b[1m\u001b[32m1.11873\u001b[0m\u001b[0m | time: 0.255s\n",
            "| Adam | epoch: 010 | loss: 1.11873 - acc: 0.9111 -- iter: 2080/2300\n",
            "Training Step: 714  | total loss: \u001b[1m\u001b[32m1.12141\u001b[0m\u001b[0m | time: 0.261s\n",
            "| Adam | epoch: 010 | loss: 1.12141 - acc: 0.9137 -- iter: 2112/2300\n",
            "Training Step: 715  | total loss: \u001b[1m\u001b[32m1.11418\u001b[0m\u001b[0m | time: 0.266s\n",
            "| Adam | epoch: 010 | loss: 1.11418 - acc: 0.9223 -- iter: 2144/2300\n",
            "Training Step: 716  | total loss: \u001b[1m\u001b[32m1.10837\u001b[0m\u001b[0m | time: 0.270s\n",
            "| Adam | epoch: 010 | loss: 1.10837 - acc: 0.9301 -- iter: 2176/2300\n",
            "Training Step: 717  | total loss: \u001b[1m\u001b[32m1.11275\u001b[0m\u001b[0m | time: 0.273s\n",
            "| Adam | epoch: 010 | loss: 1.11275 - acc: 0.9183 -- iter: 2208/2300\n",
            "Training Step: 718  | total loss: \u001b[1m\u001b[32m1.11097\u001b[0m\u001b[0m | time: 0.276s\n",
            "| Adam | epoch: 010 | loss: 1.11097 - acc: 0.9140 -- iter: 2240/2300\n",
            "Training Step: 719  | total loss: \u001b[1m\u001b[32m1.10394\u001b[0m\u001b[0m | time: 0.280s\n",
            "| Adam | epoch: 010 | loss: 1.10394 - acc: 0.9132 -- iter: 2272/2300\n",
            "Training Step: 720  | total loss: \u001b[1m\u001b[32m1.10801\u001b[0m\u001b[0m | time: 0.284s\n",
            "| Adam | epoch: 010 | loss: 1.10801 - acc: 0.9157 -- iter: 2300/2300\n",
            "--\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TELPsQHEn9IH"
      },
      "source": [
        "# test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpiCKPtrmpDH",
        "outputId": "0718eead-8cf6-4cb9-ef99-358860db48cb"
      },
      "source": [
        "!python test.py"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tflearn/initializations.py:165: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "2021-10-11 19:08:44.992680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:08:45.002176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:08:45.002999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:08:45.004387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:08:45.005262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:08:45.006053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:08:45.624071: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:08:45.625024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:08:45.626040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:08:45.627002: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-10-11 19:08:45.627078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15090 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "2021-10-11 19:08:45.904220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:08:45.905283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:08:45.906097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:08:45.906970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:08:45.907946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:08:45.908793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15090 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "2021-10-11 19:08:45.937439: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:08:45.938344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:08:45.939127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:08:45.939986: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:08:45.940777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:08:45.941794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15090 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "2021-10-11 19:08:46.007808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:08:46.008761: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:08:46.009662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:08:46.010792: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:08:46.011713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-11 19:08:46.012683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15090 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "The prediction is 0.2620081305503845\n"
          ]
        }
      ]
    }
  ]
}